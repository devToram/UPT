{"version":3,"file":"tf-backend-cpu.es2017.min.js","sources":["../src/cpu_util.ts","../src/utils/pool_utils.ts","../src/backend_cpu.ts","../src/kernels/Max_impl.ts","../src/kernels/Transpose_impl.ts","../src/base.ts","../src/kernels/Cos.ts","../src/kernels/Dilation2D.ts","../src/kernels/Dilation2DBackpropFilter.ts","../src/kernels/Dilation2DBackpropInput.ts","../src/utils/kernel_utils.ts","../src/kernels/Div_impl.ts","../src/kernels/Div.ts","../src/kernels/FlipLeftRight.ts","../src/kernels/Identity.ts","../src/kernels/Max.ts","../src/kernels/MaxPoolWithArgmax.ts","../src/kernels/MaxPoolWithArgmax_impl.ts","../src/kernels/NonMaxSuppressionV4.ts","../src/kernels/NonMaxSuppressionV5.ts","../src/kernels/PadV2.ts","../src/kernels/Reshape.ts","../src/kernels/RotateWithOffset.ts","../src/kernels/Transpose.ts","../src/kernels/SpaceToBatchND.ts","../src/kernels/Square.ts","../src/kernels/SquaredDifference.ts","../src/register_all_kernels.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {backend_util, BackendTimingInfo, buffer, DataStorage, DataType, DataValues, engine, env, kernel_impls, KernelBackend, max, NumericDataType, Rank, Scalar, ShapeMap, slice_util, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, Tensor5D, TensorBuffer, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\nconst split = kernel_impls.split;\nconst tile = kernel_impls.tile;\nconst topkImpl = kernel_impls.topkImpl;\nconst whereImpl = kernel_impls.whereImpl;\nimport * as seedrandom from 'seedrandom';\nimport {assertNotComplex} from './cpu_util';\nimport {maxPoolPositions, pool} from './utils/pool_utils';\n\ninterface DataId {}\n\nfunction mapActivation(\n    backend: MathBackendCPU, x: Tensor, activation: backend_util.Activation,\n    preluActivationWeights?: Tensor): Tensor {\n  if (activation === 'linear') {\n    return backend.linear(x);\n  } else if (activation === 'relu') {\n    return backend.relu(x);\n  } else if (activation === 'elu') {\n    return backend.elu(x);\n  } else if (activation === 'relu6') {\n    return backend.relu6(x);\n  } else if (activation === 'prelu') {\n    return backend.prelu(x, preluActivationWeights);\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensors field.\n  // TODO(smilkov): Replace Tensor with TensorInfo when you modularize ops\n  // that work with complex tensors.\n  complexTensors?: {real: Tensor, imag: Tensor};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): void {\n    this.data.set(dataId, {values, dtype, refCount: 1});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensors} = this.data.get(dataId);\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensors.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensors.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n    return this.data.get(dataId).values;\n  }\n\n  private bufferSync<R extends Rank>(t: Tensor<R>): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return tf.buffer(t.shape, t.dtype, decodedData) as TensorBuffer<R>;\n  }\n\n  private makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const {complexTensors} = this.data.get(dataId);\n      if (complexTensors != null) {\n        complexTensors.real.dispose();\n        complexTensors.imag.dispose();\n      }\n      this.data.delete(dataId);\n    }\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    const dataId = tensorInfo.dataId;\n\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n\n      tensorData.refCount--;\n\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  complex<T extends Tensor>(real: T, imag: T): T {\n    const result = this.makeOutput(null, real.shape, 'complex64');\n\n    const resultData = this.data.get(result.dataId);\n    // The backend owns the reference to the underlying real and imaginary\n    // clones. These will explicitly get disposed when the complex tensor is\n    // disposed.\n    resultData.complexTensors = {\n      real: engine().keep(real.clone()),\n      imag: engine().keep(imag.clone())\n    };\n\n    return result as T;\n  }\n  real<T extends Tensor>(input: T): T {\n    const resultData = this.data.get(input.dataId);\n    return resultData.complexTensors.real.clone() as T;\n  }\n  imag<T extends Tensor>(input: T): T {\n    const resultData = this.data.get(input.dataId);\n    return resultData.complexTensors.imag.clone() as T;\n  }\n\n  slice<T extends Tensor>(x: T, begin: number[], size: number[]): T {\n    assertNotComplex(x, 'slice');\n\n    const isContinous = slice_util.isSliceContinous(x.shape, begin, size);\n    if (isContinous) {\n      const flatOffset = slice_util.computeFlatOffset(begin, x.strides);\n      const length = util.sizeFromShape(size);\n      const vals = this.readSync(x.dataId) as TypedArray;\n      return tf.tensor(\n                 vals.subarray(flatOffset, flatOffset + length), size,\n                 x.dtype) as T;\n    }\n\n    const buffer = tf.buffer(size, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; ++i) {\n      const loc = buffer.indexToLoc(i);\n      const xLoc = loc.map((idx, j) => idx + begin[j]);\n      buffer.values[i] = xBuf.get(...xLoc);\n    }\n    return buffer.toTensor() as T;\n  }\n\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    assertNotComplex(x, 'stridedSlice');\n\n    const outShape = slice_util.computeOutShape(begin, end, strides);\n\n    if (outShape.some(axis => axis === 0)) {\n      return tf.tensor([], outShape) as T;\n    }\n\n    const buffer = tf.buffer(outShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; i++) {\n      const loc = buffer.indexToLoc(i);\n\n      const newLoc: number[] = new Array(loc.length);\n      for (let j = 0; j < newLoc.length; j++) {\n        newLoc[j] = loc[j] * strides[j] + begin[j];\n      }\n      buffer.set(xBuf.get(...newLoc), ...loc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  diag(x: Tensor): Tensor {\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const buffer = tf.buffer([x.size, x.size], x.dtype);\n    const vals = buffer.values;\n    for (let i = 0; i < xVals.length; i++) {\n      vals[i * x.size + i] = xVals[i];\n    }\n    return buffer.toTensor();\n  }\n\n  unstack(x: Tensor, axis: number): Tensor[] {\n    const num = x.shape[axis];\n    const outShape: number[] = new Array(x.rank - 1);\n    let outIndex = 0;\n    for (let i = 0; i < x.rank; i++) {\n      if (i !== axis) {\n        outShape[outIndex++] = x.shape[i];\n      }\n    }\n\n    const begin = new Array(x.rank).fill(0);\n    const size = x.shape.slice();\n    size[axis] = 1;\n    const res = new Array(num);\n    for (let i = 0; i < res.length; i++) {\n      begin[axis] = i;\n      res[i] = this.slice(x, begin, size).reshape(outShape);\n    }\n    return res;\n  }\n\n  reverse<T extends Tensor>(x: T, axis: number[]): T {\n    assertNotComplex(x, 'reverse');\n\n    const buffer = tf.buffer(x.shape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < buffer.size; i++) {\n      const outLoc = buffer.indexToLoc(i);\n      const inLoc = outLoc.slice();\n      axis.forEach(ax => inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]);\n      buffer.set(xBuf.get(...inLoc), ...outLoc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  concat(tensors: Tensor[], axis: number): Tensor {\n    if (tensors[0].dtype === 'complex64') {\n      const reals = tensors.map((t) => tf.real(t));\n      const imags = tensors.map((t) => tf.imag(t));\n      return tf.complex(this.concat(reals, axis), this.concat(imags, axis));\n    }\n    const tensors2D = tensors.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      return t.as2D(-1, innerSize);\n    });\n    const outShape =\n      backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis\n        */);\n    const values =\n        tf.buffer(outShape as [number, number], tensors[0].dtype as 'float32')\n            .values;\n    if (tensors2D[0].shape[0] === 1) {\n      // Use built-in TypedArray.set() method for speed.\n      let offset = 0;\n      tensors2D.forEach(t => {\n        values.set(this.readSync(t.dataId) as TypedArray, offset);\n        offset += t.size;\n      });\n    } else {\n      let colOffset = 0;\n      tensors2D.forEach(t => {\n        const tVals = this.readSync(t.dataId) as TypedArray;\n        let tIdx = 0;\n        for (let row = 0; row < t.shape[0]; ++row) {\n          const resIdx = row * outShape[1] + colOffset;\n          for (let col = 0; col < t.shape[1]; ++col) {\n            values[resIdx + col] = tVals[tIdx++];\n          }\n        }\n        colOffset += t.shape[1];\n      });\n    }\n    const finalOutShape =\n        backend_util.computeOutShape(tensors.map(t => t.shape), axis);\n    return tf.tensor(values, finalOutShape, tensors[0].dtype);\n  }\n\n  neg<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'neg');\n\n    return this.multiply(tf.scalar(-1), x) as T;\n  }\n\n  add(a: Tensor, b: Tensor): Tensor {\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      return this.broadcastedBinaryComplexOp(\n          a.cast('complex64'), b.cast('complex64'),\n          (aReal, aImag, bReal, bImag) => {\n            return {real: aReal + bReal, imag: aImag + bImag};\n          });\n    }\n\n    return this.broadcastedBinaryOp(\n        a, b, upcastType(a.dtype, b.dtype),\n        (aValue, bValue) => aValue + bValue);\n  }\n\n  addN<T extends Tensor>(tensors: T[]): T {\n    assertNotComplex(tensors, 'addN');\n\n    const vals = tensors.map(t => this.readSync(t.dataId) as TypedArray);\n    const result = tf.buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n    const resultVals = result.values;\n    for (let i = 0; i < tensors.length; i++) {\n      const currVals = vals[i];\n      for (let j = 0; j < resultVals.length; j++) {\n        resultVals[j] += currVals[j];\n      }\n    }\n    return result.toTensor() as T;\n  }\n\n  softmax<T extends Tensor>(logits: T, dim: number): T {\n    const axes = util.parseAxisParam([dim], logits.shape);\n    // TODO(annxingyuan): Call maxImpl rather than op as part of softmax kernel\n    // modularization.\n    const maxLogit = max(logits, axes);\n    const expandedShape =\n        backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n    const a = this.subtract(logits, maxLogit.reshape(expandedShape));\n    const b = this.exp(a);\n    const sumExp = this.sum(b, axes).reshape(expandedShape);\n\n    // TODO(annxingyuan): Call divImpl rather than op as part of softmax\n    // kernel modularization.\n    return tf.div(b, sumExp);\n  }\n\n  subtract(a: Tensor, b: Tensor): Tensor {\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      return this.broadcastedBinaryComplexOp(\n          a.cast('complex64'), b.cast('complex64'),\n          (aReal, aImag, bReal, bImag) => {\n            return {real: aReal - bReal, imag: aImag - bImag};\n          });\n    }\n\n    return this.broadcastedBinaryOp(\n        a, b, upcastType(a.dtype, b.dtype),\n        (aValue, bValue) => aValue - bValue);\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    assertNotComplex([a, b], 'pow');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.pow(aValue, bValue)) as\n        T;\n  }\n\n  batchMatMul(\n      a: Tensor3D, b: Tensor3D, transposeA: boolean,\n      transposeB: boolean): Tensor3D {\n    assertNotComplex([a, b], 'matMul');\n\n    const sharedDim = transposeA ? a.shape[1] : a.shape[2];\n    const leftDim = transposeA ? a.shape[2] : a.shape[1];\n    const rightDim = transposeB ? b.shape[1] : b.shape[2];\n    const batchDim = a.shape[0];\n\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n        [a.strides[0], 1, a.strides[1]] :\n        [a.strides[0], a.strides[1], 1];\n    const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n        [1, b.strides[1], b.strides[0]] :\n        [b.strides[1], 1, b.strides[0]];\n\n    const size = leftDim * rightDim;\n    const result = tf.buffer([batchDim, leftDim, rightDim], a.dtype);\n    const resVals = result.values as TypedArray;\n    const blockSize = this.blockSize;\n\n    for (let b = 0; b < batchDim; b++) {\n      for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n        for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n          for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n            // for when blockSize doesn't evenly divide the input\n            const iBlock = Math.min(i0 + blockSize, leftDim);\n            const jBlock = Math.min(j0 + blockSize, rightDim);\n            const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n            for (let i = i0; i < iBlock; i++) {\n              for (let j = j0; j < jBlock; j++) {\n                let sum = 0.0;\n\n                for (let k = k0; k < kBlock; k++) {\n                  sum += aValues[b * aBatch + i * aOuterStep + k * aInnerStep] *\n                      bValues[k * bInnerStep + j * bOuterStep + b * bBatch];\n                }\n                resVals[b * size + (i * rightDim + j)] += sum;\n              }\n            }\n          }\n        }\n      }\n    }\n    return result.toTensor() as Tensor3D;\n  }\n\n  fusedBatchMatMul(\n      {a, b, transposeA, transposeB, bias, activation, preluActivationWeights}:\n          backend_util.FusedBatchMatMulConfig): Tensor3D {\n    let result = this.batchMatMul(a, b, transposeA, transposeB);\n    if (bias) {\n      result = this.add(result, bias) as Tensor3D;\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor3D;\n    }\n\n    return result;\n  }\n\n  multiply(a: Tensor, b: Tensor): Tensor {\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      return this.broadcastedBinaryComplexOp(\n          a.cast('complex64'), b.cast('complex64'),\n          (aReal, aImag, bReal, bImag) => {\n            return {\n              real: aReal * bReal - aImag * bImag,\n              imag: aReal * bImag + aImag * bReal\n            };\n          });\n    }\n\n    return this.broadcastedBinaryOp(\n        a, b, upcastType(a.dtype, b.dtype),\n        (aValue, bValue) => aValue * bValue);\n  }\n\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'floorDiv');\n\n    const op = (a: number, b: number) => Math.floor(a / b);\n    const outputDtype = 'int32';\n    return this.broadcastedBinaryOp(a, b, outputDtype, op);\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    backend_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let sum = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n      vals[i] = sum;\n    }\n    return result;\n  }\n\n  prod(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let prod = 1;\n      for (let j = 0; j < reduceSize; ++j) {\n        prod *= aVals[offset + j];\n      }\n      vals[i] = prod;\n    }\n    return result;\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    assertNotComplex(x, 'unsortedSegmentSum');\n\n    const res = [];\n\n    // Reshape the segment id's so that they can be broadcast with\n    // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n    const numIters = x.rank - segmentIds.rank;\n    for (let i = 0; i < numIters; ++i) {\n      segmentIds = segmentIds.expandDims(i + 1);\n    }\n\n    for (let i = 0; i < numSegments; ++i) {\n      const segmentId = tf.scalar(i, 'int32');\n      const mask = tf.equal(segmentId, segmentIds).asType('float32');\n      const sum = mask.mul(x).sum(0);\n      res.push(sum);\n    }\n\n    return tf.stack(res);\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMin');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      let minIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n      vals[i] = minIndex;\n    }\n    return result;\n  }\n\n  argMax(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMax');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      let maxIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n      vals[i] = maxIndex;\n    }\n    return result;\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    assertNotComplex(x, 'cumsum');\n\n    if (axis !== x.rank - 1) {\n      throw new Error(\n          `backend.cumsum in CPU expects an inner-most axis=${x.rank - 1} ` +\n          `but got axis=${axis}`);\n    }\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(x.shape, resultDtype);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    const finalDim = x.shape[x.rank - 1];\n    const indexAdjuster = reverse ?\n        (i: number, j: number) => i + finalDim - j - 1 :\n        (i: number, j: number) => i + j;\n    for (let i = 0; i < aVals.length; i += finalDim) {\n      for (let j = 0; j < finalDim; j++) {\n        const idx = indexAdjuster(i, j);\n        if (j === 0) {\n          vals[idx] = exclusive ? 0 : aVals[idx];\n        } else {\n          const prevIdx = indexAdjuster(i, j - 1);\n          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                  aVals[idx] + vals[prevIdx];\n        }\n      }\n    }\n    return result;\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'equal');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal === bVal) ? 1 : 0;\n    });\n  }\n\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'notEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal !== bVal) ? 1 : 0;\n    });\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'less');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal < bVal) ? 1 : 0;\n    });\n  }\n\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'lessEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal <= bVal) ? 1 : 0;\n    });\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greater');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal > bVal) ? 1 : 0;\n    });\n  }\n\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greaterEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal >= bVal) ? 1 : 0;\n    });\n  }\n\n  logicalNot<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'logicalNot');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = values[i] ? 0 : 1;\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalAnd');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal && bVal;\n    });\n  }\n\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalOr');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal || bVal;\n    });\n  }\n\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([condition, a, b], 'select');\n\n    const values = this.readSync(condition.dataId) as TypedArray;\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const result = tf.zeros(a.shape, upcastType(a.dtype, b.dtype));\n    const newValues = this.readSync(result.dataId) as TypedArray;\n    let index = 0;\n    const offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n        1 :\n        util.sizeFromShape(a.shape.slice(1));\n\n    for (let i = 0; i < values.length; i++) {\n      for (let j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n\n    return result;\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    assertNotComplex(x, 'topk');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    return topkImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'min');\n\n    backend_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n        }\n      }\n      vals[i] = min;\n    }\n    return result;\n  }\n\n  minimum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'minimum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.min(aVal, bVal));\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'mod');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const rem = aVal % bVal;\n      if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  }\n\n  maximum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'maximum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.max(aVal, bVal));\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'all');\n\n    backend_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let all = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        all = all && value;\n      }\n      vals[i] = all;\n    }\n    return result;\n  }\n\n  any(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'any');\n\n    backend_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let anyVal = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        anyVal = anyVal || value;\n      }\n      vals[i] = anyVal;\n    }\n    return result;\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'squaredDifference');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const diff = aVal - bVal;\n      return diff * diff;\n    });\n  }\n\n  ceil<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'ceil');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.ceil(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  floor<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'floor');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.floor(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  sign<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (values[i] < 0) {\n        newValues[i] = -1;\n      } else if (values[i] > 0) {\n        newValues[i] = 1;\n      } else {\n        newValues[i] = 0;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  isNaN<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (Number.isNaN(values[i])) {\n        newValues[i] = 1;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  isInf<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (Math.abs(values[i]) === Infinity) {\n        newValues[i] = 1;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  isFinite<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'x');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Uint8Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      if (Number.isFinite(values[i])) {\n        newValues[i] = 1;\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'bool');\n  }\n\n  round<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'round');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      // The algorithm is based on banker's rounding.\n      const base = Math.floor(values[i]);\n      if (values[i] - base < 0.5) {\n        newValues[i] = Math.floor(values[i]);\n      } else if (values[i] - base > 0.5) {\n        newValues[i] = Math.ceil(values[i]);\n      } else {\n        if (base % 2.0 === 0.0) {\n          newValues[i] = base;\n        } else {\n          newValues[i] = base + 1.0;\n        }\n      }\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  exp<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'exp');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.exp(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  expm1<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'expm1');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = Math.expm1(values[i]);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  log<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'log');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.log(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  log1p<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'log1p');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.log1p(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  sqrt<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sqrt');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = Math.sqrt(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  rsqrt<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'rsqrt');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = 1 / Math.sqrt(value);\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  reciprocal<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'reciprocal');\n\n    const values = this.readSync(x.dataId) as TypedArray;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = 1 / values[i];\n    }\n    return this.makeOutput(newValues, x.shape, 'float32');\n  }\n\n  linear<T extends Tensor>(x: T): T {\n    return x;\n  }\n\n  relu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.max(0, inVals[i]);\n    }\n    return res as T;\n  }\n\n  relu6<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.min(Math.max(0, inVals[i]), 6);\n    }\n    return res as T;\n  }\n\n  prelu<T extends Tensor>(x: T, a: T): T {\n    assertNotComplex([x, a], 'prelu');\n\n    return this.broadcastedBinaryOp(\n               x, a, x.dtype,\n               (xValue, aValue) => xValue < 0 ? aValue * xValue : xValue) as T;\n  }\n\n  elu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'elu');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 0) {\n        resultValues[i] = v;\n      } else {\n        resultValues[i] = (Math.exp(v) - 1);\n      }\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    assertNotComplex([dy, y], 'eluDer');\n\n    const resultValues = new Float32Array(y.size);\n    const values = this.readSync(y.dataId) as TypedArray;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n    return this.makeOutput(resultValues, y.shape, 'float32');\n  }\n\n  selu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'selu');\n\n    // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n    // see: https://arxiv.org/abs/1706.02515\n    const scaleAlpha = backend_util.SELU_SCALEALPHA;\n    const scale = backend_util.SELU_SCALE;\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 0) {\n        resultValues[i] = scale * v;\n      } else {\n        resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n      }\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  clip<T extends Tensor>(x: T, min: number, max: number): T {\n    assertNotComplex(x, 'clip');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      resultValues[i] = v > max ? max : (v < min ? min : v);\n    }\n    return this.makeOutput(resultValues, x.shape, x.dtype);\n  }\n\n  abs<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.abs(values[i]);\n    }\n\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  complexAbs<T extends Tensor>(x: T): T {\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < x.size; ++i) {\n      const real = values[i * 2];\n      const imag = values[i * 2 + 1];\n      resultValues[i] = Math.hypot(real, imag);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  int<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'int');\n\n    const resultValues = new Int32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = values[i];\n    }\n    return this.makeOutput(resultValues, x.shape, 'int32');\n  }\n\n  sigmoid<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sigmoid');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  softplus<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'softplus');\n\n    // mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n    // epsilon is the difference between 1.0 and the next representable float.\n    // For a single precision 32 bit float this should be 2^-23, see:\n    // https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n    const epsilon = 1.1920928955078125e-7;\n    const threshold = Math.log(epsilon) + 2.0;\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < values.length; ++i) {\n      // Value above which exp(x) may overflow, but softplus(x) == x\n      // is within machine epsilon.\n      const tooLarge = values[i] > -threshold;\n\n      // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n      // is within machine epsilon.\n      const tooSmall = values[i] < threshold;\n\n      const expX = Math.exp(values[i]);\n      let result;\n\n      if (tooSmall) {\n        result = expX;\n      } else if (tooLarge) {\n        result = values[i];\n      } else {\n        result = Math.log(1.0 + expX);\n      }\n      resultValues[i] = result;\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  sin<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sin');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sin(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  tan<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'tan');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.tan(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  asin<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'asin');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asin(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  acos<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'acos');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acos(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  atan<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'atan');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atan(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  atan2<T extends Tensor>(a: T, b: T): T {\n    assertNotComplex([a, b], 'atan2');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.atan2(aValue, bValue)) as\n        T;\n  }\n\n  sinh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'sinh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sinh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  cosh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'cosh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cosh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  tanh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'tanh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = util.tanh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  asinh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'asinh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asinh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  acosh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'acosh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acosh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  atanh<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'atanh');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atanh(values[i]);\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  erf<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'erf');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    const p = backend_util.ERF_P;\n    const a1 = backend_util.ERF_A1;\n    const a2 = backend_util.ERF_A2;\n    const a3 = backend_util.ERF_A3;\n    const a4 = backend_util.ERF_A4;\n    const a5 = backend_util.ERF_A5;\n    for (let i = 0; i < values.length; ++i) {\n      const sign = Math.sign(values[i]);\n      const v = Math.abs(values[i]);\n      const t = 1.0 / (1.0 + p * v);\n      resultValues[i] = sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  step<T extends Tensor>(x: T, alpha = 0): T {\n    assertNotComplex(x, 'step');\n\n    const resultValues = new Float32Array(x.size);\n    const values = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      if (isNaN(value)) {\n        resultValues[i] = NaN;\n      } else {\n        resultValues[i] = value > 0 ? 1 : alpha;\n      }\n    }\n    return this.makeOutput(resultValues, x.shape, 'float32');\n  }\n\n  fusedConv2d(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.conv2d(input, filter, convInfo);\n\n    if (bias) {\n      result = this.add(result, bias) as Tensor4D;\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, filter], 'conv2d');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n\n    const xBatchStride = x.strides[0];\n    const xRowStride = isChannelsLast ? x.strides[1] : x.strides[2];\n    const xColStride = isChannelsLast ? x.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : x.strides[1];\n    const yBatchStride = y.strides[0];\n    const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n    const yColStride = isChannelsLast ? y.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * xBatchStride;\n      const yOffset1 = b * yBatchStride;\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * yRowStride;\n        const xRCorner = yR * convInfo.strideHeight - padTop;\n        for (let wR = 0; wR < filterHeight; wR++) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * xRowStride;\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * yColStride;\n            const xCCorner = yC * convInfo.strideWidth - padLeft;\n            for (let wC = 0; wC < filterWidth; wC++) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * xColStride;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1 * xChannelStride];\n                for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                  yVals[yOffset3 + d2 * yChannelStride] +=\n                      xVal * wVals[wOffset3 + d2];\n                }\n                wOffset3 += convInfo.outChannels;\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor() as Tensor4D;\n  }\n\n  conv3d(x: Tensor5D, filter: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padFront = convInfo.padInfo.front;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const y = tf.buffer<Rank.R5>(convInfo.outShape, x.dtype as 'float32');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n        const yOffset2 = yOffset1 + yF * y.strides[1];\n        const xFCorner = yF * convInfo.strideDepth - padFront;\n        for (let wF = 0; wF < filterDepth; wF++) {\n          const xF = xFCorner + wF * dilationDepth;\n          if (xF < 0 || xF >= convInfo.inDepth) {\n            continue;\n          }\n          const wOffset1 = wF * filter.strides[0];\n          const xOffset2 = xOffset1 + xF * x.strides[1];\n\n          for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n            const yOffset3 = yOffset2 + yR * y.strides[2];\n            const xRCorner = yR * convInfo.strideHeight - padTop;\n            for (let wR = 0; wR < filterHeight; wR++) {\n              const xR = xRCorner + wR * dilationHeight;\n              if (xR < 0 || xR >= convInfo.inHeight) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wR * filter.strides[1];\n              const xOffset3 = xOffset2 + xR * x.strides[2];\n              for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n                const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                const xCCorner = yC * convInfo.strideWidth - padLeft;\n                for (let wC = 0; wC < filterWidth; wC++) {\n                  const xC = xCCorner + wC * dilationWidth;\n                  if (xC < 0 || xC >= convInfo.inWidth) {\n                    continue;\n                  }\n                  const wOffset3 = wOffset2 + wC * filter.strides[2];\n                  const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                  let wOffset4 = wOffset3;\n                  for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    const xVal = xVals[xOffset4 + d1];\n                    for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                      yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                    }\n                    wOffset4 += convInfo.outChannels;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor();\n  }\n\n  conv2dDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'conv2dDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth,\n      dataFormat\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    const isChannelsLast = dataFormat === 'channelsLast';\n    const xBatchStride = dx.strides[0];\n    const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n    const xColStride = isChannelsLast ? dx.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n    const yBatchStride = dy.strides[0];\n    const yRowStride = isChannelsLast ? dy.strides[1] : dy.strides[2];\n    const yColStride = isChannelsLast ? dy.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : dy.strides[1];\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset =\n                    yBatchStride * b + yRowStride * yR + yColStride * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let d2 = 0; d2 < outChannels; ++d2) {\n                  const pixel = dyValues[dyOffset + yChannelStride * d2];\n                  const weight = fltValues[fltOffset + d2];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            const dxOffset = xBatchStride * b + xRowStride * xR +\n                xColStride * xC + xChannelStride * d1;\n            dxValues[dxOffset] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv3dDerInput(\n      dy: Tensor5D, filter: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    const dx = tf.buffer<Rank.R5>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2, fltS3] = filter.strides;\n    const {\n      batchSize,\n      filterDepth,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inDepth,\n      inHeight,\n      inWidth,\n      outChannels,\n      outDepth,\n      outHeight,\n      outWidth,\n      strideDepth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        // Frames of depth\n        for (let xF = 0; xF < inDepth; ++xF) {\n          const xFCorner = xF - frontPad;\n          const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n          const yFMax =\n              Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n          // Rows as per standard 2d matrix notation\n          for (let xR = 0; xR < inHeight; ++xR) {\n            const xRCorner = xR - topPad;\n            const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n            const yRMax =\n                Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n            // Columns as per standard 2d matrix notation\n            for (let xC = 0; xC < inWidth; ++xC) {\n              const xCCorner = xC - leftPad;\n              const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n              const yCMax =\n                  Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n              let dotProd = 0;\n              for (let yF = xFMin; yF < yFMax; ++yF) {\n                const wF = yF * strideDepth - xFCorner;\n\n                for (let yR = xRMin; yR < yRMax; ++yR) {\n                  const wR = yR * strideHeight - xRCorner;\n\n                  for (let yC = xCMin; yC < yCMax; ++yC) {\n                    const wC = yC * strideWidth - xCCorner;\n                    const dyOffset =\n                        dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                    const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                        fltS1 * (filterHeight - 1 - wR) +\n                        fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                    for (let d2 = 0; d2 < outChannels; ++d2) {\n                      const pixel = dyValues[dyOffset + d2];\n                      const weight = fltValues[fltOffset + d2];\n                      dotProd += pixel * weight;\n                    }\n                  }\n                }\n              }\n              dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                  dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv2dDerFilter(x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, dy], 'conv2dDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            // Need to convolve.\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              for (let yR = yRMin; yR < yRMax; ++yR) {\n                const xR = wR + yR * strideHeight - topPad;\n                for (let yC = yCMin; yC < yCMax; ++yC) {\n                  const xC = wC + yC * strideWidth - leftPad;\n                  if (isChannelsLast) {\n                    dotProd +=\n                        xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                  } else {\n                    dotProd +=\n                        xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);\n                  }\n                }\n              }\n            }\n            dW.set(dotProd, wR, wC, d1, d2);\n          }\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  conv3dDerFilter(x: Tensor5D, dy: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n\n    const dw = tf.buffer<Rank.R5>(convInfo.filterShape, 'float32');\n    const dwValues = dw.values;\n    const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const [xS0, xS1, xS2, xS3] = x.strides;\n\n    const frontPad = convInfo.padInfo.front;\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n\n    for (let wF = 0; wF < filterDepth; ++wF) {\n      const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n      const yFMax = Math.min(\n          convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n      const wOffset1 = wF * dwS0;\n\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n        const yRMax = Math.min(\n            convInfo.outHeight,\n            (convInfo.inHeight + topPad - wR) / strideHeight);\n        const wOffset2 = wR * dwS1 + wOffset1;\n\n        for (let wC = 0; wC < filterWidth; ++wC) {\n          const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n          const yCMax = Math.min(\n              convInfo.outWidth,\n              (convInfo.inWidth + leftPad - wC) / strideWidth);\n          const wOffset3 = wC * dwS2 + wOffset2;\n\n          for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n            const wOffset4 = d1 * dwS3 + wOffset3;\n\n            for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n              let dotProd = 0;\n              for (let b = 0; b < convInfo.batchSize; ++b) {\n                const xOffset1 = b * xS0;\n                const yOffset1 = b * dyS0;\n\n                for (let yF = yFMin; yF < yFMax; ++yF) {\n                  const xF = wF + yF * strideDepth - frontPad;\n                  const xOffset2 = xF * xS1 + xOffset1;\n                  const yOffset2 = yF * dyS1 + yOffset1;\n\n                  for (let yR = yRMin; yR < yRMax; ++yR) {\n                    const xR = wR + yR * strideHeight - topPad;\n                    const xOffset3 = xR * xS2 + xOffset2;\n                    const yOffset3 = yR * dyS2 + yOffset2;\n\n                    for (let yC = yCMin; yC < yCMax; ++yC) {\n                      const xC = wC + yC * strideWidth - leftPad;\n                      const xOffset4 = xC * xS3 + xOffset3;\n                      const yOffset4 = yC * dyS3 + yOffset3;\n\n                      dotProd +=\n                          xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                    }\n                  }\n                }\n              }\n              dwValues[wOffset4 + d2] = dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dw.toTensor();\n  }\n\n  fusedDepthwiseConv2D(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.depthwiseConv2D(input, filter, convInfo);\n\n    if (bias) {\n      result = this.add(result, bias) as Tensor4D;\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  depthwiseConv2D(\n      x: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, filter], 'depthwiseConv2D');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * y.strides[1];\n        const xRCorner = yR * convInfo.strideHeight - padLeft;\n        for (let wR = 0; wR < filterHeight; ++wR) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * x.strides[1];\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * y.strides[2];\n            const xCCorner = yC * convInfo.strideWidth - padTop;\n            for (let wC = 0; wC < filterWidth; ++wC) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n              let yOffset4 = yOffset3;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1];\n                for (let q = 0; q < chMul; ++q) {\n                  yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                }\n                yOffset4 += chMul;\n                wOffset3 += chMul;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return y.toTensor() as Tensor4D;\n  }\n\n  depthwiseConv2DDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'depthwiseConv2DDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    const chMul = outChannels / inChannels;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let dm = 0; dm < chMul; ++dm) {\n                  const d2 = d1 * chMul + dm;\n                  const pixel = dyValues[dyOffset + d2];\n                  const weight = fltValues[fltOffset + dm];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  depthwiseConv2DDerFilter(\n      x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, dy], 'depthwiseConv2DDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          const d1 = Math.trunc(d2 / chMul);\n          const dm = d2 % chMul;\n\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, dm);\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    assertNotComplex(x, 'tile');\n    return tile(this.bufferSync(x), reps) as T;\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor1D, axis: number): T {\n    assertNotComplex([x, indices], 'gather');\n\n    const newShape: number[] = x.shape.slice();\n    const indicesValues = this.readSync(indices.dataId) as TypedArray;\n    newShape[axis] = indicesValues.length;\n    const result = tf.buffer(newShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < result.size; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    assertNotComplex([x], 'batchToSpaceND');\n\n    const prod = blockShape.reduce((a, b) => a * b);\n\n    const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n    const permuted =\n        backend_util.getPermuted(reshaped.length, blockShape.length);\n    const reshapedPermuted =\n        backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    const sliceBeginCoords =\n        backend_util.getSliceBeginCoords(crops, blockShape.length);\n    const sliceSize =\n        backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n    return tf.transpose(x.reshape(reshaped), permuted)\n               .reshape(reshapedPermuted)\n               .slice(sliceBeginCoords, sliceSize) as T;\n  }\n\n  maxPool(x: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex(x, 'maxPool');\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    return pool(xValues, x.shape, x.dtype, x.strides, convInfo, 'max')\n               .toTensor() as Tensor4D;\n  }\n\n  maxPoolBackprop(\n      dy: Tensor4D, x: Tensor4D, y: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, y], 'maxPoolBackprop');\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const maxPosBuf = buffer(\n        convInfo.outShape, x.dtype,\n        maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R4>(x.shape, 'float32');\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            // Shader code begins.\n            const dyRCorner = dxR - padTop;\n            const dyCCorner = dxC - padLeft;\n            let dotProd = 0;\n            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n              const dyR = (dyRCorner + wR) / strideHeight;\n              if (dyR < 0 || dyR >= convInfo.outHeight ||\n                  Math.floor(dyR) !== dyR) {\n                continue;\n              }\n              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                const dyC = (dyCCorner + wC) / strideWidth;\n                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                    Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n                const maxPos = effectiveFilterHeight * effectiveFilterWidth -\n                    1 - (maxPosBuf.get(b, dyR, dyC, d) as number);\n                const curPos = wR * effectiveFilterWidth + wC;\n\n                const mask = maxPos === curPos ? 1 : 0;\n                if (mask === 0) {\n                  continue;\n                }\n\n                const pixel = dyBuf.get(b, dyR, dyC, d);\n                dotProd += pixel * mask;\n              }\n            }\n            dx.set(dotProd, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  avgPoolBackprop(dy: Tensor4D, x: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([dy, x], 'avgPoolBackprop');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R4>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      for (let d = 0; d < convInfo.inChannels; ++d) {\n        for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            // Shader code begins.\n            const dyRCorner = dxR - padTop;\n            const dyCCorner = dxC - padLeft;\n            let dotProd = 0;\n            for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n              const dyR = (dyRCorner + wR) / strideHeight;\n              if (dyR < 0 || dyR >= convInfo.outHeight ||\n                  Math.floor(dyR) !== dyR) {\n                continue;\n              }\n              for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                const dyC = (dyCCorner + wC) / strideWidth;\n                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                    Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n\n                const pixel = dyBuf.get(b, dyR, dyC, d);\n                dotProd += pixel;\n              }\n            }\n            dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  private pool3d(\n      x: Tensor5D, convInfo: backend_util.Conv3DInfo,\n      poolType: 'max'|'avg'): Tensor5D {\n    assertNotComplex(x, 'pool3d');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const initialValue =\n        (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                              Number.POSITIVE_INFINITY);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = tf.buffer(convInfo.outShape, x.dtype);\n    const outputVals = output.values;\n\n    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n        convInfo.outShape[3] * convInfo.outShape[4];\n    const outputDepthStrides =\n        convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n    const outputColStrides = convInfo.outShape[4];\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      const outputBatchOffset = batch * outputBatchStrides;\n      const inputBatchOffset = batch * x.strides[0];\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          const outputDepthOffset =\n              outputBatchOffset + yDepth * outputDepthStrides;\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n              // Shader code begins\n              const outputColOffset = outputRowOffset + yCol * outputColStrides;\n              let minMaxValue = initialValue;\n              let avgValue = 0;\n              let count = 0;\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const xDepthOffset = inputBatchOffset + xDepth * x.strides[1];\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const xRowOffset = xDepthOffset + xRow * x.strides[2];\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const xColOffset = xRowOffset + xCol * x.strides[3];\n                    const pixel = xValues[xColOffset + channel];\n                    if ((poolType === 'max' && pixel > minMaxValue)) {\n                      minMaxValue = pixel;\n                    } else if (poolType === 'avg') {\n                      avgValue += pixel;\n                      count++;\n                    }\n                    if (isNaN(minMaxValue)) {\n                      break;\n                    }\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              const outputOffset = outputColOffset + channel;\n              outputVals[outputOffset] =\n                  poolType === 'avg' ? avgValue / count : minMaxValue;\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor5D;\n  }\n\n  avgPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'avgPool3d');\n\n    return this.pool3d(x, convInfo, 'avg').toFloat();\n  }\n\n  avgPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([dy, x], 'avgPool3dBackprop');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins.\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel;\n                  }\n                }\n              }\n              dx.set(\n                  dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol,\n                  channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  maxPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'maxPool3d');\n\n    return this.pool3d(x, convInfo, 'max').toFloat();\n  }\n\n  private maxPool3dPositions(x: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const maxPositions = tf.buffer(convInfo.outShape, 'int32');\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const xBuf = this.bufferSync(x);\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n              // Shader code begins\n              let maxValue = Number.NEGATIVE_INFINITY;\n              let maxPosition = -1;\n\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const wDepth = xDepth - xDepthCorner;\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const wRow = xRow - xRowCorner;\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const wCol = xCol - xColCorner;\n                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                    if (pixel >= maxValue) {\n                      maxValue = pixel;\n                      maxPosition = wDepth * effectiveFilterHeight *\n                              effectiveFilterWidth +\n                          wRow * effectiveFilterHeight + wCol;\n                    }\n                  }\n                }\n              }\n\n              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return maxPositions.toTensor() as Tensor5D;\n  }\n\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([x, y], 'maxPool3dBackprop');\n\n    const maxPositions = this.maxPool3dPositions(x, convInfo);\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const maxPosBuf = this.bufferSync(maxPositions);\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const maxPos = effectiveFilterDepth *\n                            effectiveFilterHeight * effectiveFilterWidth -\n                        1 -\n                        maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    const curPos =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterWidth + wCol;\n\n                    const mask = maxPos === curPos ? 1 : 0;\n                    if (mask === 0) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel * mask;\n                  }\n                }\n              }\n              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  cast<T extends Tensor>(x: T, dtype: DataType): T {\n    return backend_util.castTensor(x, dtype, this);\n  }\n\n  avgPool(x: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex(x, 'avgPool');\n    assertNotComplex(x, 'maxPool');\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    return pool(xValues, x.shape, x.dtype, x.strides, convInfo, 'avg')\n               .toTensor()\n               .toFloat() as Tensor4D;\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeBilinear');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result = new Float32Array(\n        util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    let outputIdx = 0;\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceRowFloor = Math.floor(sourceFracRow);\n        const rowFrac = sourceFracRow - sourceRowFloor;\n        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n        const topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n        const botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceColFloor = Math.floor(sourceFracCol);\n          const colFrac = sourceFracCol - sourceColFloor;\n          const sourceColCeil =\n              Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n          const topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n          const botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n          const topRightOffset = topRowOffset + sourceColCeil * x.strides[2];\n          const botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n\n            // Compute the fractional index of the source.\n            const topLeft = xValues[topLeftOffest + d];\n            const bottomLeft = xValues[botLeftOffset + d];\n            const topRight = xValues[topRightOffset + d];\n            const bottomRight = xValues[botRightOffest + d];\n\n            const top = topLeft + (topRight - topLeft) * colFrac;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            const newValue = top + (bottom - top) * rowFrac;\n\n            result[outputIdx++] = newValue;\n          }\n        }\n      }\n    }\n    return tf.tensor(result, [batch, newHeight, newWidth, numChannels]);\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeBilinearBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass and add the\n    // corresponding coefficient from dy to the gradient (with some\n    // interpolation).\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    let offset = 0;\n    for (let b = 0; b < batch; b++) {\n      const bOffset = b * x.strides[0];\n      for (let r = 0; r < yHeight; r++) {\n        const dxR = r * heightScale;\n        const topDxRIndex = Math.floor(dxR);\n        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n        const topDxROffset = bOffset + topDxRIndex * x.strides[1];\n        const bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n\n        const dxRLerp = dxR - topDxRIndex;\n        const inverseDxRLerp = 1.0 - dxRLerp;\n        for (let c = 0; c < yWidth; c++) {\n          const dxC = c * widthScale;\n          const leftDxCIndex = Math.floor(dxC);\n          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n          const dxCLerp = dxC - leftDxCIndex;\n          const inverseDxCLerp = 1.0 - dxCLerp;\n\n          const topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n          const topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n          const bottomLeftRCOffset =\n              bottomDxROffset + leftDxCIndex * x.strides[2];\n          const bottomRightRCOffset =\n              bottomDxROffset + rightDxCIndex * x.strides[2];\n\n          const inverseDxRLerpTimesInverseDxCLerp =\n              inverseDxRLerp * inverseDxCLerp;\n          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n          for (let d = 0; d < depth; d++) {\n            const dyVal = dyValues[offset++];\n            output[topLeftRCOffset + d] +=\n                dyVal * inverseDxRLerpTimesInverseDxCLerp;\n            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n            output[bottomLeftRCOffset + d] +=\n                dyVal * dxRLerpTimesInverseDxCLerp;\n            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeNearestNeighbor');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n\n    let outputOffset = 0;\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceNearestRow = Math.min(\n            oldHeight - 1,\n            alignCorners ? Math.round(sourceFracRow) :\n                           Math.floor(sourceFracRow));\n        const rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceNearestCol = Math.min(\n              oldWidth - 1,\n              alignCorners ? Math.round(sourceFracCol) :\n                             Math.floor(sourceFracCol));\n          const colOffset = rowOffset + sourceNearestCol * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n            // Compute the fractional index of the source.\n            const newVal = xValues[colOffset + d];\n            output[outputOffset++] = newVal;\n          }\n        }\n      }\n    }\n    return tf.tensor(\n        output, [batch, newHeight, newWidth, numChannels], x.dtype);\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    const invHeightScale = 1 / heightScale;\n    const invWidthScale = 1 / widthScale;\n\n    // This defines the size of the window of values around a particular\n    // index in dy that we want to search for contributions to dx.\n    const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n    const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n    // Loop over the output space.\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < xHeight; r++) {\n        const rowOffset = batchOffset + r * x.strides[1];\n\n        // Compute bounds for where in dy we will look\n        const startRLerp = Math.floor(r * invHeightScale);\n        const startDyR = Math.floor(startRLerp - (winHeight / 2));\n        for (let c = 0; c < xWidth; c++) {\n          const colOffset = rowOffset + c * x.strides[2];\n\n          // Compute bounds for where in dy we will look\n          const startCLerp = Math.floor(c * invWidthScale);\n          const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n          for (let d = 0; d < depth; d++) {\n            let accum = 0;\n            // loop over dy\n\n            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n              const dyR = dyRIndex + startDyR;\n              // Guard against the window exceeding the bounds of dy\n              if (dyR < 0 || dyR >= yHeight) {\n                continue;\n              }\n\n              const dyROffset = batchOffset + dyR * dy.strides[1];\n              const sourceFracRow = dyR * heightScale;\n              const sourceNearestRow = Math.min(\n                  xHeight - 1,\n                  alignCorners ? Math.round(sourceFracRow) :\n                                 Math.floor(sourceFracRow));\n              if (r !== sourceNearestRow) {\n                continue;\n              }\n              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                const dyC = dyCIndex + startDyC;\n                // Guard against the window exceeding the bounds of dy\n                if (dyC < 0 || dyC >= yWidth) {\n                  continue;\n                }\n\n                const dyCOffset = dyROffset + dyC * dy.strides[2];\n                const sourceFracCol = dyC * widthScale;\n                const sourceNearestCol = Math.min(\n                    xWidth - 1,\n                    alignCorners ? Math.round(sourceFracCol) :\n                                   Math.floor(sourceFracCol));\n\n                if (c === sourceNearestCol) {\n                  accum += dyValues[dyCOffset + d];\n                }\n              }\n            }\n            output[colOffset + d] = accum;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, x.shape, x.dtype);\n  }\n\n  batchNorm(\n      x: Tensor4D, mean: Tensor4D|Tensor1D, variance: Tensor4D|Tensor1D,\n      offset?: Tensor4D|Tensor1D, scale?: Tensor4D|Tensor1D,\n      varianceEpsilon?: number): Tensor4D {\n    assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const mVals = this.readSync(mean.dataId) as TypedArray;\n    const varVals = this.readSync(variance.dataId) as TypedArray;\n    const sVals = scale ? this.readSync(scale.dataId) as TypedArray :\n                          new Float32Array([1]);\n    const offVals = offset ? this.readSync(offset.dataId) as TypedArray :\n                             new Float32Array([0]);\n    const outVals = new Float32Array(xVals.length);\n\n    const offValsLength = offVals.length;\n    const sValsLength = sVals.length;\n    const varValsLength = varVals.length;\n    const mValsLength = mVals.length;\n\n    let offi = 0;\n    let mi = 0;\n    let si = 0;\n    let vi = 0;\n    for (let i = 0; i < xVals.length; ++i) {\n      outVals[i] = offVals[offi++] +\n          (xVals[i] - mVals[mi++]) * sVals[si++] /\n              Math.sqrt(varVals[vi++] + varianceEpsilon);\n      if (offi >= offValsLength) {\n        offi = 0;\n      }\n      if (mi >= mValsLength) {\n        mi = 0;\n      }\n      if (si >= sValsLength) {\n        si = 0;\n      }\n      if (vi >= varValsLength) {\n        vi = 0;\n      }\n    }\n    return tf.tensor4d(outVals, x.shape);\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(x, 'localResponseNormalization4D');\n\n    const channels = x.shape[3];\n    const maxD = channels - 1;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const size = x.size;\n    const result = new Float32Array(size);\n\n    function sumAcrossChannels(offset: number) {\n      const currentChannel = offset % channels;\n      let beginSumOffset =\n          offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n      const endSumOffset = offset - currentChannel +\n          Math.min(currentChannel + depthRadius, maxD);\n\n      let sum = 0.0;\n      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n        const z = xValues[beginSumOffset];\n        sum += z * z;\n      }\n      return sum;\n    }\n\n    for (let offset = 0; offset < size; offset++) {\n      const sum = sumAcrossChannels(offset);\n      const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n      result[offset] = val;\n    }\n\n    return tf.tensor4d(result, x.shape);\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D,\n      depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(dy, 'LRNGrad');\n    const channels = dy.shape[3];\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const inputImageValues = this.readSync(inputImage.dataId) as TypedArray;\n    const outputImageValues = this.readSync(outputImage.dataId) as TypedArray;\n    const result = new Float32Array(dy.size);\n    const size = dy.size;\n\n    for (let offset = 0; offset < size; offset++) {\n      const currentChannel = offset % channels;\n      const depthBegin =\n          (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n      const depthEnd = (offset - currentChannel) +\n          Math.min(channels, currentChannel + depthRadius + 1);\n\n      let norm = 0;\n      for (let k = depthBegin; k < depthEnd; k++) {\n        norm += Math.pow(inputImageValues[k], 2);\n      }\n      norm = alpha * norm + bias;\n\n      for (let k = depthBegin; k < depthEnd; k++) {\n        let dyi = -2 * alpha * beta * inputImageValues[k] *\n            outputImageValues[offset] / norm;\n        if (offset === k) {\n          dyi += Math.pow(norm, -beta);\n        }\n        dyi *= dyValues[offset];\n        result[k] += dyi;\n      }\n    }\n    return tf.tensor4d(result, dy.shape);\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    assertNotComplex(logits, 'multinomial');\n\n    const probabilities = normalized ? logits : tf.softmax(logits);\n    const batchSize = probabilities.shape[0];\n    const numEvents = probabilities.shape[1];\n    const res = tf.zeros<Rank.R2>([batchSize, numSamples], 'int32');\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const probVals = this.readSync(probabilities.dataId) as TypedArray;\n\n    for (let b = 0; b < batchSize; ++b) {\n      const offset = b * numEvents;\n      // The cdf won't include the last event. It will be implicit if no other\n      // event happened.\n      const cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n      for (let event = 1; event < cdf.length; ++event) {\n        cdf[event] = cdf[event - 1] + probVals[offset + event];\n      }\n\n      const random = seedrandom.alea(seed.toString());\n      const outOffset = b * numSamples;\n      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n        const r = random();\n\n        // Assume last event happened by default.\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (let event = 0; event < cdf.length; event++) {\n          if (r < cdf[event]) {\n            resVals[outOffset + sampleId] = event;\n            break;\n          }\n        }\n      }\n    }\n    return res;\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    assertNotComplex(indices, 'oneHot');\n\n    const res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n    const indicesVal = this.readSync(indices.dataId) as TypedArray;\n\n    for (let event = 0; event < indices.size; ++event) {\n      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n        res[event * depth + indicesVal[event]] = onValue;\n      }\n    }\n    return tf.tensor2d(res, [indices.size, depth], 'int32');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold: number): Tensor1D {\n    assertNotComplex(boxes, 'nonMaxSuppression');\n\n    const boxesVals = this.readSync(boxes.dataId) as TypedArray;\n    const scoresVals = this.readSync(scores.dataId) as TypedArray;\n    return nonMaxSuppressionV3Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n  }\n\n  fft(x: Tensor2D): Tensor2D {\n    return this.fftBatch(x, false);\n  }\n\n  ifft(x: Tensor2D): Tensor2D {\n    return this.fftBatch(x, true);\n  }\n\n  /**\n   * Calculate FFT of inner most elements of batch tensor.\n   */\n  private fftBatch(x: Tensor2D, inverse: boolean): Tensor2D {\n    const batch = x.shape[0];\n    const innerDim = x.shape[1];\n    // Collects real and imaginary values separately.\n    const realResult = tf.buffer(x.shape, 'float32');\n    const imagResult = tf.buffer(x.shape, 'float32');\n\n    const real = tf.real(x).as2D(batch, innerDim);\n    const imag = tf.imag(x).as2D(batch, innerDim);\n\n    for (let b = 0; b < batch; b++) {\n      // TODO: Support slice ops for complex type.\n      const r = real.slice([b, 0], [1, innerDim]);\n      const i = imag.slice([b, 0], [1, innerDim]);\n      const input = tf.complex(r, i);\n      // Run FFT by batch element.\n      const res =\n          this.readSync(this.fftImpl(input, inverse).dataId) as Float32Array;\n      for (let d = 0; d < innerDim; d++) {\n        const c = backend_util.getComplexWithIndex(res, d);\n        realResult.values[b * innerDim + d] = c.real;\n        imagResult.values[b * innerDim + d] = c.imag;\n      }\n    }\n\n    const t = tf.complex(realResult.toTensor(), imagResult.toTensor());\n    return t.as2D(batch, innerDim);\n  }\n\n  private fftImpl(x: Tensor2D, inverse: boolean): Tensor2D {\n    const x1D = x.as1D();\n\n    const n = x1D.size;\n\n    if (this.isExponentOf2(n)) {\n      let result = this.fftRadix2(x1D, n, inverse).as2D(x.shape[0], x.shape[1]);\n      if (inverse) {\n        result = tf.complex(\n                     tf.real(result).div(tf.scalar(n)),\n                     tf.imag(result).div(tf.scalar(n))) as Tensor2D;\n      }\n      return result;\n    } else {\n      const data = this.readSync(x.dataId) as TypedArray;\n      const rawOutput =\n          this.fourierTransformByMatmul(data, n, inverse) as Float32Array;\n      const output = backend_util.splitRealAndImagArrays(rawOutput);\n      return tf.complex(output.real, output.imag).as2D(x.shape[0], x.shape[1]);\n    }\n  }\n\n  private isExponentOf2(size: number): boolean {\n    return (size & size - 1) === 0;\n  }\n\n  // FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\n  private fftRadix2(input: Tensor1D, size: number, inverse: boolean): Tensor1D {\n    if (size === 1) {\n      return input;\n    }\n    const data = this.readSync(input.dataId) as TypedArray as Float32Array;\n    const half = size / 2;\n    const evenComplex = backend_util.complexWithEvenIndex(data);\n    let evenTensor = tf.complex(evenComplex.real, evenComplex.imag).as1D();\n    const oddComplex = backend_util.complexWithOddIndex(data);\n    let oddTensor = tf.complex(oddComplex.real, oddComplex.imag).as1D();\n\n    // Recursive call for half part of original input.\n    evenTensor = this.fftRadix2(evenTensor, half, inverse);\n    oddTensor = this.fftRadix2(oddTensor, half, inverse);\n\n    const e = backend_util.exponents(size, inverse);\n    const exponent = tf.complex(e.real, e.imag).mul(oddTensor);\n\n    const addPart = evenTensor.add(exponent);\n    const subPart = evenTensor.sub(exponent);\n\n    const realTensor = tf.real(addPart).concat(tf.real(subPart));\n    const imagTensor = tf.imag(addPart).concat(tf.imag(subPart));\n\n    return tf.complex(realTensor, imagTensor).as1D();\n  }\n\n  // Calculate fourier transform by multplying sinusoid matrix.\n  private fourierTransformByMatmul(\n      data: TypedArray, size: number, inverse: boolean): TypedArray {\n    const ret = new Float32Array(size * 2);\n    // TODO: Use matmul instead once it supports complex64 type.\n    for (let r = 0; r < size; r++) {\n      let real = 0.0;\n      let imag = 0.0;\n      for (let c = 0; c < size; c++) {\n        const e = backend_util.exponent(r * c, size, inverse);\n        const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n        real += term.real * e.real - term.imag * e.imag;\n        imag += term.real * e.imag + term.imag * e.real;\n      }\n      if (inverse) {\n        real /= size;\n        imag /= size;\n      }\n      backend_util.assignToTypedArray(ret, real, imag, r);\n    }\n    return ret;\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: 'NHWC'|'NCHW'):\n      Tensor4D {\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n            dataFormat}`);\n    util.assert(\n        blockSize > 1,\n        () =>\n            `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n    const batchSize = x.shape[0];\n    const inputHeight = x.shape[1];\n    const inputWidth = x.shape[2];\n    const inputDepth = x.shape[3];\n\n    const outputHeight = inputHeight * blockSize;\n    const outputWidth = inputWidth * blockSize;\n    const outputDepth = inputDepth / (blockSize * blockSize);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result =\n        new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n    let outputIdx = 0;\n    for (let b = 0; b < batchSize; ++b) {\n      for (let h = 0; h < outputHeight; ++h) {\n        const inH = Math.floor(h / blockSize);\n        const offsetH = (h % blockSize);\n        for (let w = 0; w < outputWidth; ++w) {\n          const inW = Math.floor(w / blockSize);\n          const offsetW = (w % blockSize);\n          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n          for (let d = 0; d < outputDepth; ++d) {\n            const inD = d + offsetD;\n            const inputIdx =\n                inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n            result[outputIdx++] = xValues[inputIdx];\n          }\n        }\n      }\n    }\n    return tf.tensor4d(\n        result, [batchSize, outputHeight, outputWidth, outputDepth]);\n  }\n\n  private broadcastedBinaryOp(\n      a: Tensor, b: Tensor, dtype: DataType,\n      op: (a: number, b: number) => number): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const result = tf.buffer(newShape, dtype);\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const resVals = result.values;\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resVals.length; ++i) {\n        resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      const aBuf = this.bufferSync(a);\n      const bBuf = this.bufferSync(b);\n      for (let i = 0; i < resVals.length; ++i) {\n        const loc = result.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bBuf.locToIndex(bLoc);\n\n        resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n    return result.toTensor();\n  }\n\n  private broadcastedBinaryComplexOp(\n      a: Tensor, b: Tensor,\n      op:\n          (aReal: number, aImag: number, bReal: number,\n           bImag: number) => {real: number, imag: number}): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const realResult = tf.buffer(newShape, 'float32');\n    const imagResult = tf.buffer(newShape, 'float32');\n\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const realVals = realResult.values;\n    const imagVals = imagResult.values;\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < realVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        realVals[i] = result.real;\n        imagVals[i] = result.imag;\n      }\n    } else {\n      const aRealBuf =\n          this.bufferSync(this.data.get(a.dataId).complexTensors.real);\n      const bRealBuf =\n          this.bufferSync(this.data.get(b.dataId).complexTensors.real);\n      for (let i = 0; i < realVals.length; i++) {\n        const loc = realResult.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aRealBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bRealBuf.locToIndex(bLoc);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        realVals[i] = opResult.real;\n        imagVals[i] = opResult.imag;\n      }\n    }\n    return this.complex(realResult.toTensor(), imagResult.toTensor());\n  }\n\n  split<T extends Tensor>(x: T, sizeSplits: number[], axis: number): T[] {\n    return split(x, sizeSplits, axis);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n\n  cropAndResize(\n      images: Tensor4D,\n      boxes: Tensor2D,\n      boxIndex: Tensor1D,\n      cropSize: [number, number],\n      method: string,\n      extrapolationValue: number,\n  ) {\n    const [batch, imageHeight, imageWidth, numChannels] = images.shape;\n    const numBoxes = boxes.shape[0];\n\n    const [cropHeight, cropWidth] = cropSize;\n    const output =\n        tf.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n    const boxVals = this.readSync(boxes.dataId) as TypedArray;\n    const boxIndVals = this.readSync(boxIndex.dataId) as TypedArray;\n    const imageVals = this.readSync(images.dataId) as TypedArray;\n\n    const inStride = images.strides;   // to calculate flat indexes into image\n    const outStride = output.strides;  // to calculate flat indexes into output\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n    for (let b = 0; b < numBoxes; b++) {\n      const startInd = b * 4;\n      const y1 = boxVals[startInd];\n      const x1 = boxVals[startInd + 1];\n      const y2 = boxVals[startInd + 2];\n      const x2 = boxVals[startInd + 3];\n\n      const bInd: number = boxIndVals[b];\n      if (bInd >= batch) {\n        continue;\n      }\n\n      const heightScale = (cropHeight > 1) ?\n          (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n          0;\n      const widthScale =\n          (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n      for (let y = 0; y < cropHeight; y++) {\n        const yInd: number = (cropHeight > 1) ?\n            y1 * (imageHeight - 1) + y * (heightScale) :\n            0.5 * (y1 + y2) * (imageHeight - 1);\n\n        if (yInd < 0 || yInd > imageHeight - 1) {\n          for (let x = 0; x < cropWidth; x++) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n          }\n          continue;\n        }\n\n        if (method === 'bilinear') {\n          const topInd = Math.floor(yInd);\n          const bottomInd = Math.ceil(yInd);\n          const yLerp = yInd - topInd;\n\n          for (let x = 0; x < cropWidth; x++) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const leftInd = Math.floor(xInd);\n            const rightInd = Math.ceil(xInd);\n            const xLerp = xInd - leftInd;\n\n            for (let c = 0; c < numChannels; c++) {\n              let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topRight = imageVals[ind];\n\n              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomRight = imageVals[ind];\n\n              const top = topLeft + (topRight - topLeft) * xLerp;\n              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = top + ((bottom - top) * yLerp);\n            }\n          }\n        } else {  // method == \"nearest\"\n          for (let x = 0; x < cropWidth; ++x) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const closestX = Math.round(xInd);\n            const closestY = Math.round(yInd);\n            for (let c = 0; c < numChannels; c++) {\n              const inInd = c + closestX * inStride[2] +\n                  closestY * inStride[1] + bInd * inStride[0];\n              const outInd =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[outInd] = imageVals[inInd];\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor4D;\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n    const sumDupeIndices = false;\n    return this.scatter(\n        sparseIndices, sparseValues, outputShape, outputSize, sliceSize,\n        numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n\n    const [resultShape, numSlices, sliceSize, strides] =\n        backend_util.prepareAndValidate(x, indices);\n    if (numSlices === 0) {\n      return tf.tensor([], resultShape, x.dtype);\n    }\n\n    const buffer = new TensorBuffer([numSlices, sliceSize], x.dtype);\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const xData = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < numSlices; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        flattenIndex += dim * strides[j];\n        index.push(dim);\n      }\n      if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${x.shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n      }\n    }\n    return buffer.toTensor().reshape(resultShape);\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(updates, indices, shape);\n    const defaultValue = tf.scalar(0);\n    const sumDupeIndices = true;\n    return this.scatter(\n        indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank,\n        strides, defaultValue, sumDupeIndices);\n  }\n\n  fill<R extends Rank>(\n      shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n    dtype = dtype || util.inferDtype(value);\n    const values =\n        util.getArrayFromDType(dtype, util.sizeFromShape(shape)) as TypedArray;\n    values.fill(value as number);\n    return engine().makeTensor(values, shape, dtype, this) as Tensor<R>;\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    if (x.dtype === 'string') {\n      throw new Error('onesLike is not supported for string tensors');\n    } else {\n      return this.fill(x.shape, 1, x.dtype);\n    }\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    const values = util.getArrayFromDType(\n                       x.dtype, util.sizeFromShape(x.shape)) as TypedArray;\n    return this.makeOutput(values, x.shape, x.dtype);\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return backend_util.linspaceImpl(start, stop, num);\n  }\n\n  private scatter<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R], outputSize: number,\n      sliceSize: number, numUpdates: number, sliceRank: number,\n      strides: number[], defaultValue: Scalar,\n      sumDupeIndices: boolean): Tensor<R> {\n    const flattenShape = [outputSize / sliceSize, sliceSize];\n\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const updatesData = this.readSync(updates.dataId) as TypedArray;\n\n    if (outputSize === 0) {\n      return tf.tensor([], shape, updates.dtype);\n    }\n\n    const buffer = new TensorBuffer(flattenShape, updates.dtype as 'float32');\n    buffer.values.fill((this.readSync(defaultValue.dataId) as TypedArray)[0]);\n\n    for (let i = 0; i < numUpdates; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        index.push(dim);\n        flattenIndex += dim * strides[j];\n      }\n\n      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        if (sumDupeIndices) {\n          buffer.values[flattenIndex * sliceSize + k] +=\n              updatesData[i * sliceSize + k];\n        } else {\n          buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n              updatesData[0] :\n              updatesData[i * sliceSize + k];\n        }\n      }\n    }\n    return buffer.toTensor().reshape(shape);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, CosInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as CosInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'cos');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xSize = util.sizeFromShape(x.shape);\n    const newValues = new Float32Array(xSize);\n    for (let i = 0; i < xSize; ++i) {\n      newValues[i] = Math.cos(values[i]);\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BinaryInputs, KernelConfig} from '@tensorflow/tfjs-core';\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util} from '@tensorflow/tfjs-core';\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function createBinaryKernelConfig(\n    name: string,\n    op: (\n        aShape: number[], bShape: number[], aVals: TypedArray,\n        bVals: TypedArray,\n        dtype: DataType) => [TypedArray, number[]]): KernelConfig {\n  return {\n    kernelName: name,\n    backendName: 'cpu',\n    kernelFunc: ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const [resultData, resultShape] =\n          op(a.shape, b.shape, aVals, bVals, a.dtype);\n\n      const dataId = cpuBackend.write(resultData, resultShape, a.dtype);\n      return {dataId, shape: resultShape, dtype: a.dtype};\n    }\n  };\n}\n\nexport function createBinaryKernelImpl(op: (a: number, b: number) => number) {\n  return (aShape: number[], bShape: number[], aVals: TypedArray,\n          bVals: TypedArray, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {createBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const divImpl = createBinaryKernelImpl((a: number, b: number) => a / b);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Div} from '@tensorflow/tfjs-core';\nimport {createBinaryKernelConfig} from '../utils/kernel_utils';\nimport {divImpl} from './Div_impl';\n\nexport const divConfig = createBinaryKernelConfig(Div, divImpl);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n\n            const coordX = Math.round(imageWidth - x);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Max, MaxAttrs, MaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxInputs;\n    const {reductionIndices, keepDims} = attrs as {} as MaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    let xShape = x.shape;\n    const xRank = xShape.length;\n\n    const origAxes = util.parseAxisParam(reductionIndices, xShape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    if (permutedAxes != null) {\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = xShape[permutedAxes[i]];\n      }\n\n      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n      axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n      xShape = newShape;\n    }\n\n    assertNotComplex(x, 'max');\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(xShape, axes);\n\n    const reduceSize = util.sizeFromShape(reduceShape);\n\n    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n    let outShape = maxOutShape;\n    if (keepDims) {\n      // reshape\n      const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n      outShape = newShape;\n    }\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV4Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n        attrs as unknown as NonMaxSuppressionV4Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n        padToMaxOutputSize);\n\n    return [selectedIndices, validOutputs];\n  }\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV5Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} =\n        attrs as unknown as NonMaxSuppressionV5Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const maxOutputSizeVal = maxOutputSize;\n    const iouThresholdVal = iouThreshold;\n    const scoreThresholdVal = scoreThreshold;\n    const softNmsSigmaVal = softNmsSigma;\n\n    const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n        boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n        scoreThresholdVal, softNmsSigmaVal);\n\n    return [selectedIndices, selectedScores];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {SquaredDifference} from '@tensorflow/tfjs-core';\nimport {createBinaryKernelImpl} from '../utils/kernel_utils';\nimport {createBinaryKernelConfig} from '../utils/kernel_utils';\n\nconst squaredDifferenceImpl = createBinaryKernelImpl((aVal, bVal) => {\n  const diff = aVal - bVal;\n  return diff * diff;\n});\n\nexport const squaredDifferenceConfig =\n    createBinaryKernelConfig(SquaredDifference, squaredDifferenceImpl);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {cosConfig} from './kernels/Cos';\nimport {dilation2dConfig} from './kernels/Dilation2D';\nimport {dilation2dBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2dBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {divConfig} from './kernels/Div';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {identityConfig} from './kernels/Identity';\nimport {maxConfig} from './kernels/Max';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {padV2Config} from './kernels/PadV2';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {transposeConfig} from './kernels/Transpose';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  cosConfig, dilation2dConfig, dilation2dBackpropInputConfig,\n  dilation2dBackpropFilterConfig, divConfig, flipLeftRightConfig,\n  identityConfig, maxPoolWithArgmaxConfig, maxConfig, nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config, padV2Config, reshapeConfig, rotateWithOffsetConfig,\n  spaceToBatchNDConfig, squareConfig, squaredDifferenceConfig, transposeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.4.0';\nexport {version};\n"],"names":["assertNotComplex","tensor","opName","Array","isArray","forEach","t","util","assert","dtype","pool","xValues","xShape","strides","convInfo","poolType","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","effectiveFilterWidth","padTop","padInfo","top","padLeft","left","initialValue","Number","NEGATIVE_INFINITY","POSITIVE_INFINITY","output","buffer","outShape","outputVals","values","outputBatchStrides","outputRowStrides","outputColStrides","b","batchSize","outputBatchOffset","inputBatchOffset","d","inChannels","yR","outHeight","xRCorner","xRMin","Math","max","xRMax","min","inHeight","outputRowOffset","yC","outWidth","xCCorner","xCMin","xCMax","inWidth","minMaxValue","avgValue","count","xR","xROffset","xC","pixel","isNaN","maxPoolPositions","flattenPositions","includeBatchInIndex","maxPositions","xBuf","maxValue","maxPosition","wR","wC","get","set","nonMaxSuppressionV3Impl","kernel_impls","split","tile","topkImpl","whereImpl","mapActivation","backend","x","activation","preluActivationWeights","linear","relu","elu","relu6","prelu","Error","MathBackendCPU","KernelBackend","[object Object]","super","this","data","DataStorage","engine","shape","firstUse","env","backend_util","warn","dataId","refCount","has","numDataIds","readSync","complexTensors","realValues","real","imagValues","imag","mergeRealAndImagArrays","decodedData","map","decodeString","tf.buffer","write","makeTensorFromDataId","dispose","delete","tensorInfo","tensorData","disposeData","f","start","now","kernelMs","unreliable","reasons","result","makeOutput","keep","clone","input","begin","size","slice_util","isSliceContinous","flatOffset","computeFlatOffset","length","sizeFromShape","vals","tf.tensor","subarray","bufferSync","i","xLoc","indexToLoc","idx","j","toTensor","end","computeOutShape","some","axis","loc","newLoc","xVals","num","rank","outIndex","fill","slice","res","reshape","outLoc","inLoc","ax","tensors","reals","tf.real","imags","tf.imag","tf.complex","concat","tensors2D","innerSize","as2D","offset","colOffset","tVals","tIdx","row","resIdx","col","finalOutShape","multiply","tf.scalar","a","broadcastedBinaryComplexOp","cast","aReal","aImag","bReal","bImag","broadcastedBinaryOp","upcastType","aValue","bValue","resultVals","currVals","logits","dim","axes","parseAxisParam","maxLogit","expandedShape","expandShapeToKeepDim","subtract","exp","sumExp","sum","tf.div","pow","transposeA","transposeB","sharedDim","leftDim","rightDim","batchDim","aValues","bValues","aBatch","aOuterStep","aInnerStep","bInnerStep","bOuterStep","bBatch","resVals","blockSize","i0","j0","k0","iBlock","jBlock","kBlock","k","bias","batchMatMul","add","floor","assertAxesAreInnerMostDims","reduceShape","computeOutAndReduceShapes","resultDtype","tf.zeros","reduceSize","aVals","prod","segmentIds","numSegments","numIters","expandDims","segmentId","tf.equal","asType","mul","push","tf.stack","minIndex","value","maxIndex","exclusive","reverse","finalDim","indexAdjuster","prevIdx","aVal","bVal","newValues","Uint8Array","condition","index","condVals","sorted","rem","all","anyVal","diff","Float32Array","ceil","abs","Infinity","isFinite","base","expm1","log","log1p","sqrt","inVals","xValue","resultValues","v","dy","y","dyValues","scaleAlpha","SELU_SCALEALPHA","scale","SELU_SCALE","hypot","Int32Array","threshold","tooLarge","tooSmall","expX","sin","tan","asin","acos","atan","atan2","sinh","cosh","tanh","asinh","acosh","atanh","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","sign","alpha","NaN","filter","conv2d","filterHeight","filterWidth","isChannelsLast","dataFormat","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","xOffset1","yOffset1","yOffset2","wOffset1","xOffset2","yOffset3","xOffset3","wOffset3","d1","xVal","d2","outChannels","filterDepth","dilationDepth","padFront","front","yF","outDepth","xFCorner","strideDepth","wF","xF","inDepth","wOffset2","yOffset4","xOffset4","wOffset4","dx","inShape","dxValues","fltValues","fltS0","fltS1","fltS2","topPad","leftPad","yRMax","yCMax","dotProd","dyOffset","fltOffset","dxS0","dxS1","dxS2","dxS3","dyS0","dyS1","dyS2","dyS3","fltS3","frontPad","xFMin","yFMax","dW","filterShape","dyBuf","yRMin","yCMin","dw","dwValues","dwS0","dwS1","dwS2","dwS3","xS0","xS1","xS2","xS3","yFMin","depthwiseConv2D","chMul","q","dm","trunc","reps","indices","newShape","indicesValues","originalLoc","originalIndex","locToIndex","blockShape","crops","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","tf.transpose","maxPosBuf","dxR","dxC","dyRCorner","dyCCorner","dyR","dyC","mask","avgMultiplier","effectiveFilterDepth","outputDepthStrides","batch","channel","yDepth","xDepthCorner","xDepthMin","xDepthMax","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","yCol","xColCorner","xColMin","xColMax","outputColOffset","xDepth","xDepthOffset","xRow","xRowOffset","xCol","pool3d","toFloat","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","maxPool3dPositions","castTensor","newHeight","newWidth","alignCorners","oldHeight","oldWidth","numChannels","effectiveInputSize","effectiveOutputSize","outputIdx","effectiveRowSizeRatio","effectiveColSizeRatio","r","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","c","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","topLeft","bottomLeft","newValue","xHeight","xWidth","depth","yHeight","yWidth","effectiveXSize","effectiveYSize","heightScale","widthScale","bOffset","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","tf.tensor4d","outputOffset","batchOffset","rowOffset","round","newVal","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyROffset","dyCIndex","dyCOffset","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","outVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","depthRadius","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","z","val","inputImage","outputImage","inputImageValues","outputImageValues","depthBegin","depthEnd","norm","dyi","normalized","numSamples","seed","probabilities","tf.softmax","numEvents","probVals","cdf","event","random","seedrandom.alea","toString","outOffset","sampleId","onValue","offValue","indicesVal","tf.tensor2d","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","fftBatch","inverse","innerDim","realResult","imagResult","fftImpl","getComplexWithIndex","x1D","as1D","n","isExponentOf2","fftRadix2","div","rawOutput","fourierTransformByMatmul","splitRealAndImagArrays","half","evenComplex","complexWithEvenIndex","evenTensor","oddComplex","complexWithOddIndex","oddTensor","e","exponents","exponent","addPart","subPart","sub","realTensor","imagTensor","ret","term","assignToTypedArray","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","h","inH","offsetH","w","inW","offsetD","inputIdx","op","assertAndGetBroadcastShape","bVals","aBroadcastDims","getBroadcastDims","bBroadcastDims","aBuf","bBuf","aLoc","aIndex","bLoc","bIndex","realVals","imagVals","aIdx","bIdx","aRealBuf","bRealBuf","opResult","complex","sizeSplits","epsilon","images","boxIndex","cropSize","method","extrapolationValue","imageHeight","imageWidth","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topRight","bottom","closestX","closestY","inInd","outInd","sparseIndices","sparseValues","outputShape","defaultValue","sliceRank","numUpdates","outputSize","calculateShapes","scatter","indicesShape","resultShape","numSlices","prepareAndValidate","TensorBuffer","indicesData","xData","flattenIndex","updates","inferDtype","getArrayFromDType","makeTensor","stop","linspaceImpl","sumDupeIndices","flattenShape","updatesData","maxImpl","getTypedArrayFromDType","transposeImpl","perm","xRank","xSize","xStrides","computeStrides","newStrides","cosConfig","kernelName","Cos","backendName","kernelFunc","inputs","cpuBackend","cos","dilation2dConfig","Dilation2D","attrs","pad","dilations","filterVals","filterRank","computeDilation2DInfo","outSize","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","xIndex","filterIndex","toTypedArray","dilation2dBackpropFilterConfig","Dilation2DBackpropFilter","$x","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2dBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","createBinaryKernelConfig","name","resultData","createBinaryKernelImpl","aShape","bShape","resultRank","resultStrides","resultSize","aRank","bRank","aStrides","bStrides","divImpl","divConfig","Div","flipLeftRightConfig","FlipLeftRight","image","batchIdx","coordX","outIdx","outputValue","identityConfig","Identity","args","incRef","maxConfig","Max","reductionIndices","keepDims","origAxes","permutedAxes","getAxesPermutation","getInnerMostAxes","maxOutShape","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","filterSize","computePool2DInfo","pooled","indexes","maxPools","maxPoolWithArgmaxImpl","pooledDataId","indexesDataId","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","selectedIndices","validOutputs","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","maxOutputSizeVal","iouThresholdVal","scoreThresholdVal","softNmsSigmaVal","selectedScores","padV2Config","PadV2","paddings","constantValue","outCoords","reshapeConfig","Reshape","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","getImageCenter","sinFactor","cosFactor","coords","coordY","transpose","transposeConfig","Transpose","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","disposeIntermediateTensorInfo","squareConfig","Square","squaredDifferenceImpl","squaredDifferenceConfig","SquaredDifference","kernelConfigs","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;iUAmBgBA,EACZC,EAAiCC,GAC9BC,MAAMC,QAAQH,KACjBA,EAAS,CAACA,IAEZA,EAAOI,QAAQC,IACJ,MAALA,GACFC,OAAKC,OACW,cAAZF,EAAEG,MACF,IAAM,GACFP,uECVEQ,EACZC,EAAqBC,EAAkBH,EAAiBI,EACxDC,EACAC,GACF,MAAMC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BC,EACY,QAAbZ,EAAqBa,OAAOC,kBACPD,OAAOE,kBAE3BC,EAASC,SAAOlB,EAASmB,SAAUxB,GACnCyB,EAAaH,EAAOI,OAEpBC,EACFtB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAC9DI,EAAmBvB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAC5DK,EAAmBxB,EAASmB,SAAS,GAE3C,IAAK,IAAIM,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EAAG,CAC3C,MAAME,EAAoBF,EAAIH,EACxBM,EAAmBH,EAAI1B,EAAQ,GACrC,IAAK,IAAI8B,EAAI,EAAGA,EAAI7B,EAAS8B,aAAcD,EACzC,IAAK,IAAIE,EAAK,EAAGA,EAAK/B,EAASgC,YAAaD,EAAI,CAC9C,MAAME,EAAWF,EAAK7B,EAAeM,EAC/B0B,EAAQC,KAAKC,IAAI,EAAGH,GACpBI,EACFF,KAAKG,IAAItC,EAASuC,SAAUjC,EAAwB2B,GAClDO,EAAkBb,EAAoBI,EAAKR,EACjD,IAAK,IAAIkB,EAAK,EAAGA,EAAKzC,EAAS0C,WAAYD,EAAI,CAC7C,MAAME,EAAWF,EAAKtC,EAAcQ,EAC9BiC,EAAQT,KAAKC,IAAI,EAAGO,GACpBE,EACFV,KAAKG,IAAItC,EAAS8C,QAASvC,EAAuBoC,GACtD,IAAII,EAAclC,EACdmC,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAIC,EAAKhB,EAAOgB,EAAKb,EAAOa,GAAM9C,EAAgB,CACrD,MAAM+C,EAAWvB,EAAmBsB,EAAKnD,EAAQ,GACjD,IAAK,IAAIqD,EAAKR,EAAOQ,EAAKP,EAAOO,GAAM/C,EAAe,CACpD,MACMgD,EAAQxD,EADGsD,EAAWC,EAAKrD,EAAQ,GACR8B,GACf,QAAb5B,GAAsBoD,EAAQN,EACjCA,EAAcM,EACQ,QAAbpD,IACT+C,GAAYK,EACZJ,KAGJ,GAAIK,MAAMP,GACR,MAIJ3B,EADqBoB,EAAkBC,EAAKjB,EAAmBK,GAE9C,QAAb5B,EAAqB+C,EAAWC,EAAQF,IAKpD,OAAO9B,WAGOsC,EACZ1D,EAAqBC,EAAkBH,EACvCK,EAAmCwD,GAAmB,EACtDC,GAAsB,GACxB,MAAMC,EAAexC,SAAOlB,EAASmB,SAAU,SACzCjB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3B+C,EAAOzC,SAAOpB,EAAQH,EAAOE,GACnC,IAAK,IAAI4B,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EACxC,IAAK,IAAII,EAAI,EAAGA,EAAI7B,EAAS8B,aAAcD,EACzC,IAAK,IAAIE,EAAK,EAAGA,EAAK/B,EAASgC,YAAaD,EAAI,CAC9C,MAAME,EAAWF,EAAK7B,EAAeM,EACrC,IAAI0B,EAAQD,EACZ,KAAOC,EAAQ,GACbA,GAAS9B,EAGX,MAAMiC,EACFF,KAAKG,IAAItC,EAASuC,SAAUjC,EAAwB2B,GACxD,IAAK,IAAIQ,EAAK,EAAGA,EAAKzC,EAAS0C,WAAYD,EAAI,CAC7C,MAAME,EAAWF,EAAKtC,EAAcQ,EACpC,IAAIiC,EAAQD,EACZ,KAAOC,EAAQ,GACbA,GAASvC,EAEX,MAAMwC,EACFV,KAAKG,IAAItC,EAAS8C,QAASvC,EAAuBoC,GACtD,IAAIiB,EAAW9C,OAAOC,kBAClB8C,GAAe,EAEnB,IAAK,IAAIX,EAAKhB,EAAOgB,EAAKb,EAAOa,GAAM9C,EAAgB,CACrD,MAAM0D,EAAKZ,EAAKjB,EAChB,IAAK,IAAImB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAM/C,EAAe,CACpD,MAAM0D,EAAKX,EAAKT,EACVU,EAAQM,EAAKK,IAAIvC,EAAGyB,EAAIE,EAAIvB,GAC9BwB,EAAQO,IACVA,EAAWP,EAETQ,EADEL,EACYC,IACRhC,EAAIzB,EAASuC,SAAWW,GAAMlD,EAAS8C,QAAUM,GAC3CpD,EAAS8B,WACbD,GACHqB,EAAKlD,EAAS8C,QAAUM,GAAMpD,EAAS8B,WAAaD,EAE3CiC,EAAKvD,EAAuBwD,IAKlDL,EAAaO,IAAIJ,EAAapC,EAAGM,EAAIU,EAAIZ,IAKjD,OAAO6B,ECjIT,MAAMQ,EAA0BC,eAAaD,wBACvCE,EAAQD,eAAaC,MACrBC,EAAOF,eAAaE,KACpBC,EAAWH,eAAaG,SACxBC,EAAYJ,eAAaI,UAO/B,SAASC,EACLC,EAAyBC,EAAWC,EACpCC,GACF,GAAmB,WAAfD,EACF,OAAOF,EAAQI,OAAOH,GACjB,GAAmB,SAAfC,EACT,OAAOF,EAAQK,KAAKJ,GACf,GAAmB,QAAfC,EACT,OAAOF,EAAQM,IAAIL,GACd,GAAmB,UAAfC,EACT,OAAOF,EAAQO,MAAMN,GAChB,GAAmB,UAAfC,EACT,OAAOF,EAAQQ,MAAMP,EAAGE,GAE1B,MAAM,IAAIM,MACN,cAAcP,yDAiBPQ,UAAuBC,gBAMlCC,cACEC,QANKC,eAAY,GAGXA,eAAW,EAIjBA,KAAKC,KAAO,IAAIC,cAAYF,KAAMG,YAGpCL,MAAMhE,EAAoCsE,EAAiBhG,GAErD4F,KAAKK,WACPL,KAAKK,UAAW,EACZC,QAAM7B,IAAI,YACZ8B,eAAaC,KACT,4dAYR,MAAMC,EAAS,GAIf,OAFAT,KAAKC,KAAKvB,IAAI+B,EAAQ,CAAC3E,OAAAA,EAAQ1B,MAAAA,EAAOsG,SAAU,IAEzCD,EAITX,OAAOW,GACcT,KAAKC,KAAKxB,IAAIgC,GACtBC,WAIbZ,OAAOW,GACL,GAAIT,KAAKC,KAAKU,IAAIF,GAAS,CACNT,KAAKC,KAAKxB,IAAIgC,GACtBC,YAIfZ,KACIW,EAAgB3E,EAAoCsE,EACpDhG,GACF4F,KAAKC,KAAKvB,IAAI+B,EAAQ,CAAC3E,OAAAA,EAAQ1B,MAAAA,EAAOsG,SAAU,IAGlDZ,aACE,OAAOE,KAAKC,KAAKW,aAGnBd,WAAWW,GACT,OAAOT,KAAKa,SAASJ,GAEvBX,SAASW,GACP,MAAMrG,MAACA,EAAK0G,eAAEA,GAAkBd,KAAKC,KAAKxB,IAAIgC,GAC9C,GAAc,cAAVrG,EAAuB,CACzB,MAAM2G,EACFf,KAAKa,SAASC,EAAeE,KAAKP,QAChCQ,EACFjB,KAAKa,SAASC,EAAeI,KAAKT,QACtC,OAAOF,eAAaY,uBAAuBJ,EAAYE,GAEzD,OAAOjB,KAAKC,KAAKxB,IAAIgC,GAAQ3E,OAGvBgE,WAA2B7F,GACjC,MAAMgG,EAAOD,KAAKa,SAAS5G,EAAEwG,QAC7B,IAAIW,EAAcnB,EAClB,GAAgB,WAAZhG,EAAEG,MACJ,IAEEgH,EAAenB,EAAsBoB,IAAI/E,GAAKpC,OAAKoH,aAAahF,IAChE,SACA,MAAM,IAAIqD,MAAM,oDAGpB,OAAO4B,SAAUtH,EAAEmG,MAAOnG,EAAEG,MAAOgH,GAG7BtB,WACJhE,EAAoCsE,EAAiBhG,GACvD,MAAMqG,EAAST,KAAKwB,MAAM1F,EAAQsE,EAAOhG,GACzC,OAAO+F,WAASsB,qBAAqBhB,EAAQL,EAAOhG,EAAO4F,MAG7DF,YAAYW,GACV,GAAIT,KAAKC,KAAKU,IAAIF,GAAS,CACzB,MAAMK,eAACA,GAAkBd,KAAKC,KAAKxB,IAAIgC,GACjB,MAAlBK,IACFA,EAAeE,KAAKU,UACpBZ,EAAeI,KAAKQ,WAEtB1B,KAAKC,KAAK0B,OAAOlB,IAIrBX,8BAA8B8B,GAC5B,MAAMnB,EAASmB,EAAWnB,OAE1B,GAAIT,KAAKC,KAAKU,IAAIF,GAAS,CACzB,MAAMoB,EAAa7B,KAAKC,KAAKxB,IAAIgC,GAEjCoB,EAAWnB,WAEPmB,EAAWnB,SAAW,GACxBV,KAAK8B,YAAYrB,IAKvBX,WAAWiC,GACT,MAAMC,EAAQ9H,OAAK+H,MAGnB,OAFAF,IAEO,CAACG,SADShI,OAAK+H,MAAQD,GAIhClC,SACE,MAAO,CAELqC,YAAY,EACZC,QACI,CAAC,uHAKTtC,QAA0BkB,EAASE,GACjC,MAAMmB,EAASrC,KAAKsC,WAAW,KAAMtB,EAAKZ,MAAO,aAWjD,OATmBJ,KAAKC,KAAKxB,IAAI4D,EAAO5B,QAI7BK,eAAiB,CAC1BE,KAAMb,WAASoC,KAAKvB,EAAKwB,SACzBtB,KAAMf,WAASoC,KAAKrB,EAAKsB,UAGpBH,EAETvC,KAAuB2C,GAErB,OADmBzC,KAAKC,KAAKxB,IAAIgE,EAAMhC,QACrBK,eAAeE,KAAKwB,QAExC1C,KAAuB2C,GAErB,OADmBzC,KAAKC,KAAKxB,IAAIgE,EAAMhC,QACrBK,eAAeI,KAAKsB,QAGxC1C,MAAwBX,EAAMuD,EAAiBC,GAI7C,GAHAhJ,EAAiBwF,EAAG,SAEAyD,aAAWC,iBAAiB1D,EAAEiB,MAAOsC,EAAOC,GAC/C,CACf,MAAMG,EAAaF,aAAWG,kBAAkBL,EAAOvD,EAAE3E,SACnDwI,EAAS9I,OAAK+I,cAAcN,GAC5BO,EAAOlD,KAAKa,SAAS1B,EAAEsB,QAC7B,OAAO0C,SACID,EAAKE,SAASN,EAAYA,EAAaE,GAASL,EAChDxD,EAAE/E,OAGf,MAAMuB,EAAS4F,SAAUoB,EAAMxD,EAAE/E,OAC3BgE,EAAO4B,KAAKqD,WAAWlE,GAC7B,IAAK,IAAImE,EAAI,EAAGA,EAAI3H,EAAOgH,OAAQW,EAAG,CACpC,MACMC,EADM5H,EAAO6H,WAAWF,GACbjC,IAAI,CAACoC,EAAKC,IAAMD,EAAMf,EAAMgB,IAC7C/H,EAAOG,OAAOwH,GAAKlF,EAAKK,OAAO8E,GAEjC,OAAO5H,EAAOgI,WAGhB7D,aACIX,EAAMuD,EAAiBkB,EAAepJ,GACxCb,EAAiBwF,EAAG,gBAEpB,MAAMvD,EAAWgH,aAAWiB,gBAAgBnB,EAAOkB,EAAKpJ,GAExD,GAAIoB,EAASkI,KAAKC,GAAiB,IAATA,GACxB,OAAOZ,SAAU,GAAIvH,GAGvB,MAAMD,EAAS4F,SAAU3F,EAAUuD,EAAE/E,OAC/BgE,EAAO4B,KAAKqD,WAAWlE,GAC7B,IAAK,IAAImE,EAAI,EAAGA,EAAI3H,EAAOgH,KAAMW,IAAK,CACpC,MAAMU,EAAMrI,EAAO6H,WAAWF,GAExBW,EAAmB,IAAInK,MAAMkK,EAAIhB,QACvC,IAAK,IAAIU,EAAI,EAAGA,EAAIO,EAAOjB,OAAQU,IACjCO,EAAOP,GAAKM,EAAIN,GAAKlJ,EAAQkJ,GAAKhB,EAAMgB,GAE1C/H,EAAO+C,IAAIN,EAAKK,OAAOwF,MAAYD,GAGrC,OAAOrI,EAAOgI,WAGhB7D,KAAKX,GACH,MAAM+E,EAAQlE,KAAKa,SAAS1B,EAAEsB,QACxB9E,EAAS4F,SAAU,CAACpC,EAAEwD,KAAMxD,EAAEwD,MAAOxD,EAAE/E,OACvC8I,EAAOvH,EAAOG,OACpB,IAAK,IAAIwH,EAAI,EAAGA,EAAIY,EAAMlB,OAAQM,IAChCJ,EAAKI,EAAInE,EAAEwD,KAAOW,GAAKY,EAAMZ,GAE/B,OAAO3H,EAAOgI,WAGhB7D,QAAQX,EAAW4E,GACjB,MAAMI,EAAMhF,EAAEiB,MAAM2D,GACdnI,EAAqB,IAAI9B,MAAMqF,EAAEiF,KAAO,GAC9C,IAAIC,EAAW,EACf,IAAK,IAAIf,EAAI,EAAGA,EAAInE,EAAEiF,KAAMd,IACtBA,IAAMS,IACRnI,EAASyI,KAAclF,EAAEiB,MAAMkD,IAInC,MAAMZ,EAAQ,IAAI5I,MAAMqF,EAAEiF,MAAME,KAAK,GAC/B3B,EAAOxD,EAAEiB,MAAMmE,QACrB5B,EAAKoB,GAAQ,EACb,MAAMS,EAAM,IAAI1K,MAAMqK,GACtB,IAAK,IAAIb,EAAI,EAAGA,EAAIkB,EAAIxB,OAAQM,IAC9BZ,EAAMqB,GAAQT,EACdkB,EAAIlB,GAAKtD,KAAKuE,MAAMpF,EAAGuD,EAAOC,GAAM8B,QAAQ7I,GAE9C,OAAO4I,EAGT1E,QAA0BX,EAAM4E,GAC9BpK,EAAiBwF,EAAG,WAEpB,MAAMxD,EAAS4F,SAAUpC,EAAEiB,MAAOjB,EAAE/E,OAC9BgE,EAAO4B,KAAKqD,WAAWlE,GAE7B,IAAK,IAAImE,EAAI,EAAGA,EAAI3H,EAAOgH,KAAMW,IAAK,CACpC,MAAMoB,EAAS/I,EAAO6H,WAAWF,GAC3BqB,EAAQD,EAAOH,QACrBR,EAAK/J,QAAQ4K,GAAMD,EAAMC,GAAMzF,EAAEiB,MAAMwE,GAAM,EAAID,EAAMC,IACvDjJ,EAAO+C,IAAIN,EAAKK,OAAOkG,MAAWD,GAGpC,OAAO/I,EAAOgI,WAGhB7D,OAAO+E,EAAmBd,GACxB,GAAyB,cAArBc,EAAQ,GAAGzK,MAAuB,CACpC,MAAM0K,EAAQD,EAAQxD,IAAKpH,GAAM8K,OAAQ9K,IACnC+K,EAAQH,EAAQxD,IAAKpH,GAAMgL,OAAQhL,IACzC,OAAOiL,UAAWlF,KAAKmF,OAAOL,EAAOf,GAAO/D,KAAKmF,OAAOH,EAAOjB,IAEjE,MAAMqB,EAAYP,EAAQxD,IAAIpH,IAC5B,MAAMoL,EAAYnL,OAAK+I,cAAchJ,EAAEmG,MAAMmE,MAAMR,IACnD,OAAO9J,EAAEqL,MAAM,EAAGD,KAEdzJ,EACJ2E,eAAasD,gBAAgBuB,EAAU/D,IAAIpH,GAAKA,EAAEmG,OAAQ,GAEtDtE,EACFyF,SAAU3F,EAA8BiJ,EAAQ,GAAGzK,OAC9C0B,OACT,GAA8B,IAA1BsJ,EAAU,GAAGhF,MAAM,GAAU,CAE/B,IAAImF,EAAS,EACbH,EAAUpL,QAAQC,IAChB6B,EAAO4C,IAAIsB,KAAKa,SAAS5G,EAAEwG,QAAuB8E,GAClDA,GAAUtL,EAAE0I,WAET,CACL,IAAI6C,EAAY,EAChBJ,EAAUpL,QAAQC,IAChB,MAAMwL,EAAQzF,KAAKa,SAAS5G,EAAEwG,QAC9B,IAAIiF,EAAO,EACX,IAAK,IAAIC,EAAM,EAAGA,EAAM1L,EAAEmG,MAAM,KAAMuF,EAAK,CACzC,MAAMC,EAASD,EAAM/J,EAAS,GAAK4J,EACnC,IAAK,IAAIK,EAAM,EAAGA,EAAM5L,EAAEmG,MAAM,KAAMyF,EACpC/J,EAAO8J,EAASC,GAAOJ,EAAMC,KAGjCF,GAAavL,EAAEmG,MAAM,KAGzB,MAAM0F,EACFvF,eAAasD,gBAAgBgB,EAAQxD,IAAIpH,GAAKA,EAAEmG,OAAQ2D,GAC5D,OAAOZ,SAAUrH,EAAQgK,EAAejB,EAAQ,GAAGzK,OAGrD0F,IAAsBX,GAGpB,OAFAxF,EAAiBwF,EAAG,OAEba,KAAK+F,SAASC,UAAW,GAAI7G,GAGtCW,IAAImG,EAAW/J,GACb,MAAgB,cAAZ+J,EAAE7L,OAAqC,cAAZ8B,EAAE9B,MACxB4F,KAAKkG,2BACRD,EAAEE,KAAK,aAAcjK,EAAEiK,KAAK,aAC5B,CAACC,EAAOC,EAAOC,EAAOC,KACb,CAACvF,KAAMoF,EAAQE,EAAOpF,KAAMmF,EAAQE,KAI5CvG,KAAKwG,oBACRP,EAAG/J,EAAGuK,aAAWR,EAAE7L,MAAO8B,EAAE9B,OAC5B,CAACsM,EAAQC,IAAWD,EAASC,GAGnC7G,KAAuB+E,GACrBlL,EAAiBkL,EAAS,QAE1B,MAAM3B,EAAO2B,EAAQxD,IAAIpH,GAAK+F,KAAKa,SAAS5G,EAAEwG,SACxC4B,EAASd,SAAUsD,EAAQ,GAAGzE,MAAOyE,EAAQ,GAAGzK,OAChDwM,EAAavE,EAAOvG,OAC1B,IAAK,IAAIwH,EAAI,EAAGA,EAAIuB,EAAQ7B,OAAQM,IAAK,CACvC,MAAMuD,EAAW3D,EAAKI,GACtB,IAAK,IAAII,EAAI,EAAGA,EAAIkD,EAAW5D,OAAQU,IACrCkD,EAAWlD,IAAMmD,EAASnD,GAG9B,OAAOrB,EAAOsB,WAGhB7D,QAA0BgH,EAAWC,GACnC,MAAMC,EAAO9M,OAAK+M,eAAe,CAACF,GAAMD,EAAO1G,OAGzC8G,EAAWrK,MAAIiK,EAAQE,GACvBG,EACF5G,eAAa6G,qBAAqBF,EAAS9G,MAAO4G,GAChDf,EAAIjG,KAAKqH,SAASP,EAAQI,EAASzC,QAAQ0C,IAC3CjL,EAAI8D,KAAKsH,IAAIrB,GACbsB,EAASvH,KAAKwH,IAAItL,EAAG8K,GAAMvC,QAAQ0C,GAIzC,OAAOM,MAAOvL,EAAGqL,GAGnBzH,SAASmG,EAAW/J,GAClB,MAAgB,cAAZ+J,EAAE7L,OAAqC,cAAZ8B,EAAE9B,MACxB4F,KAAKkG,2BACRD,EAAEE,KAAK,aAAcjK,EAAEiK,KAAK,aAC5B,CAACC,EAAOC,EAAOC,EAAOC,KACb,CAACvF,KAAMoF,EAAQE,EAAOpF,KAAMmF,EAAQE,KAI5CvG,KAAKwG,oBACRP,EAAG/J,EAAGuK,aAAWR,EAAE7L,MAAO8B,EAAE9B,OAC5B,CAACsM,EAAQC,IAAWD,EAASC,GAGnC7G,IAAsBmG,EAAM/J,GAG1B,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,OAElB8D,KAAKwG,oBACDP,EAAG/J,EAAG+J,EAAE7L,MAAO,CAACsM,EAAQC,IAAW/J,KAAK8K,IAAIhB,EAAQC,IAIjE7G,YACImG,EAAa/J,EAAayL,EAC1BC,GACFjO,EAAiB,CAACsM,EAAG/J,GAAI,UAEzB,MAAM2L,EAAYF,EAAa1B,EAAE7F,MAAM,GAAK6F,EAAE7F,MAAM,GAC9C0H,EAAUH,EAAa1B,EAAE7F,MAAM,GAAK6F,EAAE7F,MAAM,GAC5C2H,EAAWH,EAAa1L,EAAEkE,MAAM,GAAKlE,EAAEkE,MAAM,GAC7C4H,EAAW/B,EAAE7F,MAAM,GAEnB6H,EAAUjI,KAAKa,SAASoF,EAAExF,QAC1ByH,EAAUlI,KAAKa,SAAS3E,EAAEuE,SACzB0H,EAAQC,EAAYC,GAAcV,EACrC,CAAC1B,EAAEzL,QAAQ,GAAI,EAAGyL,EAAEzL,QAAQ,IAC5B,CAACyL,EAAEzL,QAAQ,GAAIyL,EAAEzL,QAAQ,GAAI,IAC1B8N,EAAYC,EAAYC,GAAUZ,EACrC,CAAC,EAAG1L,EAAE1B,QAAQ,GAAI0B,EAAE1B,QAAQ,IAC5B,CAAC0B,EAAE1B,QAAQ,GAAI,EAAG0B,EAAE1B,QAAQ,IAE1BmI,EAAOmF,EAAUC,EACjB1F,EAASd,SAAU,CAACyG,EAAUF,EAASC,GAAW9B,EAAE7L,OACpDqO,EAAUpG,EAAOvG,OACjB4M,EAAY1I,KAAK0I,UAEvB,IAAK,IAAIxM,EAAI,EAAGA,EAAI8L,EAAU9L,IAC5B,IAAK,IAAIyM,EAAK,EAAGA,EAAKb,EAASa,GAAMD,EACnC,IAAK,IAAIE,EAAK,EAAGA,EAAKb,EAAUa,GAAMF,EACpC,IAAK,IAAIG,EAAK,EAAGA,EAAKhB,EAAWgB,GAAMH,EAAW,CAEhD,MAAMI,EAASlM,KAAKG,IAAI4L,EAAKD,EAAWZ,GAClCiB,EAASnM,KAAKG,IAAI6L,EAAKF,EAAWX,GAClCiB,EAASpM,KAAKG,IAAI8L,EAAKH,EAAWb,GAExC,IAAK,IAAIvE,EAAIqF,EAAIrF,EAAIwF,EAAQxF,IAC3B,IAAK,IAAII,EAAIkF,EAAIlF,EAAIqF,EAAQrF,IAAK,CAChC,IAAI8D,EAAM,EAEV,IAAK,IAAIyB,EAAIJ,EAAII,EAAID,EAAQC,IAC3BzB,GAAOS,EAAQ/L,EAAIiM,EAAS7E,EAAI8E,EAAaa,EAAIZ,GAC7CH,EAAQe,EAAIX,EAAa5E,EAAI6E,EAAarM,EAAIsM,GAEpDC,EAAQvM,EAAIyG,GAAQW,EAAIyE,EAAWrE,KAAO8D,GAOtD,OAAOnF,EAAOsB,WAGhB7D,kBACImG,EAACA,EAAC/J,EAAEA,EAACyL,WAAEA,EAAUC,WAAEA,EAAUsB,KAAEA,EAAI9J,WAAEA,EAAUC,uBAAEA,IAEnD,IAAIgD,EAASrC,KAAKmJ,YAAYlD,EAAG/J,EAAGyL,EAAYC,GAUhD,OATIsB,IACF7G,EAASrC,KAAKoJ,IAAI/G,EAAQ6G,IAExB9J,IACFiD,EACIpD,EAAce,KAAMqC,EAAQjD,EAAYC,IAIvCgD,EAGTvC,SAASmG,EAAW/J,GAClB,MAAgB,cAAZ+J,EAAE7L,OAAqC,cAAZ8B,EAAE9B,MACxB4F,KAAKkG,2BACRD,EAAEE,KAAK,aAAcjK,EAAEiK,KAAK,aAC5B,CAACC,EAAOC,EAAOC,EAAOC,KACb,CACLvF,KAAMoF,EAAQE,EAAQD,EAAQE,EAC9BrF,KAAMkF,EAAQG,EAAQF,EAAQC,KAKjCtG,KAAKwG,oBACRP,EAAG/J,EAAGuK,aAAWR,EAAE7L,MAAO8B,EAAE9B,OAC5B,CAACsM,EAAQC,IAAWD,EAASC,GAGnC7G,SAASmG,EAAW/J,GAClBvC,EAAiB,CAACsM,EAAG/J,GAAI,YAIzB,OAAO8D,KAAKwG,oBAAoBP,EAAG/J,EADf,QADT,CAAC+J,EAAW/J,IAAcU,KAAKyM,MAAMpD,EAAI/J,IAKtD4D,IAAIX,EAAW6H,GACbrN,EAAiBwF,EAAG,OAEpBoB,eAAa+I,2BAA2B,MAAOtC,EAAM7H,EAAEiF,MACvD,MAAOxI,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9CyC,EAAchD,aAAWtH,EAAE/E,MAAO,SAClCiI,EAASqH,QAAS9N,EAAU6N,GAC5BE,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAInC,EAAM,EACV,IAAK,IAAI9D,EAAI,EAAGA,EAAIiG,IAAcjG,EAChC8D,GAAOoC,EAAMrE,EAAS7B,GAExBR,EAAKI,GAAKkE,EAEZ,OAAOnF,EAGTvC,KAAKX,EAAW6H,GACdrN,EAAiBwF,EAAG,OAEpB,MAAOvD,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9CyC,EAAchD,aAAWtH,EAAE/E,MAAO,SAClCiI,EAASqH,QAAS9N,EAAU6N,GAC5BE,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAIE,EAAO,EACX,IAAK,IAAInG,EAAI,EAAGA,EAAIiG,IAAcjG,EAChCmG,GAAQD,EAAMrE,EAAS7B,GAEzBR,EAAKI,GAAKuG,EAEZ,OAAOxH,EAGTvC,mBACIX,EAAM2K,EAAsBC,GAC9BpQ,EAAiBwF,EAAG,sBAEpB,MAAMqF,EAAM,GAINwF,EAAW7K,EAAEiF,KAAO0F,EAAW1F,KACrC,IAAK,IAAId,EAAI,EAAGA,EAAI0G,IAAY1G,EAC9BwG,EAAaA,EAAWG,WAAW3G,EAAI,GAGzC,IAAK,IAAIA,EAAI,EAAGA,EAAIyG,IAAezG,EAAG,CACpC,MAAM4G,EAAYlE,SAAU1C,EAAG,SAEzBkE,EADO2C,QAASD,EAAWJ,GAAYM,OAAO,WACnCC,IAAIlL,GAAGqI,IAAI,GAC5BhD,EAAI8F,KAAK9C,GAGX,OAAO+C,QAAS/F,GAGlB1E,OAAOX,EAAW4E,GAChBpK,EAAiBwF,EAAG,UAEpB,MAAM6H,EAAO,CAACjD,GACdxD,eAAa+I,2BAA2B,SAAUtC,EAAM7H,EAAEiF,MAC1D,MAAOxI,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9C3E,EAASqH,QAAS9N,EAAU,SAC5B+N,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAI5M,EAAM6M,EAAMrE,GACZiF,EAAW,EACf,IAAK,IAAI9G,EAAI,EAAGA,EAAIiG,IAAcjG,EAAG,CACnC,MAAM+G,EAAQb,EAAMrE,EAAS7B,GACzB+G,EAAQ1N,IACVA,EAAM0N,EACND,EAAW9G,GAGfR,EAAKI,GAAKkH,EAEZ,OAAOnI,EAGTvC,OAAOX,EAAW4E,GAChBpK,EAAiBwF,EAAG,UAEpB,MAAM6H,EAAO,CAACjD,GACdxD,eAAa+I,2BAA2B,SAAUtC,EAAM7H,EAAEiF,MAC1D,MAAOxI,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9C3E,EAASqH,QAAS9N,EAAU,SAC5B+N,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAI9M,EAAM+M,EAAMrE,GACZmF,EAAW,EACf,IAAK,IAAIhH,EAAI,EAAGA,EAAIiG,IAAcjG,EAAG,CACnC,MAAM+G,EAAQb,EAAMrE,EAAS7B,GACzB+G,EAAQ5N,IACVA,EAAM4N,EACNC,EAAWhH,GAGfR,EAAKI,GAAKoH,EAEZ,OAAOrI,EAGTvC,OAAOX,EAAW4E,EAAc4G,EAAoBC,GAIlD,GAFAjR,EAAiBwF,EAAG,UAEhB4E,IAAS5E,EAAEiF,KAAO,EACpB,MAAM,IAAIzE,MACN,oDAAoDR,EAAEiF,KAAO,KAC7D,gBAAgBL,KAEtB,MAAM0F,EAAchD,aAAWtH,EAAE/E,MAAO,SAClCiI,EAASqH,QAASvK,EAAEiB,MAAOqJ,GAC3BvG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QACxBoK,EAAW1L,EAAEiB,MAAMjB,EAAEiF,KAAO,GAC5B0G,EAAgBF,EAClB,CAACtH,EAAWI,IAAcJ,EAAIuH,EAAWnH,EAAI,EAC7C,CAACJ,EAAWI,IAAcJ,EAAII,EAClC,IAAK,IAAIJ,EAAI,EAAGA,EAAIsG,EAAM5G,OAAQM,GAAKuH,EACrC,IAAK,IAAInH,EAAI,EAAGA,EAAImH,EAAUnH,IAAK,CACjC,MAAMD,EAAMqH,EAAcxH,EAAGI,GAC7B,GAAU,IAANA,EACFR,EAAKO,GAAOkH,EAAY,EAAIf,EAAMnG,OAC7B,CACL,MAAMsH,EAAUD,EAAcxH,EAAGI,EAAI,GACrCR,EAAKO,GAAOkH,EAAYf,EAAMmB,GAAW7H,EAAK6H,GACtBnB,EAAMnG,GAAOP,EAAK6H,IAIhD,OAAO1I,EAGTvC,MAAMmG,EAAW/J,GAGf,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,SAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC3CD,IAASC,EAAQ,EAAI,GAIjCnL,SAASmG,EAAW/J,GAGlB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,YAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC3CD,IAASC,EAAQ,EAAI,GAIjCnL,KAAKmG,EAAW/J,GAGd,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,QAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC3CD,EAAOC,EAAQ,EAAI,GAI/BnL,UAAUmG,EAAW/J,GAGnB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,aAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC3CD,GAAQC,EAAQ,EAAI,GAIhCnL,QAAQmG,EAAW/J,GAGjB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,WAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC3CD,EAAOC,EAAQ,EAAI,GAI/BnL,aAAamG,EAAW/J,GAGtB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,gBAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC3CD,GAAQC,EAAQ,EAAI,GAIhCnL,WAA6BX,GAC3BxF,EAAiBwF,EAAG,cAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIC,WAAWrP,EAAOkH,QACxC,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnC4H,EAAU5H,GAAKxH,EAAOwH,GAAK,EAAI,EAEjC,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,QAG7CN,WAAWmG,EAAW/J,GAGpB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,cAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC5CD,GAAQC,GAInBnL,UAAUmG,EAAW/J,GAGnB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,aAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG,OAAQ,CAAC8O,EAAMC,IAC5CD,GAAQC,GAInBnL,OAAOsL,EAAmBnF,EAAW/J,GACnCvC,EAAiB,CAACyR,EAAWnF,EAAG/J,GAAI,UAEpC,MAAMJ,EAASkE,KAAKa,SAASuK,EAAU3K,QACjCwH,EAAUjI,KAAKa,SAASoF,EAAExF,QAC1ByH,EAAUlI,KAAKa,SAAS3E,EAAEuE,QAC1B4B,EAASqH,QAASzD,EAAE7F,MAAOqG,aAAWR,EAAE7L,MAAO8B,EAAE9B,QACjD8Q,EAAYlL,KAAKa,SAASwB,EAAO5B,QACvC,IAAI4K,EAAQ,EACZ,MAAM9F,EAA4B,IAAnB6F,EAAUhH,MAAcgH,EAAUhH,KAAO,GAAgB,IAAX6B,EAAE7B,KAC3D,EACAlK,OAAK+I,cAAcgD,EAAE7F,MAAMmE,MAAM,IAErC,IAAK,IAAIjB,EAAI,EAAGA,EAAIxH,EAAOkH,OAAQM,IACjC,IAAK,IAAII,EAAI,EAAGA,EAAI6B,EAAQ7B,IACR,IAAd5H,EAAOwH,GACT4H,EAAUG,KAAWpD,EAAQ3E,GAE7B4H,EAAUG,KAAWnD,EAAQ5E,GAKnC,OAAOjB,EAGTvC,MAAMsL,GACJzR,EAAiB,CAACyR,GAAY,SAE9B,MAAME,EAAWtL,KAAKa,SAASuK,EAAU3K,QACzC,OAAOzB,EAAUoM,EAAUhL,MAAOkL,GAGpCxL,KAAuBX,EAAM8J,EAAWsC,GACtC5R,EAAiBwF,EAAG,QAEpB,MAAM+E,EAAQlE,KAAKa,SAAS1B,EAAEsB,QAC9B,OAAO1B,EAASmF,EAAO/E,EAAEiB,MAAOjB,EAAE/E,MAA0B6O,EAAGsC,GAGjEzL,IAAIX,EAAW6H,GACbrN,EAAiBwF,EAAG,OAEpBoB,eAAa+I,2BAA2B,MAAOtC,EAAM7H,EAAEiF,MACvD,MAAOxI,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9C3E,EAASqH,QAAS9N,EAAUuD,EAAE/E,OAC9BuP,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAI5M,EAAM6M,EAAMrE,GAChB,IAAK,IAAI7B,EAAI,EAAGA,EAAIiG,IAAcjG,EAAG,CACnC,MAAM+G,EAAQb,EAAMrE,EAAS7B,GACzB+G,EAAQ1N,IACVA,EAAM0N,GAGVvH,EAAKI,GAAKvG,EAEZ,OAAOsF,EAGTvC,QAAQmG,EAAW/J,GAGjB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,WAElB8D,KAAKwG,oBACRP,EAAG/J,EAAG+J,EAAE7L,MAAO,CAAC4Q,EAAMC,IAASrO,KAAKG,IAAIiO,EAAMC,IAGpDnL,IAAImG,EAAW/J,GAGb,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,OAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG+J,EAAE7L,MAAO,CAAC4Q,EAAMC,KACpD,MAAMO,EAAMR,EAAOC,EACnB,OAAKD,EAAO,GAAKC,EAAO,GAAOD,GAAQ,GAAKC,GAAQ,EAC3CO,GAECA,EAAMP,GAAQA,IAK5BnL,QAAQmG,EAAW/J,GAGjB,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,WAElB8D,KAAKwG,oBACRP,EAAG/J,EAAG+J,EAAE7L,MAAO,CAAC4Q,EAAMC,IAASrO,KAAKC,IAAImO,EAAMC,IAGpDnL,IAAIX,EAAW6H,GACbrN,EAAiBwF,EAAG,OAEpBoB,eAAa+I,2BAA2B,MAAOtC,EAAM7H,EAAEiF,MACvD,MAAOxI,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9C3E,EAASqH,QAAS9N,EAAUuD,EAAE/E,OAC9BuP,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAI8B,EAAM7B,EAAMrE,GAChB,IAAK,IAAI7B,EAAI,EAAGA,EAAIiG,IAAcjG,EAAG,CACnC,MAAM+G,EAAQb,EAAMrE,EAAS7B,GAC7B+H,EAAMA,GAAOhB,EAEfvH,EAAKI,GAAKmI,EAEZ,OAAOpJ,EAGTvC,IAAIX,EAAW6H,GACbrN,EAAiBwF,EAAG,OAEpBoB,eAAa+I,2BAA2B,MAAOtC,EAAM7H,EAAEiF,MACvD,MAAOxI,EAAU2N,GACbhJ,eAAaiJ,0BAA0BrK,EAAEiB,MAAO4G,GAC9C3E,EAASqH,QAAS9N,EAAUuD,EAAE/E,OAC9BuP,EAAazP,OAAK+I,cAAcsG,GAChCrG,EAAOlD,KAAKa,SAASwB,EAAO5B,QAE5BmJ,EAAQ5J,KAAKa,SAAS1B,EAAEsB,QAC9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAI+B,EAAS9B,EAAMrE,GACnB,IAAK,IAAI7B,EAAI,EAAGA,EAAIiG,IAAcjG,EAAG,CACnC,MAAM+G,EAAQb,EAAMrE,EAAS7B,GAC7BgI,EAASA,GAAUjB,EAErBvH,EAAKI,GAAKoI,EAEZ,OAAOrJ,EAGTvC,kBAAkBmG,EAAW/J,GAG3B,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,qBAElB8D,KAAKwG,oBAAoBP,EAAG/J,EAAG+J,EAAE7L,MAAO,CAAC4Q,EAAMC,KACpD,MAAMU,EAAOX,EAAOC,EACpB,OAAOU,EAAOA,IAIlB7L,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnC4H,EAAU5H,GAAK1G,KAAKiP,KAAK/P,EAAOwH,IAElC,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnC4H,EAAU5H,GAAK1G,KAAKyM,MAAMvN,EAAOwH,IAEnC,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,KAAuBX,GACrBxF,EAAiBwF,EAAG,KAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAC/BxH,EAAOwH,GAAK,EACd4H,EAAU5H,IAAM,EACPxH,EAAOwH,GAAK,EACrB4H,EAAU5H,GAAK,EAEf4H,EAAU5H,GAAK,EAGnB,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,KAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIC,WAAWrP,EAAOkH,QACxC,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAC/B/H,OAAOwC,MAAMjC,EAAOwH,MACtB4H,EAAU5H,GAAK,GAGnB,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,QAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,KAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIC,WAAWrP,EAAOkH,QACxC,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAC/B1G,KAAKkP,IAAIhQ,EAAOwH,MAAQyI,EAAAA,IAC1Bb,EAAU5H,GAAK,GAGnB,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,QAG7CN,SAA2BX,GACzBxF,EAAiBwF,EAAG,KAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIC,WAAWrP,EAAOkH,QACxC,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAC/B/H,OAAOyQ,SAASlQ,EAAOwH,MACzB4H,EAAU5H,GAAK,GAGnB,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,QAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CAEtC,MAAM2I,EAAOrP,KAAKyM,MAAMvN,EAAOwH,IAC3BxH,EAAOwH,GAAK2I,EAAO,GACrBf,EAAU5H,GAAK1G,KAAKyM,MAAMvN,EAAOwH,IACxBxH,EAAOwH,GAAK2I,EAAO,GAC5Bf,EAAU5H,GAAK1G,KAAKiP,KAAK/P,EAAOwH,IAG9B4H,EAAU5H,GADR2I,EAAO,GAAQ,EACFA,EAEAA,EAAO,EAI5B,OAAOjM,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnC4H,EAAU5H,GAAK1G,KAAK0K,IAAIxL,EAAOwH,IAEjC,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnC4H,EAAU5H,GAAK1G,KAAKsP,MAAMpQ,EAAOwH,IAEnC,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmH,EAAQ3O,EAAOwH,GACrB4H,EAAU5H,GAAK1G,KAAKuP,IAAI1B,GAE1B,OAAOzK,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmH,EAAQ3O,EAAOwH,GACrB4H,EAAU5H,GAAK1G,KAAKwP,MAAM3B,GAE5B,OAAOzK,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmH,EAAQ3O,EAAOwH,GACrB4H,EAAU5H,GAAK1G,KAAKyP,KAAK5B,GAE3B,OAAOzK,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmH,EAAQ3O,EAAOwH,GACrB4H,EAAU5H,GAAK,EAAI1G,KAAKyP,KAAK5B,GAE/B,OAAOzK,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,WAA6BX,GAC3BxF,EAAiBwF,EAAG,cAEpB,MAAMrD,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzByK,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnC4H,EAAU5H,GAAK,EAAIxH,EAAOwH,GAE5B,OAAOtD,KAAKsC,WAAW4I,EAAW/L,EAAEiB,MAAO,WAG7CN,OAAyBX,GACvB,OAAOA,EAGTW,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqF,EAAMkF,QAASvK,EAAEiB,MAAOjB,EAAE/E,OAC1BqO,EAAUzI,KAAKa,SAAS2D,EAAI/D,QAC5B6L,EAAStM,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIgJ,EAAOtJ,SAAUM,EACnCmF,EAAQnF,GAAK1G,KAAKC,IAAI,EAAGyP,EAAOhJ,IAElC,OAAOkB,EAGT1E,MAAwBX,GACtBxF,EAAiBwF,EAAG,QAEpB,MAAMqF,EAAMkF,QAASvK,EAAEiB,MAAOjB,EAAE/E,OAC1BqO,EAAUzI,KAAKa,SAAS2D,EAAI/D,QAC5B6L,EAAStM,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIgJ,EAAOtJ,SAAUM,EACnCmF,EAAQnF,GAAK1G,KAAKG,IAAIH,KAAKC,IAAI,EAAGyP,EAAOhJ,IAAK,GAEhD,OAAOkB,EAGT1E,MAAwBX,EAAM8G,GAG5B,OAFAtM,EAAiB,CAACwF,EAAG8G,GAAI,SAElBjG,KAAKwG,oBACDrH,EAAG8G,EAAG9G,EAAE/E,MACR,CAACmS,EAAQ7F,IAAW6F,EAAS,EAAI7F,EAAS6F,EAASA,GAGhEzM,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmJ,EAAI3Q,EAAOwH,GAEfkJ,EAAalJ,GADXmJ,GAAK,EACWA,EAEC7P,KAAK0K,IAAImF,GAAK,EAGrC,OAAOzM,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,OAAyB4M,EAAOC,GAC9BhT,EAAiB,CAAC+S,EAAIC,GAAI,UAE1B,MAAMH,EAAe,IAAIZ,aAAae,EAAEhK,MAClC7G,EAASkE,KAAKa,SAAS8L,EAAElM,QACzBmM,EAAW5M,KAAKa,SAAS6L,EAAGjM,QAClC,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmJ,EAAI3Q,EAAOwH,GAEfkJ,EAAalJ,GADXmJ,GAAK,EACWG,EAAStJ,GAETsJ,EAAStJ,IAAMmJ,EAAI,GAGzC,OAAOzM,KAAKsC,WAAWkK,EAAcG,EAAEvM,MAAO,WAGhDN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAIpB,MAAM0N,EAAatM,eAAauM,gBAC1BC,EAAQxM,eAAayM,WAErBR,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmJ,EAAI3Q,EAAOwH,GAEfkJ,EAAalJ,GADXmJ,GAAK,EACWM,EAAQN,EAERI,GAAcjQ,KAAK0K,IAAImF,GAAK,GAGlD,OAAOzM,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,EAAMpC,EAAaF,GACxClD,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmJ,EAAI3Q,EAAOwH,GACjBkJ,EAAalJ,GAAKmJ,EAAI5P,EAAMA,EAAO4P,EAAI1P,EAAMA,EAAM0P,EAErD,OAAOzM,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAOjB,EAAE/E,OAGlD0F,IAAsBX,GACpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAKkP,IAAIhQ,EAAOwH,IAGpC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,WAA6BX,GAC3B,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAE/B,IAAK,IAAI6C,EAAI,EAAGA,EAAInE,EAAEwD,OAAQW,EAAG,CAC/B,MAAMtC,EAAOlF,EAAW,EAAJwH,GACdpC,EAAOpF,EAAW,EAAJwH,EAAQ,GAC5BkJ,EAAalJ,GAAK1G,KAAKqQ,MAAMjM,EAAME,GAErC,OAAOlB,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMqN,EAAe,IAAIU,WAAW/N,EAAEwD,MAChC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAKxH,EAAOwH,GAE3B,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,SAGhDN,QAA0BX,GACxBxF,EAAiBwF,EAAG,WAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK,GAAK,EAAI1G,KAAK0K,KAAKxL,EAAOwH,KAE9C,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,SAA2BX,GACzBxF,EAAiBwF,EAAG,YAOpB,MACMgO,EAAYvQ,KAAKuP,IADP,uBACsB,EAEhCK,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAE/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CAGtC,MAAM8J,EAAWtR,EAAOwH,IAAM6J,EAIxBE,EAAWvR,EAAOwH,GAAK6J,EAEvBG,EAAO1Q,KAAK0K,IAAIxL,EAAOwH,IAC7B,IAAIjB,EAGFA,EADEgL,EACOC,EACAF,EACAtR,EAAOwH,GAEP1G,KAAKuP,IAAI,EAAMmB,GAE1Bd,EAAalJ,GAAKjB,EAEpB,OAAOrC,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAK2Q,IAAIzR,EAAOwH,IAEpC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAK4Q,IAAI1R,EAAOwH,IAEpC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAK6Q,KAAK3R,EAAOwH,IAErC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAK8Q,KAAK5R,EAAOwH,IAErC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAK+Q,KAAK7R,EAAOwH,IAErC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,MAAwBmG,EAAM/J,GAG5B,OAFAvC,EAAiB,CAACsM,EAAG/J,GAAI,SAElB8D,KAAKwG,oBACDP,EAAG/J,EAAG+J,EAAE7L,MAAO,CAACsM,EAAQC,IAAW/J,KAAKgR,MAAMlH,EAAQC,IAInE7G,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAKiR,KAAK/R,EAAOwH,IAErC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAKkR,KAAKhS,EAAOwH,IAErC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,GACrBxF,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAKpJ,OAAK6T,KAAKjS,EAAOwH,IAErC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAKoR,MAAMlS,EAAOwH,IAEtC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAKqR,MAAMnS,EAAOwH,IAEtC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,MAAwBX,GACtBxF,EAAiBwF,EAAG,SAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EACnCkJ,EAAalJ,GAAK1G,KAAKsR,MAAMpS,EAAOwH,IAEtC,OAAOtD,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,IAAsBX,GACpBxF,EAAiBwF,EAAG,OAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QACzB0N,EAAI5N,eAAa6N,MACjBC,EAAK9N,eAAa+N,OAClBC,EAAKhO,eAAaiO,OAClBC,EAAKlO,eAAamO,OAClBC,EAAKpO,eAAaqO,OAClBC,EAAKtO,eAAauO,OACxB,IAAK,IAAIxL,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMyL,EAAOnS,KAAKmS,KAAKjT,EAAOwH,IACxBmJ,EAAI7P,KAAKkP,IAAIhQ,EAAOwH,IACpBrJ,EAAI,GAAO,EAAMkU,EAAI1B,GAC3BD,EAAalJ,GAAKyL,GACb,MACKF,EAAK5U,EAAI0U,GAAM1U,EAAKwU,GAAMxU,EAAIsU,GAAMtU,EAAIoU,GAAMpU,EAC/C2C,KAAK0K,KAAKmF,EAAIA,IAEzB,OAAOzM,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,KAAuBX,EAAM6P,EAAQ,GACnCrV,EAAiBwF,EAAG,QAEpB,MAAMqN,EAAe,IAAIZ,aAAazM,EAAEwD,MAClC7G,EAASkE,KAAKa,SAAS1B,EAAEsB,QAC/B,IAAK,IAAI6C,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmH,EAAQ3O,EAAOwH,GACjBvF,MAAM0M,GACR+B,EAAalJ,GAAK2L,IAElBzC,EAAalJ,GAAKmH,EAAQ,EAAI,EAAIuE,EAGtC,OAAOhP,KAAKsC,WAAWkK,EAAcrN,EAAEiB,MAAO,WAGhDN,aACI2C,MAACA,EAAKyM,OAAEA,EAAMzU,SAAEA,EAAQyO,KAAEA,EAAI9J,WAAEA,EAAUC,uBAAEA,IAE9C,IAAIgD,EAASrC,KAAKmP,OAAO1M,EAAOyM,EAAQzU,GAUxC,OARIyO,IACF7G,EAASrC,KAAKoJ,IAAI/G,EAAQ6G,IAExB9J,IACFiD,EACIpD,EAAce,KAAMqC,EAAQjD,EAAYC,IAGvCgD,EAGTvC,OAAOX,EAAa+P,EAAkBzU,GAEpCd,EAAiB,CAACwF,EAAG+P,GAAS,UAE9B,MAAME,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvBxU,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1BmU,EAAyC,iBAAxB7U,EAAS8U,WAE1B5C,EAAIpL,SAAU9G,EAASmB,SAAUuD,EAAE/E,OAEnCoV,EAAerQ,EAAE3E,QAAQ,GACzBiV,EAAaH,EAAiBnQ,EAAE3E,QAAQ,GAAK2E,EAAE3E,QAAQ,GACvDkV,EAAaJ,EAAiBnQ,EAAE3E,QAAQ,GAAK,EAC7CmV,EAAiBL,EAAiB,EAAInQ,EAAE3E,QAAQ,GAChDoV,EAAejD,EAAEnS,QAAQ,GACzBqV,EAAaP,EAAiB3C,EAAEnS,QAAQ,GAAKmS,EAAEnS,QAAQ,GACvDsV,EAAaR,EAAiB3C,EAAEnS,QAAQ,GAAK,EAC7CuV,EAAiBT,EAAiB,EAAI3C,EAAEnS,QAAQ,GAEhD0J,EAAQlE,KAAKa,SAAS1B,EAAEsB,QACxBuP,EAAQhQ,KAAKa,SAASqO,EAAOzO,QAC7BwP,EAAQtD,EAAE7Q,OAEhB,IAAK,IAAII,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EAAG,CAC3C,MAAMgU,EAAWhU,EAAIsT,EACfW,EAAWjU,EAAI0T,EACrB,IAAK,IAAIpT,EAAK,EAAGA,EAAK/B,EAASgC,YAAaD,EAAI,CAC9C,MAAM4T,EAAWD,EAAW3T,EAAKqT,EAC3BnT,EAAWF,EAAK/B,EAASE,aAAeM,EAC9C,IAAK,IAAIsD,EAAK,EAAGA,EAAK6Q,EAAc7Q,IAAM,CACxC,MAAMZ,EAAKjB,EAAW6B,EAAK1D,EAC3B,GAAI8C,EAAK,GAAKA,GAAMlD,EAASuC,SAC3B,SAEF,MAAMqT,EAAW9R,EAAK2Q,EAAO1U,QAAQ,GAC/B8V,EAAWJ,EAAWvS,EAAK8R,EACjC,IAAK,IAAIvS,EAAK,EAAGA,EAAKzC,EAAS0C,WAAYD,EAAI,CAC7C,MAAMqT,EAAWH,EAAWlT,EAAK4S,EAC3B1S,EAAWF,EAAKzC,EAASG,YAAcQ,EAC7C,IAAK,IAAIoD,EAAK,EAAGA,EAAK6Q,EAAa7Q,IAAM,CACvC,MAAMX,EAAKT,EAAWoB,EAAK1D,EAC3B,GAAI+C,EAAK,GAAKA,GAAMpD,EAAS8C,QAC3B,SAEF,MACMiT,EAAWF,EAAWzS,EAAK6R,EACjC,IAAIe,EAFaJ,EAAW7R,EAAK0Q,EAAO1U,QAAQ,GAGhD,IAAK,IAAIkW,EAAK,EAAGA,EAAKjW,EAAS8B,aAAcmU,EAAI,CAC/C,MAAMC,EAAOzM,EAAMsM,EAAWE,EAAKf,GACnC,IAAK,IAAIiB,EAAK,EAAGA,EAAKnW,EAASoW,cAAeD,EAC5CX,EAAMM,EAAWK,EAAKb,IAClBY,EAAOX,EAAMS,EAAWG,GAE9BH,GAAYhW,EAASoW,iBAOjC,OAAOlE,EAAEhJ,WAGX7D,OAAOX,EAAa+P,EAAkBzU,GAEpC,MAAMqW,EAAcrW,EAASqW,YACvB1B,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvB0B,EAAgBtW,EAASsW,cACzBlW,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBkW,EAAWvW,EAASS,QAAQ+V,MAC5B7V,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1BwR,EAAIpL,SAAmB9G,EAASmB,SAAUuD,EAAE/E,OAE5C8J,EAAQlE,KAAKa,SAAS1B,EAAEsB,QACxBuP,EAAQhQ,KAAKa,SAASqO,EAAOzO,QAC7BwP,EAAQtD,EAAE7Q,OAEhB,IAAK,IAAII,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EAAG,CAC3C,MAAMgU,EAAWhU,EAAIiD,EAAE3E,QAAQ,GACzB2V,EAAWjU,EAAIyQ,EAAEnS,QAAQ,GAC/B,IAAK,IAAI0W,EAAK,EAAGA,EAAKzW,EAAS0W,WAAYD,EAAI,CAC7C,MAAMd,EAAWD,EAAWe,EAAKvE,EAAEnS,QAAQ,GACrC4W,EAAWF,EAAKzW,EAAS4W,YAAcL,EAC7C,IAAK,IAAIM,EAAK,EAAGA,EAAKR,EAAaQ,IAAM,CACvC,MAAMC,EAAKH,EAAWE,EAAKP,EAC3B,GAAIQ,EAAK,GAAKA,GAAM9W,EAAS+W,QAC3B,SAEF,MAAMnB,EAAWiB,EAAKpC,EAAO1U,QAAQ,GAC/B8V,EAAWJ,EAAWqB,EAAKpS,EAAE3E,QAAQ,GAE3C,IAAK,IAAIgC,EAAK,EAAGA,EAAK/B,EAASgC,YAAaD,EAAI,CAC9C,MAAM+T,EAAWH,EAAW5T,EAAKmQ,EAAEnS,QAAQ,GACrCkC,EAAWF,EAAK/B,EAASE,aAAeM,EAC9C,IAAK,IAAIsD,EAAK,EAAGA,EAAK6Q,EAAc7Q,IAAM,CACxC,MAAMZ,EAAKjB,EAAW6B,EAAK1D,EAC3B,GAAI8C,EAAK,GAAKA,GAAMlD,EAASuC,SAC3B,SAEF,MAAMyU,EAAWpB,EAAW9R,EAAK2Q,EAAO1U,QAAQ,GAC1CgW,EAAWF,EAAW3S,EAAKwB,EAAE3E,QAAQ,GAC3C,IAAK,IAAI0C,EAAK,EAAGA,EAAKzC,EAAS0C,WAAYD,EAAI,CAC7C,MAAMwU,EAAWnB,EAAWrT,EAAKzC,EAASoW,YACpCzT,EAAWF,EAAKzC,EAASG,YAAcQ,EAC7C,IAAK,IAAIoD,EAAK,EAAGA,EAAK6Q,EAAa7Q,IAAM,CACvC,MAAMX,EAAKT,EAAWoB,EAAK1D,EAC3B,GAAI+C,EAAK,GAAKA,GAAMpD,EAAS8C,QAC3B,SAEF,MAAMkT,EAAWgB,EAAWjT,EAAK0Q,EAAO1U,QAAQ,GAC1CmX,EAAWnB,EAAW3S,EAAKpD,EAAS8B,WAC1C,IAAIqV,EAAWnB,EACf,IAAK,IAAIC,EAAK,EAAGA,EAAKjW,EAAS8B,aAAcmU,EAAI,CAC/C,MAAMC,EAAOzM,EAAMyN,EAAWjB,GAC9B,IAAK,IAAIE,EAAK,EAAGA,EAAKnW,EAASoW,cAAeD,EAC5CX,EAAMyB,EAAWd,IAAOD,EAAOX,EAAM4B,EAAWhB,GAElDgB,GAAYnX,EAASoW,mBASrC,OAAOlE,EAAEhJ,WAGX7D,eACI4M,EAAcwC,EACdzU,GACFd,EAAiB,CAAC+S,EAAIwC,GAAS,kBAE/B,MAAM2C,EAAKtQ,SAAmB9G,EAASqX,QAAS,WAC1CC,EAAWF,EAAG/V,OACd8Q,EAAW5M,KAAKa,SAAS6L,EAAGjM,QAC5BuR,EAAYhS,KAAKa,SAASqO,EAAOzO,SAChCwR,EAAOC,EAAOC,GAASjD,EAAO1U,SAC/B2B,UACJA,EAASiT,aACTA,EAAYC,YACZA,EAAW9S,WACXA,EAAUS,SACVA,EAAQO,QACRA,EAAOsT,YACPA,EAAWpU,UACXA,EAASU,SACTA,EAAQxC,aACRA,EAAYC,YACZA,EAAW2U,WACXA,GACE9U,EACE2X,EAAShD,EAAe,EAAI3U,EAASS,QAAQC,IAC7CkX,EAAUhD,EAAc,EAAI5U,EAASS,QAAQG,KAE7CiU,EAAgC,iBAAfC,EACjBC,EAAeqC,EAAGrX,QAAQ,GAC1BiV,EAAaH,EAAiBuC,EAAGrX,QAAQ,GAAKqX,EAAGrX,QAAQ,GACzDkV,EAAaJ,EAAiBuC,EAAGrX,QAAQ,GAAK,EAC9CmV,EAAiBL,EAAiB,EAAIuC,EAAGrX,QAAQ,GACjDoV,EAAelD,EAAGlS,QAAQ,GAC1BqV,EAAaP,EAAiB5C,EAAGlS,QAAQ,GAAKkS,EAAGlS,QAAQ,GACzDsV,EAAaR,EAAiB5C,EAAGlS,QAAQ,GAAK,EAC9CuV,EAAiBT,EAAiB,EAAI5C,EAAGlS,QAAQ,GAEvD,IAAK,IAAI0B,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIwU,EAAK,EAAGA,EAAKnU,IAAcmU,EAClC,IAAK,IAAI/S,EAAK,EAAGA,EAAKX,IAAYW,EAAI,CACpC,MAAMjB,EAAWiB,EAAKyU,EAChBzV,EAAQC,KAAKC,IAAI,EAAGD,KAAKiP,KAAKnP,EAAW/B,IACzC2X,EACF1V,KAAKG,IAAIN,GAAY2S,EAAe1S,GAAY/B,GAEpD,IAAK,IAAIkD,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CACnC,MAAMT,EAAWS,EAAKwU,EAChBhV,EAAQT,KAAKC,IAAI,EAAGD,KAAKiP,KAAKzO,EAAWxC,IACzC2X,EACF3V,KAAKG,IAAII,GAAWkS,EAAcjS,GAAYxC,GAElD,IAAI4X,EAAU,EACd,IAAK,IAAIhW,EAAKG,EAAOH,EAAK8V,IAAS9V,EAAI,CACrC,MAAM+B,EAAK/B,EAAK7B,EAAe+B,EAE/B,IAAK,IAAIQ,EAAKG,EAAOH,EAAKqV,IAASrV,EAAI,CACrC,MACMuV,EACF7C,EAAe1T,EAAI2T,EAAarT,EAAKsT,EAAa5S,EAChDwV,EAAYT,GAAS7C,EAAe,EAAI7Q,GAC1C2T,GAAS7C,EAAc,GAJhBnS,EAAKtC,EAAcwC,IAIO+U,EAAQzB,EAE7C,IAAK,IAAIE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvC4B,GAFc5F,EAAS6F,EAAW1C,EAAiBa,GACpCoB,EAAUU,EAAY9B,KAO3CmB,EAFiBvC,EAAetT,EAAIuT,EAAa9R,EAC7C+R,EAAa7R,EAAK8R,EAAiBe,GAClB8B,GAK7B,OAAOX,EAAGlO,WAGZ7D,eACI4M,EAAcwC,EACdzU,GACF,MAAMoX,EAAKtQ,SAAmB9G,EAASqX,QAAS,WAC1CC,EAAWF,EAAG/V,QACb6W,EAAMC,EAAMC,EAAMC,GAAQjB,EAAGrX,QAC9BoS,EAAW5M,KAAKa,SAAS6L,EAAGjM,SAC3BsS,EAAMC,EAAMC,EAAMC,GAAQxG,EAAGlS,QAC9BwX,EAAYhS,KAAKa,SAASqO,EAAOzO,SAChCwR,EAAOC,EAAOC,EAAOgB,GAASjE,EAAO1U,SACtC2B,UACJA,EAAS2U,YACTA,EAAW1B,aACXA,EAAYC,YACZA,EAAW9S,WACXA,EAAUiV,QACVA,EAAOxU,SACPA,EAAQO,QACRA,EAAOsT,YACPA,EAAWM,SACXA,EAAQ1U,UACRA,EAASU,SACTA,EAAQkU,YACRA,EAAW1W,aACXA,EAAYC,YACZA,GACEH,EACE2Y,EAAWtC,EAAc,EAAIrW,EAASS,QAAQ+V,MAC9CmB,EAAShD,EAAe,EAAI3U,EAASS,QAAQC,IAC7CkX,EAAUhD,EAAc,EAAI5U,EAASS,QAAQG,KAEnD,IAAK,IAAIa,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIwU,EAAK,EAAGA,EAAKnU,IAAcmU,EAElC,IAAK,IAAIa,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CACnC,MAAMH,EAAWG,EAAK6B,EAChBC,EAAQzW,KAAKC,IAAI,EAAGD,KAAKiP,KAAKuF,EAAWC,IACzCiC,EACF1W,KAAKG,IAAIoU,GAAWL,EAAcM,GAAYC,GAGlD,IAAK,IAAI1T,EAAK,EAAGA,EAAKX,IAAYW,EAAI,CACpC,MAAMjB,EAAWiB,EAAKyU,EAChBzV,EAAQC,KAAKC,IAAI,EAAGD,KAAKiP,KAAKnP,EAAW/B,IACzC2X,EACF1V,KAAKG,IAAIN,GAAY2S,EAAe1S,GAAY/B,GAEpD,IAAK,IAAIkD,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CACnC,MAAMT,EAAWS,EAAKwU,EAChBhV,EAAQT,KAAKC,IAAI,EAAGD,KAAKiP,KAAKzO,EAAWxC,IACzC2X,EACF3V,KAAKG,IAAII,GAAWkS,EAAcjS,GAAYxC,GAElD,IAAI4X,EAAU,EACd,IAAK,IAAItB,EAAKmC,EAAOnC,EAAKoC,IAASpC,EAAI,CACrC,MAAMI,EAAKJ,EAAKG,EAAcD,EAE9B,IAAK,IAAI5U,EAAKG,EAAOH,EAAK8V,IAAS9V,EAAI,CACrC,MAAM+B,EAAK/B,EAAK7B,EAAe+B,EAE/B,IAAK,IAAIQ,EAAKG,EAAOH,EAAKqV,IAASrV,EAAI,CACrC,MACMuV,EACFM,EAAO7W,EAAI8W,EAAO9B,EAAK+B,EAAOzW,EAAK0W,EAAOhW,EACxCwV,EAAYT,GAASnB,EAAc,EAAIQ,GACzCY,GAAS9C,EAAe,EAAI7Q,GAC5B4T,GAAS9C,EAAc,GALhBnS,EAAKtC,EAAcwC,IAKO+V,EAAQzC,EAE7C,IAAK,IAAIE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvC4B,GAFc5F,EAAS6F,EAAW7B,GACnBoB,EAAUU,EAAY9B,MAM7CmB,EAASY,EAAOzW,EAAI0W,EAAOrB,EAAKsB,EAAOlV,EAAKmV,EAAOjV,EAAK6S,GACpD8B,IAMd,OAAOX,EAAGlO,WAGZ7D,gBAAgBX,EAAauN,EAAcjS,GAEzCd,EAAiB,CAACwF,EAAGuN,GAAK,mBAE1B,MAAM/R,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBwU,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvBC,EAAyC,iBAAxB7U,EAAS8U,WAC1BgE,EAAKhS,SAAmB9G,EAAS+Y,YAAa,WAE9CnB,EAAU5X,EAASS,QAAQG,KAC3B+W,EAAS3X,EAASS,QAAQC,IAC1BiD,EAAO4B,KAAKqD,WAAWlE,GACvBsU,EAAQzT,KAAKqD,WAAWqJ,GAC9B,IAAK,IAAInO,EAAK,EAAGA,EAAK6Q,IAAgB7Q,EAAI,CACxC,MAAMmV,EAAQ9W,KAAKC,IAAI,EAAGD,KAAKiP,MAAMuG,EAAS7T,GAAM5D,IAC9C2X,EAAQ1V,KAAKG,IACftC,EAASgC,WAAYhC,EAASuC,SAAWoV,EAAS7T,GAAM5D,GAE5D,IAAK,IAAI6D,EAAK,EAAGA,EAAK6Q,IAAe7Q,EAAI,CACvC,MAAMmV,EAAQ/W,KAAKC,IAAI,EAAGD,KAAKiP,MAAMwG,EAAU7T,GAAM5D,IAC/C2X,EAAQ3V,KAAKG,IACftC,EAAS0C,UAAW1C,EAAS8C,QAAU8U,EAAU7T,GAAM5D,GAE3D,IAAK,IAAI8V,EAAK,EAAGA,EAAKjW,EAAS8B,aAAcmU,EAC3C,IAAK,IAAIE,EAAK,EAAGA,EAAKnW,EAASoW,cAAeD,EAAI,CAEhD,IAAI4B,EAAU,EACd,IAAK,IAAItW,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EACxC,IAAK,IAAIM,EAAKkX,EAAOlX,EAAK8V,IAAS9V,EAAI,CACrC,MAAMmB,EAAKY,EAAK/B,EAAK7B,EAAeyX,EACpC,IAAK,IAAIlV,EAAKyW,EAAOzW,EAAKqV,IAASrV,EAAI,CACrC,MAAMW,EAAKW,EAAKtB,EAAKtC,EAAcyX,EAEjCG,GADElD,EAEElR,EAAKK,IAAIvC,EAAGyB,EAAIE,EAAI6S,GAAM+C,EAAMhV,IAAIvC,EAAGM,EAAIU,EAAI0T,GAG/CxS,EAAKK,IAAIvC,EAAGwU,EAAI/S,EAAIE,GAAM4V,EAAMhV,IAAIvC,EAAG0U,EAAIpU,EAAIU,IAK3DqW,EAAG7U,IAAI8T,EAASjU,EAAIC,EAAIkS,EAAIE,KAKpC,OAAO2C,EAAG5P,WAGZ7D,gBAAgBX,EAAauN,EAAcjS,GAEzC,MAAM4W,EAAc5W,EAAS4W,YACvB1W,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBkW,EAAcrW,EAASqW,YACvB1B,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YAEvBuE,EAAKrS,SAAmB9G,EAAS+Y,YAAa,WAC9CK,EAAWD,EAAG9X,QACbgY,EAAMC,EAAMC,EAAMC,GAAQL,EAAGpZ,QAC9BoS,EAAW5M,KAAKa,SAAS6L,EAAGjM,SAC3BsS,EAAMC,EAAMC,EAAMC,GAAQxG,EAAGlS,QAC9BF,EAAU0F,KAAKa,SAAS1B,EAAEsB,SACzByT,EAAKC,EAAKC,EAAKC,GAAOlV,EAAE3E,QAEzB4Y,EAAW3Y,EAASS,QAAQ+V,MAC5BoB,EAAU5X,EAASS,QAAQG,KAC3B+W,EAAS3X,EAASS,QAAQC,IAEhC,IAAK,IAAImW,EAAK,EAAGA,EAAKR,IAAeQ,EAAI,CACvC,MAAMgD,EAAQ1X,KAAKC,IAAI,EAAGD,KAAKiP,MAAMuH,EAAW9B,GAAMD,IAChDiC,EAAQ1W,KAAKG,IACftC,EAAS0W,UAAW1W,EAAS+W,QAAU4B,EAAW9B,GAAMD,GACtDhB,EAAWiB,EAAKwC,EAEtB,IAAK,IAAIvV,EAAK,EAAGA,EAAK6Q,IAAgB7Q,EAAI,CACxC,MAAMmV,EAAQ9W,KAAKC,IAAI,EAAGD,KAAKiP,MAAMuG,EAAS7T,GAAM5D,IAC9C2X,EAAQ1V,KAAKG,IACftC,EAASgC,WACRhC,EAASuC,SAAWoV,EAAS7T,GAAM5D,GAClC8W,EAAWlT,EAAKwV,EAAO1D,EAE7B,IAAK,IAAI7R,EAAK,EAAGA,EAAK6Q,IAAe7Q,EAAI,CACvC,MAAMmV,EAAQ/W,KAAKC,IAAI,EAAGD,KAAKiP,MAAMwG,EAAU7T,GAAM5D,IAC/C2X,EAAQ3V,KAAKG,IACftC,EAAS0C,UACR1C,EAAS8C,QAAU8U,EAAU7T,GAAM5D,GAClC6V,EAAWjS,EAAKwV,EAAOvC,EAE7B,IAAK,IAAIf,EAAK,EAAGA,EAAKjW,EAAS8B,aAAcmU,EAAI,CAC/C,MAAMkB,EAAWlB,EAAKuD,EAAOxD,EAE7B,IAAK,IAAIG,EAAK,EAAGA,EAAKnW,EAASoW,cAAeD,EAAI,CAChD,IAAI4B,EAAU,EACd,IAAK,IAAItW,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EAAG,CAC3C,MAAMgU,EAAWhU,EAAIgY,EACf/D,EAAWjU,EAAI6W,EAErB,IAAK,IAAI7B,EAAKoD,EAAOpD,EAAKoC,IAASpC,EAAI,CACrC,MACMZ,GADKgB,EAAKJ,EAAKG,EAAc+B,GACbe,EAAMjE,EACtBE,EAAWc,EAAK8B,EAAO7C,EAE7B,IAAK,IAAI3T,EAAKkX,EAAOlX,EAAK8V,IAAS9V,EAAI,CACrC,MACMgU,GADKjS,EAAK/B,EAAK7B,EAAeyX,GACdgC,EAAM9D,EACtBC,EAAW/T,EAAKyW,EAAO7C,EAE7B,IAAK,IAAIlT,EAAKyW,EAAOzW,EAAKqV,IAASrV,EAAI,CACrC,MAEMwU,EAAWxU,EAAKgW,EAAO3C,EAE7BiC,GACIlY,GALOkE,EAAKtB,EAAKtC,EAAcyX,GACbgC,EAAM7D,EAILE,GAAM9D,EAAS8E,EAAWd,MAKzDiD,EAASjC,EAAWhB,GAAM4B,MAMpC,OAAOoB,EAAGjQ,WAGZ7D,sBACI2C,MAACA,EAAKyM,OAAEA,EAAMzU,SAAEA,EAAQyO,KAAEA,EAAI9J,WAAEA,EAAUC,uBAAEA,IAE9C,IAAIgD,EAASrC,KAAKuU,gBAAgB9R,EAAOyM,EAAQzU,GAUjD,OARIyO,IACF7G,EAASrC,KAAKoJ,IAAI/G,EAAQ6G,IAExB9J,IACFiD,EACIpD,EAAce,KAAMqC,EAAQjD,EAAYC,IAGvCgD,EAGTvC,gBACIX,EAAa+P,EACbzU,GACFd,EAAiB,CAACwF,EAAG+P,GAAS,mBAE9B,MAAME,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvBxU,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1BqZ,EAAQ/Z,EAASoW,YAAcpW,EAAS8B,WACxCoQ,EAAIpL,SAAU9G,EAASmB,SAAUuD,EAAE/E,OACnC8J,EAAQlE,KAAKa,SAAS1B,EAAEsB,QACxBuP,EAAQhQ,KAAKa,SAASqO,EAAOzO,QAC7BwP,EAAQtD,EAAE7Q,OAEhB,IAAK,IAAII,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EAAG,CAC3C,MAAMgU,EAAWhU,EAAIiD,EAAE3E,QAAQ,GACzB2V,EAAWjU,EAAIyQ,EAAEnS,QAAQ,GAC/B,IAAK,IAAIgC,EAAK,EAAGA,EAAK/B,EAASgC,YAAaD,EAAI,CAC9C,MAAM4T,EAAWD,EAAW3T,EAAKmQ,EAAEnS,QAAQ,GACrCkC,EAAWF,EAAK/B,EAASE,aAAeS,EAC9C,IAAK,IAAImD,EAAK,EAAGA,EAAK6Q,IAAgB7Q,EAAI,CACxC,MAAMZ,EAAKjB,EAAW6B,EAAK1D,EAC3B,GAAI8C,EAAK,GAAKA,GAAMlD,EAASuC,SAC3B,SAEF,MAAMqT,EAAW9R,EAAK2Q,EAAO1U,QAAQ,GAC/B8V,EAAWJ,EAAWvS,EAAKwB,EAAE3E,QAAQ,GAC3C,IAAK,IAAI0C,EAAK,EAAGA,EAAKzC,EAAS0C,WAAYD,EAAI,CAC7C,MAAMqT,EAAWH,EAAWlT,EAAKyP,EAAEnS,QAAQ,GACrC4C,EAAWF,EAAKzC,EAASG,YAAcK,EAC7C,IAAK,IAAIuD,EAAK,EAAGA,EAAK6Q,IAAe7Q,EAAI,CACvC,MAAMX,EAAKT,EAAWoB,EAAK1D,EAC3B,GAAI+C,EAAK,GAAKA,GAAMpD,EAAS8C,QAC3B,SAEF,MAAMkU,EAAWpB,EAAW7R,EAAK0Q,EAAO1U,QAAQ,GAC1CgW,EAAWF,EAAWzS,EAAKpD,EAAS8B,WAC1C,IAAImV,EAAWnB,EACXE,EAAWgB,EACf,IAAK,IAAIf,EAAK,EAAGA,EAAKjW,EAAS8B,aAAcmU,EAAI,CAC/C,MAAMC,EAAOzM,EAAMsM,EAAWE,GAC9B,IAAK,IAAI+D,EAAI,EAAGA,EAAID,IAASC,EAC3BxE,EAAMyB,EAAW+C,IAAM9D,EAAOX,EAAMS,EAAWgE,GAEjD/C,GAAY8C,EACZ/D,GAAY+D,OAQxB,OAAO7H,EAAEhJ,WAGX7D,wBACI4M,EAAcwC,EACdzU,GACFd,EAAiB,CAAC+S,EAAIwC,GAAS,2BAE/B,MAAM2C,EAAKtQ,SAAmB9G,EAASqX,QAAS,WAC1CC,EAAWF,EAAG/V,QACb6W,EAAMC,EAAMC,GAAQhB,EAAGrX,QACxBoS,EAAW5M,KAAKa,SAAS6L,EAAGjM,SAC3BsS,EAAMC,EAAMC,GAAQvG,EAAGlS,QACxBwX,EAAYhS,KAAKa,SAASqO,EAAOzO,SAChCwR,EAAOC,EAAOC,GAASjD,EAAO1U,SAC/B2B,UACJA,EAASiT,aACTA,EAAYC,YACZA,EAAW9S,WACXA,EAAUS,SACVA,EAAQO,QACRA,EAAOsT,YACPA,EAAWpU,UACXA,EAASU,SACTA,EAAQxC,aACRA,EAAYC,YACZA,GACEH,EACE2X,EAAShD,EAAe,EAAI3U,EAASS,QAAQC,IAC7CkX,EAAUhD,EAAc,EAAI5U,EAASS,QAAQG,KAC7CmZ,EAAQ3D,EAActU,EAE5B,IAAK,IAAIL,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIwU,EAAK,EAAGA,EAAKnU,IAAcmU,EAClC,IAAK,IAAI/S,EAAK,EAAGA,EAAKX,IAAYW,EAAI,CACpC,MAAMjB,EAAWiB,EAAKyU,EAChBzV,EAAQC,KAAKC,IAAI,EAAGD,KAAKiP,KAAKnP,EAAW/B,IACzC2X,EACF1V,KAAKG,IAAIN,GAAY2S,EAAe1S,GAAY/B,GAEpD,IAAK,IAAIkD,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CACnC,MAAMT,EAAWS,EAAKwU,EAChBhV,EAAQT,KAAKC,IAAI,EAAGD,KAAKiP,KAAKzO,EAAWxC,IACzC2X,EACF3V,KAAKG,IAAII,GAAWkS,EAAcjS,GAAYxC,GAElD,IAAI4X,EAAU,EACd,IAAK,IAAIhW,EAAKG,EAAOH,EAAK8V,IAAS9V,EAAI,CACrC,MAAM+B,EAAK/B,EAAK7B,EAAe+B,EAE/B,IAAK,IAAIQ,EAAKG,EAAOH,EAAKqV,IAASrV,EAAI,CACrC,MACMuV,EAAWM,EAAO7W,EAAI8W,EAAOxW,EAAKyW,EAAO/V,EACzCwV,EAAYT,GAAS7C,EAAe,EAAI7Q,GAC1C2T,GAAS7C,EAAc,GAHhBnS,EAAKtC,EAAcwC,IAGO+U,EAAQzB,EAE7C,IAAK,IAAIgE,EAAK,EAAGA,EAAKF,IAASE,EAAI,CAIjClC,GAFc5F,EAAS6F,GADZ/B,EAAK8D,EAAQE,IAET1C,EAAUU,EAAYgC,KAK3C3C,EAASY,EAAOzW,EAAI0W,EAAOjV,EAAKkV,EAAOhV,EAAK6S,GAAM8B,GAK1D,OAAOX,EAAGlO,WAGZ7D,yBACIX,EAAauN,EAAcjS,GAC7Bd,EAAiB,CAACwF,EAAGuN,GAAK,4BAE1B,MAAM/R,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBwU,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvBkE,EAAKhS,SAAmB9G,EAAS+Y,YAAa,WAE9CnB,EAAU5X,EAASS,QAAQG,KAC3B+W,EAAS3X,EAASS,QAAQC,IAC1BqZ,EAAQ/Z,EAASoW,YAAcpW,EAAS8B,WAExC6B,EAAO4B,KAAKqD,WAAWlE,GACvBsU,EAAQzT,KAAKqD,WAAWqJ,GAC9B,IAAK,IAAInO,EAAK,EAAGA,EAAK6Q,IAAgB7Q,EAAI,CACxC,MAAMmV,EAAQ9W,KAAKC,IAAI,EAAGD,KAAKiP,MAAMuG,EAAS7T,GAAM5D,IAC9C2X,EAAQ1V,KAAKG,IACftC,EAASgC,WAAYhC,EAASuC,SAAWoV,EAAS7T,GAAM5D,GAE5D,IAAK,IAAI6D,EAAK,EAAGA,EAAK6Q,IAAe7Q,EAAI,CACvC,MAAMmV,EAAQ/W,KAAKC,IAAI,EAAGD,KAAKiP,MAAMwG,EAAU7T,GAAM5D,IAC/C2X,EAAQ3V,KAAKG,IACftC,EAAS0C,UAAW1C,EAAS8C,QAAU8U,EAAU7T,GAAM5D,GAE3D,IAAK,IAAIgW,EAAK,EAAGA,EAAKnW,EAASoW,cAAeD,EAAI,CAChD,MAAMF,EAAK9T,KAAK+X,MAAM/D,EAAK4D,GACrBE,EAAK9D,EAAK4D,EAEhB,IAAIhC,EAAU,EACd,IAAK,IAAItW,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EACxC,IAAK,IAAIM,EAAKkX,EAAOlX,EAAK8V,IAAS9V,EAAI,CACrC,MAAMmB,EAAKY,EAAK/B,EAAK7B,EAAeyX,EACpC,IAAK,IAAIlV,EAAKyW,EAAOzW,EAAKqV,IAASrV,EAAI,CACrC,MAAMW,EAAKW,EAAKtB,EAAKtC,EAAcyX,EACnCG,GAAWpU,EAAKK,IAAIvC,EAAGyB,EAAIE,EAAI6S,GAAM+C,EAAMhV,IAAIvC,EAAGM,EAAIU,EAAI0T,IAIhE2C,EAAG7U,IAAI8T,EAASjU,EAAIC,EAAIkS,EAAIgE,KAIlC,OAAOnB,EAAG5P,WAGZ7D,KAAuBX,EAAMyV,GAE3B,OADAjb,EAAiBwF,EAAG,QACbL,EAAKkB,KAAKqD,WAAWlE,GAAIyV,GAGlC9U,OAAyBX,EAAM0V,EAAmB9Q,GAChDpK,EAAiB,CAACwF,EAAG0V,GAAU,UAE/B,MAAMC,EAAqB3V,EAAEiB,MAAMmE,QAC7BwQ,EAAgB/U,KAAKa,SAASgU,EAAQpU,QAC5CqU,EAAS/Q,GAAQgR,EAAc/R,OAC/B,MAAMX,EAASd,SAAUuT,EAAU3V,EAAE/E,OAC/BgE,EAAO4B,KAAKqD,WAAWlE,GAE7B,IAAK,IAAImE,EAAI,EAAGA,EAAIjB,EAAOM,OAAQW,EAAG,CACpC,MAAMW,EAAS5B,EAAOmB,WAAWF,GAE3B0R,EAAwB/Q,EAAOM,QACrCyQ,EAAYjR,GAAQgR,EAAc9Q,EAAOF,IAEzC,MAAMkR,EAAgB7W,EAAK8W,WAAWF,GACtC3S,EAAOvG,OAAOwH,GAAKlF,EAAKtC,OAAOmZ,GAEjC,OAAO5S,EAAOsB,WAGhB7D,eACIX,EAAMgW,EAAsBC,GAC9Bzb,EAAiB,CAACwF,GAAI,kBAEtB,MAAM0K,EAAOsL,EAAWE,OAAO,CAACpP,EAAG/J,IAAM+J,EAAI/J,GAEvCoZ,EAAW/U,eAAagV,YAAYpW,EAAEiB,MAAO+U,EAAYtL,GACzD2L,EACFjV,eAAakV,YAAYH,EAAStS,OAAQmS,EAAWnS,QACnD0S,EACFnV,eAAaoV,oBAAoBxW,EAAEiB,MAAO+U,EAAYtL,GACpD+L,EACFrV,eAAasV,oBAAoBT,EAAOD,EAAWnS,QACjD8S,EACFvV,eAAawV,aAAaL,EAAkBN,EAAOD,EAAWnS,QAElE,OAAOgT,YAAa7W,EAAEsF,QAAQ6Q,GAAWE,GAC7B/Q,QAAQiR,GACRnR,MAAMqR,EAAkBE,GAGtChW,QAAQX,EAAa1E,GAGnB,OAFAd,EAAiBwF,EAAG,WAEb9E,EADS2F,KAAKa,SAAS1B,EAAEsB,QACXtB,EAAEiB,MAAOjB,EAAE/E,MAAO+E,EAAE3E,QAASC,EAAU,OAChDkJ,WAGd7D,gBACI4M,EAAcvN,EAAawN,EAC3BlS,GACFd,EAAiB,CAACwF,EAAGwN,GAAI,mBAEzB,MAAMrS,EAAU0F,KAAKa,SAAS1B,EAAEsB,QAC1BwV,EAAYta,SACdlB,EAASmB,SAAUuD,EAAE/E,MACrB4D,EAAiB1D,EAAS6E,EAAEiB,MAAOjB,EAAE/E,MAAOK,GAAUqB,QACpDnB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD0W,EAAKtQ,SAAmBpC,EAAEiB,MAAO,WAEjCqT,EAAQzT,KAAKqD,WAAWqJ,GAE9B,IAAK,IAAIxQ,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EACxC,IAAK,IAAII,EAAI,EAAGA,EAAI7B,EAAS8B,aAAcD,EACzC,IAAK,IAAI4Z,EAAM,EAAGA,EAAMzb,EAASuC,WAAYkZ,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAM1b,EAAS8C,UAAW4Y,EAAK,CAE/C,MAAMC,EAAYF,EAAMjb,EAClBob,EAAYF,EAAM/a,EACxB,IAAIoX,EAAU,EACd,IAAK,IAAIjU,EAAK,EAAGA,EAAKxD,EAAuBwD,GAAM1D,EAAgB,CACjE,MAAMyb,GAAOF,EAAY7X,GAAM5D,EAC/B,KAAI2b,EAAM,GAAKA,GAAO7b,EAASgC,WAC3BG,KAAKyM,MAAMiN,KAASA,GAGxB,IAAK,IAAI9X,EAAK,EAAGA,EAAKxD,EAAsBwD,GAAM1D,EAAe,CAC/D,MAAMyb,GAAOF,EAAY7X,GAAM5D,EAC/B,GAAI2b,EAAM,GAAKA,GAAO9b,EAAS0C,UAC3BP,KAAKyM,MAAMkN,KAASA,EACtB,SAEF,MAIMC,EAJSzb,EAAwBC,EACnC,EAAKib,EAAUxX,IAAIvC,EAAGoa,EAAKC,EAAKja,KACrBiC,EAAKvD,EAAuBwD,EAEV,EAAI,EACxB,IAATgY,IAKJhE,GADciB,EAAMhV,IAAIvC,EAAGoa,EAAKC,EAAKja,GAClBka,IAGvB3E,EAAGnT,IAAI8T,EAAStW,EAAGga,EAAKC,EAAK7Z,GAKrC,OAAOuV,EAAGlO,WAGZ7D,gBAAgB4M,EAAcvN,EAAa1E,GAEzCd,EAAiB,CAAC+S,EAAIvN,GAAI,mBAE1B,MAAMxE,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBwU,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvBxU,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD0W,EAAKtQ,SAAmBpC,EAAEiB,MAAO,WAEjCqW,EAAgB,GAAKrH,EAAeC,GAEpCoE,EAAQzT,KAAKqD,WAAWqJ,GAE9B,IAAK,IAAIxQ,EAAI,EAAGA,EAAIzB,EAAS0B,YAAaD,EACxC,IAAK,IAAII,EAAI,EAAGA,EAAI7B,EAAS8B,aAAcD,EACzC,IAAK,IAAI4Z,EAAM,EAAGA,EAAMzb,EAASuC,WAAYkZ,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAM1b,EAAS8C,UAAW4Y,EAAK,CAE/C,MAAMC,EAAYF,EAAMjb,EAClBob,EAAYF,EAAM/a,EACxB,IAAIoX,EAAU,EACd,IAAK,IAAIjU,EAAK,EAAGA,EAAKxD,EAAuBwD,GAAM1D,EAAgB,CACjE,MAAMyb,GAAOF,EAAY7X,GAAM5D,EAC/B,KAAI2b,EAAM,GAAKA,GAAO7b,EAASgC,WAC3BG,KAAKyM,MAAMiN,KAASA,GAGxB,IAAK,IAAI9X,EAAK,EAAGA,EAAKxD,EAAsBwD,GAAM1D,EAAe,CAC/D,MAAMyb,GAAOF,EAAY7X,GAAM5D,EAC3B2b,EAAM,GAAKA,GAAO9b,EAAS0C,UAC3BP,KAAKyM,MAAMkN,KAASA,IAKxB/D,GADciB,EAAMhV,IAAIvC,EAAGoa,EAAKC,EAAKja,KAIzCuV,EAAGnT,IAAI8T,EAAUiE,EAAeva,EAAGga,EAAKC,EAAK7Z,GAKrD,OAAOuV,EAAGlO,WAGJ7D,OACJX,EAAa1E,EACbC,GACFf,EAAiBwF,EAAG,UAEpB,MAAMkS,EAAc5W,EAAS4W,YACvB1W,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBmW,EAAgBtW,EAASsW,cACzBlW,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzB4b,EAAuBjc,EAASic,qBAChC3b,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCgW,EAAWvW,EAASS,QAAQ+V,MAC5BhW,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BC,EACY,QAAbZ,EAAqBa,OAAOC,kBACPD,OAAOE,kBAE3BnB,EAAU0F,KAAKa,SAAS1B,EAAEsB,QAC1B/E,EAAS6F,SAAU9G,EAASmB,SAAUuD,EAAE/E,OACxCyB,EAAaH,EAAOI,OAEpBC,EAAqBtB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAChEnB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GACvC+a,EACFlc,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAC9DI,EAAmBvB,EAASmB,SAAS,GAAKnB,EAASmB,SAAS,GAC5DK,EAAmBxB,EAASmB,SAAS,GAE3C,IAAK,IAAIgb,EAAQ,EAAGA,EAAQnc,EAAS0B,YAAaya,EAAO,CACvD,MAAMxa,EAAoBwa,EAAQ7a,EAC5BM,EAAmBua,EAAQzX,EAAE3E,QAAQ,GAC3C,IAAK,IAAIqc,EAAU,EAAGA,EAAUpc,EAAS8B,aAAcsa,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAASrc,EAAS0W,WAAY2F,EAAQ,CACzD,MAAMC,EAAeD,EAASzF,EAAcL,EAC5C,IAAIgG,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAajG,EAEf,MAAMkG,EACFra,KAAKG,IAAItC,EAAS+W,QAASkF,EAAuBK,GAChDG,EACF9a,EAAoB0a,EAASH,EACjC,IAAK,IAAIQ,EAAO,EAAGA,EAAO1c,EAASgC,YAAa0a,EAAM,CACpD,MAAMC,EAAaD,EAAOxc,EAAeM,EACzC,IAAIoc,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWxc,EAEb,MAAMyc,EACF1a,KAAKG,IAAItC,EAASuC,SAAUjC,EAAwBqc,GAClDna,EAAkBia,EAAoBC,EAAOnb,EACnD,IAAK,IAAIub,EAAO,EAAGA,EAAO9c,EAAS0C,WAAYoa,EAAM,CACnD,MAAMC,EAAaD,EAAO3c,EAAcQ,EACxC,IAAIqc,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW3c,EAEb,MAAM4c,EACF9a,KAAKG,IAAItC,EAAS8C,QAASvC,EAAuBwc,GAEhDG,EAAkB1a,EAAkBsa,EAAOtb,EACjD,IAAIuB,EAAclC,EACdmC,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAIka,EAASZ,EAAWY,EAASX,EACjCW,GAAU7G,EAAe,CAC5B,MAAM8G,EAAexb,EAAmBub,EAASzY,EAAE3E,QAAQ,GAC3D,IAAK,IAAIsd,EAAOT,EAASS,EAAOR,EAC3BQ,GAAQjd,EAAgB,CAC3B,MAAMkd,EAAaF,EAAeC,EAAO3Y,EAAE3E,QAAQ,GACnD,IAAK,IAAIwd,EAAOP,EAASO,EAAON,EAC3BM,GAAQld,EAAe,CAC1B,MACMgD,EAAQxD,EADKyd,EAAaC,EAAO7Y,EAAE3E,QAAQ,GACdqc,GAOnC,GANkB,QAAbnc,GAAsBoD,EAAQN,EACjCA,EAAcM,EACQ,QAAbpD,IACT+C,GAAYK,EACZJ,KAEEK,MAAMP,GACR,MAGJ,GAAIO,MAAMP,GACR,MAGJ,GAAIO,MAAMP,GACR,MAIJ3B,EADqB8b,EAAkBd,GAEtB,QAAbnc,EAAqB+C,EAAWC,EAAQF,KAMtD,OAAO9B,EAAOiI,WAGhB7D,UAAUX,EAAa1E,GAGrB,OAFAd,EAAiBwF,EAAG,aAEba,KAAKiY,OAAO9Y,EAAG1E,EAAU,OAAOyd,UAGzCpY,kBACI4M,EAAcvN,EAAa1E,GAC7Bd,EAAiB,CAAC+S,EAAIvN,GAAI,qBAE1B,MAAMkS,EAAc5W,EAAS4W,YACvB1W,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBkW,EAAcrW,EAASqW,YACvB1B,EAAe3U,EAAS2U,aACxBC,EAAc5U,EAAS4U,YACvB0B,EAAgBtW,EAASsW,cACzBlW,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzB4b,EAAuBjc,EAASic,qBAChC3b,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCgW,EAAW0F,EAAuB,EAAIjc,EAASS,QAAQ+V,MACvD7V,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD0W,EAAKtQ,SAAmBpC,EAAEiB,MAAO,WAEjCqW,EAAgB,GAAK3F,EAAc1B,EAAeC,GAElDoE,EAAQzT,KAAKqD,WAAWqJ,GAE9B,IAAK,IAAIkK,EAAQ,EAAGA,EAAQnc,EAAS0B,YAAaya,EAChD,IAAK,IAAIC,EAAU,EAAGA,EAAUpc,EAAS8B,aAAcsa,EACrD,IAAK,IAAIsB,EAAU,EAAGA,EAAU1d,EAAS+W,UAAW2G,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ3d,EAASuC,WAAYob,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ5d,EAAS8C,UAAW8a,EAAO,CAErD,MAAMC,EAAgBH,EAAUnH,EAC1BuH,EAAcH,EAAQnd,EACtBud,EAAcH,EAAQjd,EAC5B,IAAIoX,EAAU,EACd,IAAK,IAAIiG,EAAS,EAAGA,EAAS/B,EACzB+B,GAAU1H,EAAe,CAC5B,MAAM2H,GAAWJ,EAAgBG,GAAUpH,EAC3C,KAAIqH,EAAU,GAAKA,GAAWje,EAAS0W,UACnCvU,KAAKyM,MAAMqP,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO5d,EACrB4d,GAAQ9d,EAAgB,CAC3B,MAAM+d,GAASL,EAAcI,GAAQhe,EACrC,KAAIie,EAAQ,GAAKA,GAASne,EAASgC,WAC/BG,KAAKyM,MAAMuP,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO7d,EACrB6d,GAAQ/d,EAAe,CAC1B,MAAMge,GAASN,EAAcK,GAAQje,EACjCke,EAAQ,GAAKA,GAASre,EAAS0C,UAC/BP,KAAKyM,MAAMyP,KAAWA,IAM1BtG,GADIiB,EAAMhV,IAAImY,EAAO8B,EAASE,EAAOE,EAAOjC,MAKlDhF,EAAGnT,IACC8T,EAAUiE,EAAeG,EAAOuB,EAASC,EAAOC,EAChDxB,GAMd,OAAOhF,EAAGlO,WAGZ7D,UAAUX,EAAa1E,GAGrB,OAFAd,EAAiBwF,EAAG,aAEba,KAAKiY,OAAO9Y,EAAG1E,EAAU,OAAOyd,UAGjCpY,mBAAmBX,EAAa1E,GAEtC,MAAM0D,EAAeoD,SAAU9G,EAASmB,SAAU,SAC5CyV,EAAc5W,EAAS4W,YACvB1W,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBmW,EAAgBtW,EAASsW,cACzBlW,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzB4b,EAAuBjc,EAASic,qBAChC3b,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCgW,EAAWvW,EAASS,QAAQ+V,MAC5BhW,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3B+C,EAAO4B,KAAKqD,WAAWlE,GAC7B,IAAK,IAAIyX,EAAQ,EAAGA,EAAQnc,EAAS0B,YAAaya,EAChD,IAAK,IAAIC,EAAU,EAAGA,EAAUpc,EAAS8B,aAAcsa,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAASrc,EAAS0W,WAAY2F,EAAQ,CACzD,MAAMC,EAAeD,EAASzF,EAAcL,EAC5C,IAAIgG,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAajG,EAEf,MAAMkG,EACFra,KAAKG,IAAItC,EAAS+W,QAASkF,EAAuBK,GACtD,IAAK,IAAII,EAAO,EAAGA,EAAO1c,EAASgC,YAAa0a,EAAM,CACpD,MAAMC,EAAaD,EAAOxc,EAAeM,EACzC,IAAIoc,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWxc,EAEb,MAAMyc,EACF1a,KAAKG,IAAItC,EAASuC,SAAUjC,EAAwBqc,GACxD,IAAK,IAAIG,EAAO,EAAGA,EAAO9c,EAAS0C,WAAYoa,EAAM,CACnD,MAAMC,EAAaD,EAAO3c,EAAcQ,EACxC,IAAIqc,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW3c,EAEb,MAAM4c,EACF9a,KAAKG,IAAItC,EAAS8C,QAASvC,EAAuBwc,GAGtD,IAAInZ,EAAW9C,OAAOC,kBAClB8C,GAAe,EAEnB,IAAK,IAAIsZ,EAASZ,EAAWY,EAASX,EACjCW,GAAU7G,EAAe,CAC5B,MAAM0H,EAASb,EAASb,EACxB,IAAK,IAAIe,EAAOT,EAASS,EAAOR,EAC3BQ,GAAQjd,EAAgB,CAC3B,MAAM8d,EAAOb,EAAOV,EACpB,IAAK,IAAIY,EAAOP,EAASO,EAAON,EAC3BM,GAAQld,EAAe,CAC1B,MAAM+d,EAAOb,EAAOR,EACd1Z,EAAQM,EAAKK,IAAImY,EAAOgB,EAAQE,EAAME,EAAMnB,GAC9C/Y,GAASO,IACXA,EAAWP,EACXQ,EAAcma,EAAS1d,EACfC,EACJ2d,EAAO5d,EAAwB8d,KAM3C1a,EAAaO,IAAIJ,EAAasY,EAAOE,EAAQK,EAAMI,EAAMV,KAMnE,OAAO1Y,EAAawF,WAGtB7D,kBACI4M,EAAcvN,EAAawN,EAC3BlS,GACFd,EAAiB,CAACwF,EAAGwN,GAAI,qBAEzB,MAAMxO,EAAe6B,KAAK+Y,mBAAmB5Z,EAAG1E,GAC1C4W,EAAc5W,EAAS4W,YACvB1W,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBmW,EAAgBtW,EAASsW,cACzBlW,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzB4b,EAAuBjc,EAASic,qBAChC3b,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCgW,EAAW0F,EAAuB,EAAIjc,EAASS,QAAQ+V,MACvD7V,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD0W,EAAKtQ,SAAmBpC,EAAEiB,MAAO,WAEjC6V,EAAYjW,KAAKqD,WAAWlF,GAC5BsV,EAAQzT,KAAKqD,WAAWqJ,GAE9B,IAAK,IAAIkK,EAAQ,EAAGA,EAAQnc,EAAS0B,YAAaya,EAChD,IAAK,IAAIC,EAAU,EAAGA,EAAUpc,EAAS8B,aAAcsa,EACrD,IAAK,IAAIsB,EAAU,EAAGA,EAAU1d,EAAS+W,UAAW2G,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ3d,EAASuC,WAAYob,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ5d,EAAS8C,UAAW8a,EAAO,CAErD,MAAMC,EAAgBH,EAAUnH,EAC1BuH,EAAcH,EAAQnd,EACtBud,EAAcH,EAAQjd,EAC5B,IAAIoX,EAAU,EACd,IAAK,IAAIiG,EAAS,EAAGA,EAAS/B,EACzB+B,GAAU1H,EAAe,CAC5B,MAAM2H,GAAWJ,EAAgBG,GAAUpH,EAC3C,KAAIqH,EAAU,GAAKA,GAAWje,EAAS0W,UACnCvU,KAAKyM,MAAMqP,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO5d,EACrB4d,GAAQ9d,EAAgB,CAC3B,MAAM+d,GAASL,EAAcI,GAAQhe,EACrC,KAAIie,EAAQ,GAAKA,GAASne,EAASgC,WAC/BG,KAAKyM,MAAMuP,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO7d,EACrB6d,GAAQ/d,EAAe,CAC1B,MAAMge,GAASN,EAAcK,GAAQje,EACrC,GAAIke,EAAQ,GAAKA,GAASre,EAAS0C,UAC/BP,KAAKyM,MAAMyP,KAAWA,EACxB,SAGF,MAQMtC,EARSE,EACP3b,EAAwBC,EAC5B,EACAib,EAAUxX,IAAImY,EAAO8B,EAASE,EAAOE,EAAOjC,KAE5C4B,EAAS1d,EAAwBC,EACjC2d,EAAO3d,EAAuB6d,EAED,EAAI,EACxB,IAATrC,IAMJhE,GADIiB,EAAMhV,IAAImY,EAAO8B,EAASE,EAAOE,EAAOjC,GACzBL,KAIzB3E,EAAGnT,IAAI8T,EAASoE,EAAOuB,EAASC,EAAOC,EAAOxB,GAMxD,OAAOhF,EAAGlO,WAGZ7D,KAAuBX,EAAM/E,GAC3B,OAAOmG,eAAayY,WAAW7Z,EAAG/E,EAAO4F,MAG3CF,QAAQX,EAAa1E,GAInB,OAHAd,EAAiBwF,EAAG,WACpBxF,EAAiBwF,EAAG,WAEb9E,EADS2F,KAAKa,SAAS1B,EAAEsB,QACXtB,EAAEiB,MAAOjB,EAAE/E,MAAO+E,EAAE3E,QAASC,EAAU,OAChDkJ,WACAuU,UAGdpY,eACIX,EAAa8Z,EAAmBC,EAChCC,GACFxf,EAAiBwF,EAAG,kBAEpB,MAAOyX,EAAOwC,EAAWC,EAAUC,GAAena,EAAEiB,MAC9C9F,EAAU0F,KAAKa,SAAS1B,EAAEsB,QAC1B4B,EAAS,IAAIuJ,aACf1R,OAAK+I,cAAc,CAAC2T,EAAOqC,EAAWC,EAAUI,KAE9CC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAElD,IAAIO,EAAY,EAChB,MAAMC,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAChD,IAAK,IAAItd,EAAI,EAAGA,EAAI0a,EAAO1a,IACzB,IAAK,IAAI0d,EAAI,EAAGA,EAAIX,EAAWW,IAAK,CAClC,MAAMC,EAAgBH,EAAwBE,EACxCE,EAAiBld,KAAKyM,MAAMwQ,GAC5BE,EAAUF,EAAgBC,EAC1BE,EAAgBpd,KAAKG,IAAIqc,EAAY,EAAGxc,KAAKiP,KAAKgO,IAClDI,EAAe/d,EAAIiD,EAAE3E,QAAQ,GAAKsf,EAAiB3a,EAAE3E,QAAQ,GAC7D0f,EAAehe,EAAIiD,EAAE3E,QAAQ,GAAKwf,EAAgB7a,EAAE3E,QAAQ,GAClE,IAAK,IAAI2f,EAAI,EAAGA,EAAIjB,EAAUiB,IAAK,CACjC,MAAMC,EAAgBT,EAAwBQ,EACxCE,EAAiBzd,KAAKyM,MAAM+Q,GAC5BE,EAAUF,EAAgBC,EAC1BE,EACF3d,KAAKG,IAAIsc,EAAW,EAAGzc,KAAKiP,KAAKuO,IAC/BI,EAAgBP,EAAeI,EAAiBlb,EAAE3E,QAAQ,GAC1DigB,EAAgBP,EAAeG,EAAiBlb,EAAE3E,QAAQ,GAC1DkgB,EAAiBT,EAAeM,EAAgBpb,EAAE3E,QAAQ,GAC1DmgB,EAAiBT,EAAeK,EAAgBpb,EAAE3E,QAAQ,GAChE,IAAK,IAAI8B,EAAI,EAAGA,EAAIgd,EAAahd,IAAK,CAIpC,MAAMse,EAAUtgB,EAAQkgB,EAAgBle,GAClCue,EAAavgB,EAAQmgB,EAAgBne,GAIrCnB,EAAMyf,GAHKtgB,EAAQogB,EAAiBpe,GAGRse,GAAWN,EAEvCQ,EAAW3f,GADF0f,GAHKvgB,EAAQqgB,EAAiBre,GAGFue,GAAcP,EACxBnf,GAAO4e,EAExC1X,EAAOoX,KAAeqB,IAK9B,OAAO3X,SAAUd,EAAQ,CAACuU,EAAOqC,EAAWC,EAAUI,IAGxDxZ,uBAAuB4M,EAAcvN,EAAaga,GAChDxf,EAAiB,CAAC+S,EAAIvN,GAAI,0BAE1B,MAAOyX,EAAOmE,EAASC,EAAQC,GAAS9b,EAAEiB,QACjC8a,EAASC,GAAUzO,EAAGtM,MAEzB1E,EAAS,IAAIkQ,aAAagL,EAAQmE,EAAUC,EAASC,GAOrDG,EAAmC,CACtCjC,GAAgB+B,EAAU,EAAKH,EAAU,EAAIA,EAC7C5B,GAAgBgC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtClC,GAAgB+B,EAAU,EAAKA,EAAU,EAAIA,EAC7C/B,GAAgBgC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAMhDzO,EAAW5M,KAAKa,SAAS6L,EAAGjM,QAClC,IAAI8E,EAAS,EACb,IAAK,IAAIrJ,EAAI,EAAGA,EAAI0a,EAAO1a,IAAK,CAC9B,MAAMsf,EAAUtf,EAAIiD,EAAE3E,QAAQ,GAC9B,IAAK,IAAIof,EAAI,EAAGA,EAAIsB,EAAStB,IAAK,CAChC,MAAM1D,EAAM0D,EAAI0B,EACVG,EAAc7e,KAAKyM,MAAM6M,GACzBwF,EAAiB9e,KAAKG,IAAIH,KAAKiP,KAAKqK,GAAM6E,EAAU,GAEpDY,EAAeH,EAAUC,EAActc,EAAE3E,QAAQ,GACjDohB,EAAkBJ,EAAUE,EAAiBvc,EAAE3E,QAAQ,GAEvDqhB,EAAU3F,EAAMuF,EAChBK,EAAiB,EAAMD,EAC7B,IAAK,IAAI1B,EAAI,EAAGA,EAAIgB,EAAQhB,IAAK,CAC/B,MAAMhE,EAAMgE,EAAIoB,EACVQ,EAAenf,KAAKyM,MAAM8M,GAC1B6F,EAAgBpf,KAAKG,IAAIH,KAAKiP,KAAKsK,GAAM6E,EAAS,GAClDiB,EAAU9F,EAAM4F,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBR,EAAeI,EAAe5c,EAAE3E,QAAQ,GAC1D4hB,EAAmBT,EAAeK,EAAgB7c,EAAE3E,QAAQ,GAC5D6hB,EACFT,EAAkBG,EAAe5c,EAAE3E,QAAQ,GACzC8hB,EACFV,EAAkBI,EAAgB7c,EAAE3E,QAAQ,GAE1C+hB,EACFT,EAAiBI,EACfM,EAA6BV,EAAiBG,EAC9CQ,EAA6BZ,EAAUK,EACvCQ,EAAsBb,EAAUI,EACtC,IAAK,IAAI3f,EAAI,EAAGA,EAAI2e,EAAO3e,IAAK,CAC9B,MAAMqgB,EAAQ/P,EAASrH,KACvB7J,EAAOygB,EAAkB7f,IACrBqgB,EAAQJ,EACZ7gB,EAAO0gB,EAAmB9f,IAAMqgB,EAAQH,EACxC9gB,EAAO2gB,EAAqB/f,IACxBqgB,EAAQF,EACZ/gB,EAAO4gB,EAAsBhgB,IAAMqgB,EAAQD,KAKnD,OAAOE,WAAYlhB,EAAQ,CAACkb,EAAOoE,EAAQD,EAASE,GAAQ9b,EAAE/E,OAGhE0F,sBACIX,EAAa8Z,EAAmBC,EAChCC,GACFxf,EAAiBwF,EAAG,yBAEpB,MAAOyX,EAAOwC,EAAWC,EAAUC,GAAena,EAAEiB,MAC9C9F,EAAU0F,KAAKa,SAAS1B,EAAEsB,QAC1B/E,EAAS,IAAIkQ,aAAagL,EAAQqC,EAAYC,EAAWI,GAEzDC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAG5CQ,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAEhD,IAAIqD,EAAe,EACnB,IAAK,IAAI3gB,EAAI,EAAGA,EAAI0a,EAAO1a,IAAK,CAC9B,MAAM4gB,EAAc5gB,EAAIiD,EAAE3E,QAAQ,GAClC,IAAK,IAAIof,EAAI,EAAGA,EAAIX,EAAWW,IAAK,CAClC,MAAMC,EAAgBH,EAAwBE,EAKxCmD,EAAYD,EAJOlgB,KAAKG,IAC1Bqc,EAAY,EACZD,EAAevc,KAAKogB,MAAMnD,GACXjd,KAAKyM,MAAMwQ,IACqB1a,EAAE3E,QAAQ,GAC7D,IAAK,IAAI2f,EAAI,EAAGA,EAAIjB,EAAUiB,IAAK,CACjC,MAAMC,EAAgBT,EAAwBQ,EAKxC3U,EAAYuX,EAJOngB,KAAKG,IAC1Bsc,EAAW,EACXF,EAAevc,KAAKogB,MAAM5C,GACXxd,KAAKyM,MAAM+Q,IACmBjb,EAAE3E,QAAQ,GAC3D,IAAK,IAAI8B,EAAI,EAAGA,EAAIgd,EAAahd,IAAK,CAGpC,MAAM2gB,EAAS3iB,EAAQkL,EAAYlJ,GACnCZ,EAAOmhB,KAAkBI,KAKjC,OAAO9Z,SACHzH,EAAQ,CAACkb,EAAOqC,EAAWC,EAAUI,GAAcna,EAAE/E,OAG3D0F,8BACI4M,EAAcvN,EAAaga,GAC7Bxf,EAAiB,CAAC+S,EAAIvN,GAAI,iCAE1B,MAAOyX,EAAOmE,EAASC,EAAQC,GAAS9b,EAAEiB,QACjC8a,EAASC,GAAUzO,EAAGtM,MAEzB1E,EAAS,IAAIkQ,aAAagL,EAAQmE,EAAUC,EAASC,GACrDrO,EAAW5M,KAAKa,SAAS6L,EAAGjM,QAK5B2a,EAAmC,CACtCjC,GAAgB+B,EAAU,EAAKH,EAAU,EAAIA,EAC7C5B,GAAgBgC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtClC,GAAgB+B,EAAU,EAAKA,EAAU,EAAIA,EAC7C/B,GAAgBgC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAEhD6B,EAAiB,EAAI5B,EACrB6B,EAAgB,EAAI5B,EAIpB6B,EAAyC,EAA5BxgB,KAAKiP,KAAKqR,GAAuB,EAC9CG,EAAuC,EAA3BzgB,KAAKiP,KAAKsR,GAAsB,EAGlD,IAAK,IAAIjhB,EAAI,EAAGA,EAAI0a,EAAO1a,IAAK,CAC9B,MAAM4gB,EAAc5gB,EAAIiD,EAAE3E,QAAQ,GAClC,IAAK,IAAIof,EAAI,EAAGA,EAAImB,EAASnB,IAAK,CAChC,MAAMmD,EAAYD,EAAclD,EAAIza,EAAE3E,QAAQ,GAGxC8iB,EAAa1gB,KAAKyM,MAAMuQ,EAAIsD,GAC5BK,EAAW3gB,KAAKyM,MAAMiU,EAAcF,EAAY,GACtD,IAAK,IAAIjD,EAAI,EAAGA,EAAIa,EAAQb,IAAK,CAC/B,MAAM3U,EAAYuX,EAAY5C,EAAIhb,EAAE3E,QAAQ,GAGtCgjB,EAAa5gB,KAAKyM,MAAM8Q,EAAIgD,GAC5BM,EAAW7gB,KAAKyM,MAAMmU,EAAcH,EAAW,GAErD,IAAK,IAAI/gB,EAAI,EAAGA,EAAI2e,EAAO3e,IAAK,CAC9B,IAAIohB,EAAQ,EAGZ,IAAK,IAAIC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,MAAMrH,EAAMqH,EAAWJ,EAEvB,GAAIjH,EAAM,GAAKA,GAAO4E,EACpB,SAGF,MAAM0C,EAAYd,EAAcxG,EAAM5J,EAAGlS,QAAQ,GAC3Cqf,EAAgBvD,EAAMgF,EAK5B,GAAI1B,IAJqBhd,KAAKG,IAC1Bge,EAAU,EACV5B,EAAevc,KAAKogB,MAAMnD,GACXjd,KAAKyM,MAAMwQ,IAI9B,IAAK,IAAIgE,EAAW,EAAGA,EAAWR,EAAUQ,IAAY,CACtD,MAAMtH,EAAMsH,EAAWJ,EAEvB,GAAIlH,EAAM,GAAKA,GAAO4E,EACpB,SAGF,MAAM2C,EAAYF,EAAYrH,EAAM7J,EAAGlS,QAAQ,GACzC4f,EAAgB7D,EAAMgF,EAMxBpB,IALqBvd,KAAKG,IAC1Bie,EAAS,EACT7B,EAAevc,KAAKogB,MAAM5C,GACXxd,KAAKyM,MAAM+Q,MAG5BsD,GAAS9Q,EAASkR,EAAYxhB,KAIpCZ,EAAO8J,EAAYlJ,GAAKohB,KAKhC,OAAOd,WAAYlhB,EAAQyD,EAAEiB,MAAOjB,EAAE/E,OAGxC0F,UACIX,EAAa4e,EAAyBC,EACtCzY,EAA4BwH,EAC5BkR,GACFtkB,EAAiB,CAACwF,EAAG4e,EAAMC,EAAUjR,EAAOxH,GAAS,aAErD,MAAMrB,EAAQlE,KAAKa,SAAS1B,EAAEsB,QACxByd,EAAQle,KAAKa,SAASkd,EAAKtd,QAC3B0d,EAAUne,KAAKa,SAASmd,EAASvd,QACjC2d,EAAQrR,EAAQ/M,KAAKa,SAASkM,EAAMtM,QACpB,IAAImL,aAAa,CAAC,IAClCyS,EAAU9Y,EAASvF,KAAKa,SAAS0E,EAAO9E,QACrB,IAAImL,aAAa,CAAC,IACrC0S,EAAU,IAAI1S,aAAa1H,EAAMlB,QAEjCub,EAAgBF,EAAQrb,OACxBwb,EAAcJ,EAAMpb,OACpByb,EAAgBN,EAAQnb,OACxB0b,EAAcR,EAAMlb,OAE1B,IAAI2b,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACT,IAAK,IAAIxb,EAAI,EAAGA,EAAIY,EAAMlB,SAAUM,EAClCgb,EAAQhb,GAAK+a,EAAQM,MAChBza,EAAMZ,GAAK4a,EAAMU,MAASR,EAAMS,KAC7BjiB,KAAKyP,KAAK8R,EAAQW,KAAQb,GAC9BU,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAOlC,WAAY0B,EAASnf,EAAEiB,OAGhCN,6BACIX,EAAa4f,EAAqB7V,EAAc8F,EAChDgQ,GACFrlB,EAAiBwF,EAAG,gCAEpB,MAAM8f,EAAW9f,EAAEiB,MAAM,GACnB8e,EAAOD,EAAW,EAClB3kB,EAAU0F,KAAKa,SAAS1B,EAAEsB,QAC1BkC,EAAOxD,EAAEwD,KACTN,EAAS,IAAIuJ,aAAajJ,GAEhC,SAASwc,EAAkB5Z,GACzB,MAAM6Z,EAAiB7Z,EAAS0Z,EAChC,IAAII,EACA9Z,EAAS6Z,EAAiBxiB,KAAKC,IAAI,EAAGuiB,EAAiBL,GAC3D,MAAMO,EAAe/Z,EAAS6Z,EAC1BxiB,KAAKG,IAAIqiB,EAAiBL,EAAaG,GAE3C,IAAI1X,EAAM,EACV,KAAO6X,GAAkBC,EAAcD,IAAkB,CACvD,MAAME,EAAIjlB,EAAQ+kB,GAClB7X,GAAO+X,EAAIA,EAEb,OAAO/X,EAGT,IAAK,IAAIjC,EAAS,EAAGA,EAAS5C,EAAM4C,IAAU,CAC5C,MAAMiC,EAAM2X,EAAkB5Z,GACxBia,EAAMllB,EAAQiL,GAAU3I,KAAK8K,IAAIwB,EAAO8F,EAAQxH,GAAMwX,GAC5D3c,EAAOkD,GAAUia,EAGnB,OAAO5C,WAAYva,EAAQlD,EAAEiB,OAG/BN,QACI4M,EAAc+S,EAAsBC,EACpCX,EAAqB7V,EAAc8F,EACnCgQ,GACFrlB,EAAiB+S,EAAI,WACrB,MAAMuS,EAAWvS,EAAGtM,MAAM,GACpBwM,EAAW5M,KAAKa,SAAS6L,EAAGjM,QAC5Bkf,EAAmB3f,KAAKa,SAAS4e,EAAWhf,QAC5Cmf,EAAoB5f,KAAKa,SAAS6e,EAAYjf,QAC9C4B,EAAS,IAAIuJ,aAAac,EAAG/J,MAC7BA,EAAO+J,EAAG/J,KAEhB,IAAK,IAAI4C,EAAS,EAAGA,EAAS5C,EAAM4C,IAAU,CAC5C,MAAM6Z,EAAiB7Z,EAAS0Z,EAC1BY,EACDta,EAAS6Z,EAAkBxiB,KAAKC,IAAI,EAAGuiB,EAAiBL,GACvDe,EAAYva,EAAS6Z,EACvBxiB,KAAKG,IAAIkiB,EAAUG,EAAiBL,EAAc,GAEtD,IAAIgB,EAAO,EACX,IAAK,IAAI9W,EAAI4W,EAAY5W,EAAI6W,EAAU7W,IACrC8W,GAAQnjB,KAAK8K,IAAIiY,EAAiB1W,GAAI,GAExC8W,EAAO/Q,EAAQ+Q,EAAO7W,EAEtB,IAAK,IAAID,EAAI4W,EAAY5W,EAAI6W,EAAU7W,IAAK,CAC1C,IAAI+W,GAAO,EAAIhR,EAAQgQ,EAAOW,EAAiB1W,GAC3C2W,EAAkBra,GAAUwa,EAC5Bxa,IAAW0D,IACb+W,GAAOpjB,KAAK8K,IAAIqY,GAAOf,IAEzBgB,GAAOpT,EAASrH,GAChBlD,EAAO4G,IAAM+W,GAGjB,OAAOpD,WAAYva,EAAQqK,EAAGtM,OAGhCN,YACIgH,EAAkBmZ,EAAqBC,EACvCC,GACFxmB,EAAiBmN,EAAQ,eAEzB,MAAMsZ,EAAgBH,EAAanZ,EAASuZ,UAAWvZ,GACjD3K,EAAYikB,EAAchgB,MAAM,GAChCkgB,EAAYF,EAAchgB,MAAM,GAChCoE,EAAMkF,QAAkB,CAACvN,EAAW+jB,GAAa,SACjDzX,EAAUzI,KAAKa,SAAS2D,EAAI/D,QAC5B8f,EAAWvgB,KAAKa,SAASuf,EAAc3f,QAE7C,IAAK,IAAIvE,EAAI,EAAGA,EAAIC,IAAaD,EAAG,CAClC,MAAMqJ,EAASrJ,EAAIokB,EAGbE,EAAM,IAAI5U,aAAa0U,EAAY,GACzCE,EAAI,GAAKD,EAAShb,GAClB,IAAK,IAAIkb,EAAQ,EAAGA,EAAQD,EAAIxd,SAAUyd,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKF,EAAShb,EAASkb,GAGlD,MAAMC,EAASC,OAAgBR,EAAKS,YAC9BC,EAAY3kB,EAAIgkB,EACtB,IAAK,IAAIY,EAAW,EAAGA,EAAWZ,IAAcY,EAAU,CACxD,MAAMlH,EAAI8G,IAGVjY,EAAQoY,EAAYC,GAAYN,EAAIxd,OAEpC,IAAK,IAAIyd,EAAQ,EAAGA,EAAQD,EAAIxd,OAAQyd,IACtC,GAAI7G,EAAI4G,EAAIC,GAAQ,CAClBhY,EAAQoY,EAAYC,GAAYL,EAChC,QAKR,OAAOjc,EAGT1E,OAAO+U,EAAmBoG,EAAe8F,EAAiBC,GAExDrnB,EAAiBkb,EAAS,UAE1B,MAAMrQ,EAAM,IAAIoH,aAAaiJ,EAAQlS,KAAOsY,GAC5CzW,EAAIF,KAAK0c,GACT,MAAMC,EAAajhB,KAAKa,SAASgU,EAAQpU,QAEzC,IAAK,IAAIggB,EAAQ,EAAGA,EAAQ5L,EAAQlS,OAAQ8d,EACtCQ,EAAWR,IAAU,GAAKQ,EAAWR,GAASxF,IAChDzW,EAAIic,EAAQxF,EAAQgG,EAAWR,IAAUM,GAG7C,OAAOG,WAAY1c,EAAK,CAACqQ,EAAQlS,KAAMsY,GAAQ,SAGjDnb,kBACIqhB,EAAiBC,EAAkBC,EACnCC,EAAsBC,GACxB5nB,EAAiBwnB,EAAO,qBAExB,MAAMK,EAAYxhB,KAAKa,SAASsgB,EAAM1gB,QAChCghB,EAAazhB,KAAKa,SAASugB,EAAO3gB,QACxC,OAAO9B,EACH6iB,EAAWC,EAAYJ,EAAeC,EAAcC,GAG1DzhB,IAAIX,GACF,OAAOa,KAAK0hB,SAASviB,GAAG,GAG1BW,KAAKX,GACH,OAAOa,KAAK0hB,SAASviB,GAAG,GAMlBW,SAASX,EAAawiB,GAC5B,MAAM/K,EAAQzX,EAAEiB,MAAM,GAChBwhB,EAAWziB,EAAEiB,MAAM,GAEnByhB,EAAatgB,SAAUpC,EAAEiB,MAAO,WAChC0hB,EAAavgB,SAAUpC,EAAEiB,MAAO,WAEhCY,EAAO+D,OAAQ5F,GAAGmG,KAAKsR,EAAOgL,GAC9B1gB,EAAO+D,OAAQ9F,GAAGmG,KAAKsR,EAAOgL,GAEpC,IAAK,IAAI1lB,EAAI,EAAGA,EAAI0a,EAAO1a,IAAK,CAE9B,MAAM0d,EAAI5Y,EAAKuD,MAAM,CAACrI,EAAG,GAAI,CAAC,EAAG0lB,IAC3Bte,EAAIpC,EAAKqD,MAAM,CAACrI,EAAG,GAAI,CAAC,EAAG0lB,IAC3Bnf,EAAQyC,UAAW0U,EAAGtW,GAEtBkB,EACFxE,KAAKa,SAASb,KAAK+hB,QAAQtf,EAAOkf,GAASlhB,QAC/C,IAAK,IAAInE,EAAI,EAAGA,EAAIslB,EAAUtlB,IAAK,CACjC,MAAM6d,EAAI5Z,eAAayhB,oBAAoBxd,EAAKlI,GAChDulB,EAAW/lB,OAAOI,EAAI0lB,EAAWtlB,GAAK6d,EAAEnZ,KACxC8gB,EAAWhmB,OAAOI,EAAI0lB,EAAWtlB,GAAK6d,EAAEjZ,MAK5C,OADUgE,UAAW2c,EAAWle,WAAYme,EAAWne,YAC9C2B,KAAKsR,EAAOgL,GAGf9hB,QAAQX,EAAawiB,GAC3B,MAAMM,EAAM9iB,EAAE+iB,OAERC,EAAIF,EAAItf,KAEd,GAAI3C,KAAKoiB,cAAcD,GAAI,CACzB,IAAI9f,EAASrC,KAAKqiB,UAAUJ,EAAKE,EAAGR,GAASrc,KAAKnG,EAAEiB,MAAM,GAAIjB,EAAEiB,MAAM,IAMtE,OALIuhB,IACFtf,EAAS6C,UACIH,OAAQ1C,GAAQigB,IAAItc,SAAUmc,IAC9Bld,OAAQ5C,GAAQigB,IAAItc,SAAUmc,MAEtC9f,EACF,CACL,MAAMpC,EAAOD,KAAKa,SAAS1B,EAAEsB,QACvB8hB,EACFviB,KAAKwiB,yBAAyBviB,EAAMkiB,EAAGR,GACrCjmB,EAAS6E,eAAakiB,uBAAuBF,GACnD,OAAOrd,UAAWxJ,EAAOsF,KAAMtF,EAAOwF,MAAMoE,KAAKnG,EAAEiB,MAAM,GAAIjB,EAAEiB,MAAM,KAIjEN,cAAc6C,GACpB,OAA6B,IAArBA,EAAOA,EAAO,GAIhB7C,UAAU2C,EAAiBE,EAAcgf,GAC/C,GAAa,IAAThf,EACF,OAAOF,EAET,MAAMxC,EAAOD,KAAKa,SAAS4B,EAAMhC,QAC3BiiB,EAAO/f,EAAO,EACdggB,EAAcpiB,eAAaqiB,qBAAqB3iB,GACtD,IAAI4iB,EAAa3d,UAAWyd,EAAY3hB,KAAM2hB,EAAYzhB,MAAMghB,OAChE,MAAMY,EAAaviB,eAAawiB,oBAAoB9iB,GACpD,IAAI+iB,EAAY9d,UAAW4d,EAAW9hB,KAAM8hB,EAAW5hB,MAAMghB,OAG7DW,EAAa7iB,KAAKqiB,UAAUQ,EAAYH,EAAMf,GAC9CqB,EAAYhjB,KAAKqiB,UAAUW,EAAWN,EAAMf,GAE5C,MAAMsB,EAAI1iB,eAAa2iB,UAAUvgB,EAAMgf,GACjCwB,EAAWje,UAAW+d,EAAEjiB,KAAMiiB,EAAE/hB,MAAMmJ,IAAI2Y,GAE1CI,EAAUP,EAAWzZ,IAAI+Z,GACzBE,EAAUR,EAAWS,IAAIH,GAEzBI,EAAaxe,OAAQqe,GAASje,OAAOJ,OAAQse,IAC7CG,EAAave,OAAQme,GAASje,OAAOF,OAAQoe,IAEnD,OAAOne,UAAWqe,EAAYC,GAAYtB,OAIpCpiB,yBACJG,EAAkB0C,EAAcgf,GAClC,MAAM8B,EAAM,IAAI7X,aAAoB,EAAPjJ,GAE7B,IAAK,IAAIiX,EAAI,EAAGA,EAAIjX,EAAMiX,IAAK,CAC7B,IAAI5Y,EAAO,EACPE,EAAO,EACX,IAAK,IAAIiZ,EAAI,EAAGA,EAAIxX,EAAMwX,IAAK,CAC7B,MAAM8I,EAAI1iB,eAAa4iB,SAASvJ,EAAIO,EAAGxX,EAAMgf,GACvC+B,EAAOnjB,eAAayhB,oBAAoB/hB,EAAsBka,GACpEnZ,GAAQ0iB,EAAK1iB,KAAOiiB,EAAEjiB,KAAO0iB,EAAKxiB,KAAO+hB,EAAE/hB,KAC3CA,GAAQwiB,EAAK1iB,KAAOiiB,EAAE/hB,KAAOwiB,EAAKxiB,KAAO+hB,EAAEjiB,KAEzC2gB,IACF3gB,GAAQ2B,EACRzB,GAAQyB,GAEVpC,eAAaojB,mBAAmBF,EAAKziB,EAAME,EAAM0Y,GAEnD,OAAO6J,EAGT3jB,aAAaX,EAAauJ,EAAmB6G,GAE3CrV,OAAKC,OACc,SAAfoV,EACA,IAAM,+DACFA,KACRrV,OAAKC,OACDuO,EAAY,EACZ,IACI,sDAAsDA,KAE9D,MAAMvM,EAAYgD,EAAEiB,MAAM,GACpBwjB,EAAczkB,EAAEiB,MAAM,GACtByjB,EAAa1kB,EAAEiB,MAAM,GACrB0jB,EAAa3kB,EAAEiB,MAAM,GAErB2jB,EAAeH,EAAclb,EAC7Bsb,EAAcH,EAAanb,EAC3Bub,EAAcH,GAAcpb,EAAYA,GAExCpO,EAAU0F,KAAKa,SAAS1B,EAAEsB,QAC1B4B,EACF,IAAIuJ,aAAazP,EAAY4nB,EAAeC,EAAcC,GAE9D,IAAIxK,EAAY,EAChB,IAAK,IAAIvd,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIgoB,EAAI,EAAGA,EAAIH,IAAgBG,EAAG,CACrC,MAAMC,EAAMvnB,KAAKyM,MAAM6a,EAAIxb,GACrB0b,EAAWF,EAAIxb,EACrB,IAAK,IAAI2b,EAAI,EAAGA,EAAIL,IAAeK,EAAG,CACpC,MAAMC,EAAM1nB,KAAKyM,MAAMgb,EAAI3b,GAErB6b,GAAWH,EAAU1b,EADV2b,EAAI3b,GAC6Bub,EAClD,IAAK,IAAI3nB,EAAI,EAAGA,EAAI2nB,IAAe3nB,EAAG,CACpC,MACMkoB,EADMloB,EAAIioB,EAENT,GAAcQ,EAAMT,GAAcM,EAAMP,EAAc1nB,IAChEmG,EAAOoX,KAAenf,EAAQkqB,KAKtC,OAAO5H,WACHva,EAAQ,CAAClG,EAAW4nB,EAAcC,EAAaC,IAG7CnkB,oBACJmG,EAAW/J,EAAW9B,EACtBqqB,GACF,MAAM3P,EAAWvU,eAAamkB,2BAA2Bze,EAAE7F,MAAOlE,EAAEkE,OAC9DiC,EAASd,SAAUuT,EAAU1a,GAC7BwP,EAAQ5J,KAAKa,SAASoF,EAAExF,QACxBkkB,EAAQ3kB,KAAKa,SAAS3E,EAAEuE,QACxBmkB,EAAiBrkB,eAAaskB,iBAAiB5e,EAAE7F,MAAO0U,GACxDgQ,EAAiBvkB,eAAaskB,iBAAiB3oB,EAAEkE,MAAO0U,GAExDrM,EAAUpG,EAAOvG,OACvB,GAAI8oB,EAAe5hB,OAAS8hB,EAAe9hB,SAAW,EACpD,IAAK,IAAIM,EAAI,EAAGA,EAAImF,EAAQzF,SAAUM,EACpCmF,EAAQnF,GAAKmhB,EAAG7a,EAAMtG,EAAIsG,EAAM5G,QAAS2hB,EAAMrhB,EAAIqhB,EAAM3hB,aAEtD,CACL,MAAM+hB,EAAO/kB,KAAKqD,WAAW4C,GACvB+e,EAAOhlB,KAAKqD,WAAWnH,GAC7B,IAAK,IAAIoH,EAAI,EAAGA,EAAImF,EAAQzF,SAAUM,EAAG,CACvC,MAAMU,EAAM3B,EAAOmB,WAAWF,GAExB2hB,EAAOjhB,EAAIO,OAAO0B,EAAE7B,MAC1BwgB,EAAe5qB,QAAQsC,GAAK2oB,EAAK3oB,GAAK,GACtC,MAAM4oB,EAASH,EAAK7P,WAAW+P,GAEzBE,EAAOnhB,EAAIO,OAAOrI,EAAEkI,MAC1B0gB,EAAe9qB,QAAQsC,GAAK6oB,EAAK7oB,GAAK,GACtC,MAAM8oB,EAASJ,EAAK9P,WAAWiQ,GAE/B1c,EAAQnF,GAAKmhB,EAAG7a,EAAMsb,GAASP,EAAMS,KAGzC,OAAO/iB,EAAOsB,WAGR7D,2BACJmG,EAAW/J,EACXuoB,GAGF,MAAM3P,EAAWvU,eAAamkB,2BAA2Bze,EAAE7F,MAAOlE,EAAEkE,OAC9DyhB,EAAatgB,SAAUuT,EAAU,WACjCgN,EAAavgB,SAAUuT,EAAU,WAEjClL,EAAQ5J,KAAKa,SAASoF,EAAExF,QACxBkkB,EAAQ3kB,KAAKa,SAAS3E,EAAEuE,QACxBmkB,EAAiBrkB,eAAaskB,iBAAiB5e,EAAE7F,MAAO0U,GACxDgQ,EAAiBvkB,eAAaskB,iBAAiB3oB,EAAEkE,MAAO0U,GAExDuQ,EAAWxD,EAAW/lB,OACtBwpB,EAAWxD,EAAWhmB,OAE5B,GAAI8oB,EAAe5hB,OAAS8hB,EAAe9hB,SAAW,EACpD,IAAK,IAAIM,EAAI,EAAGA,EAAI+hB,EAASriB,OAAQM,IAAK,CACxC,MAAMiiB,EAAOjiB,EAAIsG,EAAM5G,OACjBwiB,EAAOliB,EAAIqhB,EAAM3hB,OAEjBX,EACFoiB,EAAG7a,EAAa,EAAP2b,GAAW3b,EAAa,EAAP2b,EAAW,GAAIZ,EAAa,EAAPa,GAC5Cb,EAAa,EAAPa,EAAW,IAExBH,EAAS/hB,GAAKjB,EAAOrB,KACrBskB,EAAShiB,GAAKjB,EAAOnB,SAElB,CACL,MAAMukB,EACFzlB,KAAKqD,WAAWrD,KAAKC,KAAKxB,IAAIwH,EAAExF,QAAQK,eAAeE,MACrD0kB,EACF1lB,KAAKqD,WAAWrD,KAAKC,KAAKxB,IAAIvC,EAAEuE,QAAQK,eAAeE,MAC3D,IAAK,IAAIsC,EAAI,EAAGA,EAAI+hB,EAASriB,OAAQM,IAAK,CACxC,MAAMU,EAAM6d,EAAWre,WAAWF,GAE5B2hB,EAAOjhB,EAAIO,OAAO0B,EAAE7B,MAC1BwgB,EAAe5qB,QAAQsC,GAAK2oB,EAAK3oB,GAAK,GACtC,MAAM4oB,EAASO,EAASvQ,WAAW+P,GAE7BE,EAAOnhB,EAAIO,OAAOrI,EAAEkI,MAC1B0gB,EAAe9qB,QAAQsC,GAAK6oB,EAAK7oB,GAAK,GACtC,MAAM8oB,EAASM,EAASxQ,WAAWiQ,GAE7BQ,EACFlB,EAAG7a,EAAe,EAATsb,GAAatb,EAAe,EAATsb,EAAa,GAAIP,EAAe,EAATS,GAChDT,EAAe,EAATS,EAAa,IAE1BC,EAAS/hB,GAAKqiB,EAAS3kB,KACvBskB,EAAShiB,GAAKqiB,EAASzkB,MAG3B,OAAOlB,KAAK4lB,QAAQ/D,EAAWle,WAAYme,EAAWne,YAGxD7D,MAAwBX,EAAM0mB,EAAsB9hB,GAClD,OAAOlF,EAAMM,EAAG0mB,EAAY9hB,GAG9BjE,WAEAA,iBACE,OAAO,GAITA,UACE,OAAOC,MAAM+lB,UAGfhmB,cACIimB,EACA5E,EACA6E,EACAC,EACAC,EACAC,GAEF,MAAOvP,EAAOwP,EAAaC,EAAY/M,GAAeyM,EAAO3lB,MACvDkmB,EAAWnF,EAAM/gB,MAAM,IAEtBmmB,EAAYC,GAAaP,EAC1BvqB,EACF6F,SAAU,CAAC+kB,EAAUC,EAAYC,EAAWlN,GAAc,WAExDmN,EAAUzmB,KAAKa,SAASsgB,EAAM1gB,QAC9BimB,EAAa1mB,KAAKa,SAASmlB,EAASvlB,QACpCkmB,EAAY3mB,KAAKa,SAASklB,EAAOtlB,QAEjCmmB,EAAWb,EAAOvrB,QAClBqsB,EAAYnrB,EAAOlB,QAKzB,IAAK,IAAI0B,EAAI,EAAGA,EAAIoqB,EAAUpqB,IAAK,CACjC,MAAM4qB,EAAe,EAAJ5qB,EACX6qB,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAWxqB,GAChC,GAAIirB,GAAQvQ,EACV,SAGF,MAAM0E,EAAeiL,EAAa,GAC7BU,EAAKF,IAAOX,EAAc,IAAMG,EAAa,GAC9C,EACEhL,EACDiL,EAAY,GAAMU,EAAKF,IAAOX,EAAa,IAAMG,EAAY,GAAK,EAEvE,IAAK,IAAI7Z,EAAI,EAAGA,EAAI4Z,EAAY5Z,IAAK,CACnC,MAAMya,EAAgBb,EAAa,EAC/BQ,GAAMX,EAAc,GAAKzZ,IACzB,IAAOoa,EAAKE,IAAOb,EAAc,GAErC,GAAIgB,EAAO,GAAKA,EAAOhB,EAAc,EACnC,IAAK,IAAIjnB,EAAI,EAAGA,EAAIqnB,EAAWrnB,IAC7B,IAAK,IAAIgb,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAMkN,EACFlN,EAAIhb,EAAI0nB,EAAU,GAAKla,EAAIka,EAAU,GAAK3qB,EAAI2qB,EAAU,GAC5DnrB,EAAOI,OAAOurB,GAAOlB,OAM3B,GAAe,aAAXD,EAAuB,CACzB,MAAMoB,EAAS1qB,KAAKyM,MAAM+d,GACpBG,EAAY3qB,KAAKiP,KAAKub,GACtBI,EAAQJ,EAAOE,EAErB,IAAK,IAAInoB,EAAI,EAAGA,EAAIqnB,EAAWrnB,IAAK,CAClC,MAAMsoB,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKlnB,EAAIoc,EAC5B,IAAOyL,EAAKE,IAAOb,EAAa,GAEpC,GAAIoB,EAAO,GAAKA,EAAOpB,EAAa,EAAG,CACrC,IAAK,IAAIlM,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAMkN,EACFlN,EAAIhb,EAAI0nB,EAAU,GAAKla,EAAIka,EAAU,GAAK3qB,EAAI2qB,EAAU,GAC5DnrB,EAAOI,OAAOurB,GAAOlB,EAEvB,SAGF,MAAMuB,EAAU9qB,KAAKyM,MAAMoe,GACrBE,EAAW/qB,KAAKiP,KAAK4b,GACrBG,EAAQH,EAAOC,EAErB,IAAK,IAAIvN,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,IAAIkN,EAAMlN,EAAIuN,EAAUd,EAAS,GAAKU,EAASV,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAAMhM,EAAU+L,EAAUU,GAE1BA,EAAMlN,EAAIwN,EAAWf,EAAS,GAAKU,EAASV,EAAS,GACjDO,EAAOP,EAAS,GACpB,MAAMiB,EAAWlB,EAAUU,GAE3BA,EAAMlN,EAAIuN,EAAUd,EAAS,GAAKW,EAAYX,EAAS,GACnDO,EAAOP,EAAS,GACpB,MAAM/L,EAAa8L,EAAUU,GAE7BA,EAAMlN,EAAIwN,EAAWf,EAAS,GAAKW,EAAYX,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAEMzrB,EAAMyf,GAAWiN,EAAWjN,GAAWgN,EACvCE,EAASjN,GAHK8L,EAAUU,GAGaxM,GAAc+M,EAEzDP,EAAMlN,EAAIhb,EAAI0nB,EAAU,GAAKla,EAAIka,EAAU,GAAK3qB,EAAI2qB,EAAU,GAC9DnrB,EAAOI,OAAOurB,GAAOlsB,GAAQ2sB,EAAS3sB,GAAOqsB,SAIjD,IAAK,IAAIroB,EAAI,EAAGA,EAAIqnB,IAAarnB,EAAG,CAClC,MAAMsoB,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKlnB,EAAIoc,EAC5B,IAAOyL,EAAKE,IAAOb,EAAa,GAEpC,GAAIoB,EAAO,GAAKA,EAAOpB,EAAa,EAAG,CACrC,IAAK,IAAIlM,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAMkN,EACFlN,EAAIhb,EAAI0nB,EAAU,GAAKla,EAAIka,EAAU,GAAK3qB,EAAI2qB,EAAU,GAC5DnrB,EAAOI,OAAOurB,GAAOlB,EAEvB,SAGF,MAAM4B,EAAWnrB,KAAKogB,MAAMyK,GACtBO,EAAWprB,KAAKogB,MAAMoK,GAC5B,IAAK,IAAIjN,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAM8N,EAAQ9N,EAAI4N,EAAWnB,EAAS,GAClCoB,EAAWpB,EAAS,GAAKO,EAAOP,EAAS,GACvCsB,EACF/N,EAAIhb,EAAI0nB,EAAU,GAAKla,EAAIka,EAAU,GAAK3qB,EAAI2qB,EAAU,GAC5DnrB,EAAOI,OAAOosB,GAAUvB,EAAUsB,MAM5C,OAAOvsB,EAAOiI,WAGhB7D,cACIqoB,EAAuBC,EAAsBC,EAC7CC,GACF,MAAMC,UAACA,EAASC,WAAEA,EAAU1S,UAAEA,EAAStb,QAAEA,EAAOiuB,WAAEA,GAC9CloB,eAAamoB,gBAAgBN,EAAcD,EAAeE,GAE9D,OAAOroB,KAAK2oB,QACRR,EAAeC,EAAcC,EAAaI,EAAY3S,EACtD0S,EAAYD,EAAW/tB,EAAS8tB,GAHb,GAMzBxoB,SAASX,EAAW0V,GAClB,MAAM+T,EAAe/T,EAAQzU,MACvBmoB,EAAYK,EAAaA,EAAa5lB,OAAS,IAE9C6lB,EAAaC,EAAWhT,EAAWtb,GACtC+F,eAAawoB,mBAAmB5pB,EAAG0V,GACvC,GAAkB,IAAdiU,EACF,OAAO3lB,SAAU,GAAI0lB,EAAa1pB,EAAE/E,OAGtC,MAAMuB,EAAS,IAAIqtB,eAAa,CAACF,EAAWhT,GAAY3W,EAAE/E,OACpD6uB,EAAcjpB,KAAKa,SAASgU,EAAQpU,QACpCyoB,EAAQlpB,KAAKa,SAAS1B,EAAEsB,QAE9B,IAAK,IAAI6C,EAAI,EAAGA,EAAIwlB,EAAWxlB,IAAK,CAClC,MAAM+H,EAAQ,GACd,IAAI8d,EAAe,EACnB,IAAK,IAAIzlB,EAAI,EAAGA,EAAI6kB,EAAW7kB,IAAK,CAClC,MAAMqD,EAAMkiB,EAAY3lB,EAAIilB,EAAY7kB,GACxCylB,GAAgBpiB,EAAMvM,EAAQkJ,GAC9B2H,EAAMf,KAAKvD,GAEb,GAAIoiB,EAAe,GAAKA,GAAgBhqB,EAAEwD,KAAOmT,EAC/C,MAAM,IAAInW,MACN,oBAAoB0L,yBAA6BlM,EAAEiB,SAGzD,IAAK,IAAI6I,EAAI,EAAGA,EAAI6M,EAAW7M,IAC7BtN,EAAOG,OAAOwH,EAAIwS,EAAY7M,GAAKigB,EAAMC,EAAerT,EAAY7M,GAGxE,OAAOtN,EAAOgI,WAAWc,QAAQokB,GAGnC/oB,UACI+U,EAAiBuU,EAAiBhpB,GACpC,MAAMmoB,UAACA,EAASC,WAAEA,EAAU1S,UAAEA,EAAStb,QAAEA,EAAOiuB,WAAEA,GAC9CloB,eAAamoB,gBAAgBU,EAASvU,EAASzU,GAC7CkoB,EAAetiB,SAAU,GAE/B,OAAOhG,KAAK2oB,QACR9T,EAASuU,EAAShpB,EAAOqoB,EAAY3S,EAAW0S,EAAYD,EAC5D/tB,EAAS8tB,GAHU,GAMzBxoB,KACIM,EAAoBqK,EAAsBrQ,GAC5CA,EAAQA,GAASF,OAAKmvB,WAAW5e,GACjC,MAAM3O,EACF5B,OAAKovB,kBAAkBlvB,EAAOF,OAAK+I,cAAc7C,IAErD,OADAtE,EAAOwI,KAAKmG,GACLtK,WAASopB,WAAWztB,EAAQsE,EAAOhG,EAAO4F,MAGnDF,SAAyBX,GACvB,GAAgB,WAAZA,EAAE/E,MACJ,MAAM,IAAIuF,MAAM,gDAEhB,OAAOK,KAAKsE,KAAKnF,EAAEiB,MAAO,EAAGjB,EAAE/E,OAInC0F,UAA0BX,GACxB,MAAMrD,EAAS5B,OAAKovB,kBACDnqB,EAAE/E,MAAOF,OAAK+I,cAAc9D,EAAEiB,QACjD,OAAOJ,KAAKsC,WAAWxG,EAAQqD,EAAEiB,MAAOjB,EAAE/E,OAG5C0F,SAASkC,EAAewnB,EAAcrlB,GACpC,OAAO5D,eAAakpB,aAAaznB,EAAOwnB,EAAMrlB,GAGxCrE,QACJ+U,EAAiBuU,EAAiBhpB,EAAoBqoB,EACtD3S,EAAmB0S,EAAoBD,EACvC/tB,EAAmB8tB,EACnBoB,GACF,MAAMC,EAAe,CAAClB,EAAa3S,EAAWA,GAExCmT,EAAcjpB,KAAKa,SAASgU,EAAQpU,QACpCmpB,EAAc5pB,KAAKa,SAASuoB,EAAQ3oB,QAE1C,GAAmB,IAAfgoB,EACF,OAAOtlB,SAAU,GAAI/C,EAAOgpB,EAAQhvB,OAGtC,MAAMuB,EAAS,IAAIqtB,eAAaW,EAAcP,EAAQhvB,OACtDuB,EAAOG,OAAOwI,KAAMtE,KAAKa,SAASynB,EAAa7nB,QAAuB,IAEtE,IAAK,IAAI6C,EAAI,EAAGA,EAAIklB,EAAYllB,IAAK,CACnC,MAAM+H,EAAQ,GACd,IAAI8d,EAAe,EACnB,IAAK,IAAIzlB,EAAI,EAAGA,EAAI6kB,EAAW7kB,IAAK,CAClC,MAAMqD,EAAMkiB,EAAY3lB,EAAIilB,EAAY7kB,GACxC2H,EAAMf,KAAKvD,GACXoiB,GAAgBpiB,EAAMvM,EAAQkJ,GAGhC,GAAIylB,EAAe,GAAKA,GAAgBV,EAAa3S,EACnD,MAAM,IAAInW,MACN,oBAAoB0L,yBAA6BjL,KAGvD,IAAK,IAAI6I,EAAI,EAAGA,EAAI6M,EAAW7M,IACzBygB,EACF/tB,EAAOG,OAAOqtB,EAAerT,EAAY7M,IACrC2gB,EAAYtmB,EAAIwS,EAAY7M,GAEhCtN,EAAOG,OAAOqtB,EAAerT,EAAY7M,GAAsB,IAAjBmgB,EAAQhlB,KAClDwlB,EAAY,GACZA,EAAYtmB,EAAIwS,EAAY7M,GAItC,OAAOtN,EAAOgI,WAAWc,QAAQrE,aCnhHrBypB,EACZjgB,EAAmBD,EAAoB/N,EACvCxB,GACF,MAAM8I,EAAOhJ,OAAK4vB,uBACd1vB,EAA0BF,OAAK+I,cAAcrH,IAEjD,IAAK,IAAI0H,EAAI,EAAGA,EAAIJ,EAAKF,SAAUM,EAAG,CACpC,MAAMiC,EAASjC,EAAIqG,EACnB,IAAI9M,EAAM+M,EAAMrE,GAChB,IAAK,IAAI7B,EAAI,EAAGA,EAAIiG,IAAcjG,EAAG,CACnC,MAAM+G,EAAQb,EAAMrE,EAAS7B,GACzB+G,EAAQ5N,IACVA,EAAM4N,GAGVvH,EAAKI,GAAKzG,EAEZ,OAAOqG,WChBO6mB,EACZ7lB,EAAmB3J,EAAkBH,EAAiB4vB,EACtDlV,GACF,MAAMmV,EAAQ1vB,EAAOyI,OACfknB,EAAQhwB,OAAK+I,cAAc1I,GAC3B4vB,EAAWjwB,OAAKkwB,eAAe7vB,GAC/B8vB,EAAanwB,OAAKkwB,eAAetV,GAEjCzS,EAASnI,OAAK4vB,uBAChB1vB,EAA0BF,OAAK+I,cAAc6R,IAEjD,IAAK,IAAIxR,EAAI,EAAGA,EAAI4mB,IAAS5mB,EAAG,CAC9B,MAAMU,EAAM9J,OAAKsJ,WAAWF,EAAG2mB,EAAOE,GAGhClmB,EAAmB,IAAInK,MAAMkK,EAAIhB,QACvC,IAAK,IAAIM,EAAI,EAAGA,EAAIW,EAAOjB,OAAQM,IACjCW,EAAOX,GAAKU,EAAIgmB,EAAK1mB,IAIvBjB,EADiBnI,OAAKgb,WAAWjR,EAAQgmB,EAAOI,IAC7BnmB,EAAMZ,GAE3B,OAAOjB,oFCbO,MAAO,IAAM,IAAIzC,EAAkB,GCR5C,MAAM0qB,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,MACpB,MAAMC,EAACA,GAAKwrB,EACNC,EAAa1rB,EACnBvF,EAAiBwF,EAAG,OAEpB,MAAMrD,EAAS8uB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OACvCouB,EAAQhwB,OAAK+I,cAAc9D,EAAEiB,OAC7B8K,EAAY,IAAIU,aAAase,GACnC,IAAK,IAAI5mB,EAAI,EAAGA,EAAI4mB,IAAS5mB,EAC3B4H,EAAU5H,GAAK1G,KAAKiuB,IAAI/uB,EAAOwH,IAGjC,MAAO,CAAC7C,OADOmqB,EAAWppB,MAAM0J,EAAW/L,EAAEiB,MAAOjB,EAAE/E,OACtCgG,MAAOjB,EAAEiB,MAAOhG,MAAO+E,EAAE/E,SChBhC0wB,EAAiC,CAC5CP,WAAYQ,aACZN,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,EAAS8rB,MAAAA,MAC7B,MAAM7rB,EAACA,EAAC+P,OAAEA,GAAUyb,GACdnwB,QAACA,EAAOywB,IAAEA,EAAGC,UAAEA,GAAaF,EAC5BJ,EAAa1rB,EAEbgF,EAAQ0mB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OACtCmuB,EAAQ9qB,EAAEiB,MAAM4C,OAEhBmoB,EAAaP,EAAW3qB,KAAKxB,IAAIyQ,EAAOzO,QAAQ3E,OAChDsvB,EAAalc,EAAO9O,MAAM4C,QAE1B7G,UACJA,EAASa,SACTA,EAAQO,QACRA,EAAOhB,WACPA,EAAUE,UACVA,EAASU,SACTA,EAAQjC,QACRA,EAAOP,aACPA,EAAYC,YACZA,EAAWwU,aACXA,EAAYC,YACZA,EAAWxU,eACXA,EAAcC,cACdA,EAAac,SACbA,GAEE2E,eAAa8qB,sBACTlsB,EAAEiB,MACF8O,EAAO9O,MAAmC5F,EAASywB,EACnD,OAAyBC,GAE3BI,EAAUpxB,OAAK+I,cAAcrH,GAC7B2vB,EAAU3vB,EAASoH,OACnBnH,EAAa3B,OAAKovB,kBAAkBnqB,EAAE/E,MAAOkxB,GAMnD,IAAK,IAAIpvB,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIsvB,EAAO,EAAGA,EAAO/uB,IAAa+uB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7wB,EAAeO,EAAQC,IAC3C,IAAK,IAAIuwB,EAAO,EAAGA,EAAOvuB,IAAYuuB,EAAM,CAC1C,MAAMC,EAAOD,EAAO9wB,EAAcM,EAAQG,KAC1C,IAAK,IAAIiB,EAAI,EAAGA,EAAIC,IAAcD,EAAG,CACnC,IAAIsvB,EAASrwB,OAAOswB,iBACpB,IAAK,IAAI3H,EAAI,EAAGA,EAAI9U,IAAgB8U,EAAG,CACrC,MAAM4H,EAAML,EAAOvH,EAAIrpB,EACvB,GAAIixB,GAAO,GAAKA,EAAM9uB,EACpB,IAAK,IAAIqnB,EAAI,EAAGA,EAAIhV,IAAegV,EAAG,CACpC,MAAM0H,EAAMJ,EAAOtH,EAAIvpB,EACvB,GAAIixB,GAAO,GAAKA,EAAMxuB,EAAS,CAC7B,MAAMyuB,EAAS9xB,OAAKgb,WAChB,CAAChZ,EAAG4vB,EAAKC,EAAKzvB,GAAI2tB,EAAO/vB,OAAKkwB,eAAejrB,EAAEiB,QAC7C6rB,EAAc/xB,OAAKgb,WACrB,CAACgP,EAAGG,EAAG/nB,GAAI8uB,EACXlxB,OAAKkwB,eAAelb,EAAO9O,QACzBof,EAAMtb,EAAM8nB,GAAUb,EAAWc,GACnCzM,EAAMoM,IACRA,EAASpM,KAQnB3jB,EAFoB3B,OAAKgb,WACrB,CAAChZ,EAAGsvB,EAAME,EAAMpvB,GAAIivB,EAASrxB,OAAKkwB,eAAexuB,KAC3BgwB,IASlC,MAAO,CAACnrB,OAHOmqB,EAAWppB,MACtBtH,OAAKgyB,aAAarwB,EAAYsD,EAAE/E,OAAQwB,EAAUuD,EAAE/E,OAExCgG,MAAOxE,EAAUxB,MAAO+E,EAAE/E,SC/EjC+xB,EAA+C,CAC1D5B,WAAY6B,2BACZ3B,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,EAAS8rB,MAAAA,MAC7B,MAAM7rB,EAACA,EAAC+P,OAAEA,EAAMxC,GAAEA,GACdie,GACEnwB,QAACA,EAAOywB,IAAEA,EAAGC,UAAEA,GAAaF,EAC5BJ,EAAa1rB,EAEbmtB,EACFnyB,OAAKoyB,cACDntB,EAAEiB,MAAOwqB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,QAGzCywB,EAAUryB,OAAKoyB,cACDpd,EAAO9O,MACPwqB,EAAW3qB,KAAKxB,IAAIyQ,EAAOzO,QAAQ3E,SAGjDK,UACJA,EAASa,SACTA,EAAQO,QACRA,EAAOhB,WACPA,EAAUE,UACVA,EAASU,SACTA,EAAQjC,QACRA,EAAOP,aACPA,EAAYC,YACZA,EAAWwU,aACXA,EAAYC,YACZA,EAAWxU,eACXA,EAAcC,cACdA,EAAac,SACbA,GAEE2E,eAAa8qB,sBACTlsB,EAAEiB,MACF8O,EAAO9O,MAAmC5F,EAASywB,EACnD,OAAyBC,GAEjChxB,OAAKC,OACDuS,EAAGtI,OAASxI,EAASoH,OACrB,IAAM,YAAYopB,kCACd,qCAAqCxwB,EAASoH,mBAC9C,GAAG0J,EAAGtI,QAEd,MAAMooB,EACFtyB,OAAKoyB,cACD1wB,EAAUgvB,EAAW3qB,KAAKxB,IAAIiO,EAAGjM,QAAQ3E,QAK3C2wB,EAAYvyB,OAAKwyB,0BACDxd,EAAO9O,MAAO8O,EAAO9U,OAO3C,IAAK,IAAI8B,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIsvB,EAAO,EAAGA,EAAO/uB,IAAa+uB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7wB,EAAeO,EAAQC,IAC3C,IAAK,IAAIuwB,EAAO,EAAGA,EAAOvuB,IAAYuuB,EAAM,CAC1C,MAAMC,EAAOD,EAAO9wB,EAAcM,EAAQG,KAC1C,IAAK,IAAIiB,EAAI,EAAGA,EAAIC,IAAcD,EAAG,CACnC,IAAIsvB,EAASrwB,OAAOswB,iBAChBc,EAAO,EACPC,EAAO,EACX,IAAK,IAAI1I,EAAI,EAAGA,EAAI9U,IAAgB8U,EAAG,CACrC,MAAM4H,EAAML,EAAOvH,EAAIrpB,EACvB,GAAIixB,GAAO,GAAKA,EAAM9uB,EACpB,IAAK,IAAIqnB,EAAI,EAAGA,EAAIhV,IAAegV,EAAG,CACpC,MAAM0H,EAAMJ,EAAOtH,EAAIvpB,EACvB,GAAIixB,GAAO,GAAKA,EAAMxuB,EAAS,CAC7B,MAAMiiB,EAAM6M,EAAGnwB,GAAG4vB,GAAKC,GAAKzvB,GAAKiwB,EAAQrI,GAAGG,GAAG/nB,GAC3CkjB,EAAMoM,IACRA,EAASpM,EACTmN,EAAOzI,EACP0I,EAAOvI,KAMjBoI,EAAUE,GAAMC,GAAMtwB,IAAMkwB,EAAItwB,GAAGsvB,GAAME,GAAMpvB,KASvD,MAAO,CAACmE,OAHOmqB,EAAWppB,MACtBtH,OAAKgyB,aAAaO,EAAWttB,EAAE/E,OAAQ8U,EAAO9O,MAAO8O,EAAO9U,OAEhDgG,MAAO8O,EAAO9O,MAAOhG,MAAO8U,EAAO9U,SC/F1CyyB,EAA8C,CACzDtC,WAAYuC,0BACZrC,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,EAAS8rB,MAAAA,MAC7B,MAAM7rB,EAACA,EAAC+P,OAAEA,EAAMxC,GAAEA,GACdie,GACEnwB,QAACA,EAAOywB,IAAEA,EAAGC,UAAEA,GAAaF,EAC5BJ,EAAa1rB,EAEbmtB,EACFnyB,OAAKoyB,cACDntB,EAAEiB,MAAOwqB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,QAGzCywB,EAAUryB,OAAKoyB,cACDpd,EAAO9O,MACPwqB,EAAW3qB,KAAKxB,IAAIyQ,EAAOzO,QAAQ3E,SAGjDK,UACJA,EAASa,SACTA,EAAQO,QACRA,EAAOhB,WACPA,EAAUE,UACVA,EAASU,SACTA,EAAQjC,QACRA,EAAOP,aACPA,EAAYC,YACZA,EAAWwU,aACXA,EAAYC,YACZA,EAAWxU,eACXA,EAAcC,cACdA,EAAac,SACbA,GAEE2E,eAAa8qB,sBACTlsB,EAAEiB,MACF8O,EAAO9O,MAAmC5F,EAASywB,EACnD,OAAyBC,GAEjChxB,OAAKC,OACDuS,EAAGtI,OAASxI,EAASoH,OACrB,IAAM,YAAY8pB,iCACd,qCAAqClxB,EAASoH,mBAC9C,GAAG0J,EAAGtI,QAEd,MAAMooB,EACFtyB,OAAKoyB,cACD1wB,EAAUgvB,EAAW3qB,KAAKxB,IAAIiO,EAAGjM,QAAQ3E,QAK3C2wB,EACFvyB,OAAKwyB,0BAA0BvtB,EAAEiB,MAAOjB,EAAE/E,OAO9C,IAAK,IAAI8B,EAAI,EAAGA,EAAIC,IAAaD,EAC/B,IAAK,IAAIsvB,EAAO,EAAGA,EAAO/uB,IAAa+uB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7wB,EAAeO,EAAQC,IAC3C,IAAK,IAAIuwB,EAAO,EAAGA,EAAOvuB,IAAYuuB,EAAM,CAC1C,MAAMC,EAAOD,EAAO9wB,EAAcM,EAAQG,KAC1C,IAAK,IAAIiB,EAAI,EAAGA,EAAIC,IAAcD,EAAG,CACnC,IAAIsvB,EAASrwB,OAAOswB,iBAChBkB,EAAUtB,EAAO,EAAK,EAAIA,EAC1BuB,EAAUrB,EAAO,EAAK,EAAIA,EAC9B,IAAK,IAAIzH,EAAI,EAAGA,EAAI9U,IAAgB8U,EAAG,CACrC,MAAM4H,EAAML,EAAOvH,EAAIrpB,EACvB,GAAIixB,GAAO,GAAKA,EAAM9uB,EACpB,IAAK,IAAIqnB,EAAI,EAAGA,EAAIhV,IAAegV,EAAG,CACpC,MAAM0H,EAAMJ,EAAOtH,EAAIvpB,EACvB,GAAIixB,GAAO,GAAKA,EAAMxuB,EAAS,CAC7B,MAAMiiB,EAAM6M,EAAGnwB,GAAG4vB,GAAKC,GAAKzvB,GAAKiwB,EAAQrI,GAAGG,GAAG/nB,GAC3CkjB,EAAMoM,IACRA,EAASpM,EACTuN,EAASjB,EACTkB,EAASjB,KAMnBU,EAAUvwB,GAAG6wB,GAAQC,GAAQ1wB,IAAMkwB,EAAItwB,GAAGsvB,GAAME,GAAMpvB,KAS9D,MAAO,CAACmE,OAHOmqB,EAAWppB,MACtBtH,OAAKgyB,aAAaO,EAAWttB,EAAE/E,OAAQ+E,EAAEiB,MAAOjB,EAAE/E,OAEtCgG,MAAOjB,EAAEiB,MAAOhG,MAAO+E,EAAE/E,kBC5F7B6yB,EACZC,EACAzI,GAIF,MAAO,CACL8F,WAAY2C,EACZzC,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,MACpB,MAAM+G,EAACA,EAAC/J,EAAEA,GAAKyuB,EACTC,EAAa1rB,EACnBvF,EAAiB,CAACsM,EAAG/J,GAAIgxB,GAEzB,MAAMtjB,EAAQghB,EAAW3qB,KAAKxB,IAAIwH,EAAExF,QAAQ3E,OACtC6oB,EAAQiG,EAAW3qB,KAAKxB,IAAIvC,EAAEuE,QAAQ3E,QAErCqxB,EAAYtE,GACfpE,EAAGxe,EAAE7F,MAAOlE,EAAEkE,MAAOwJ,EAAO+a,EAAO1e,EAAE7L,OAGzC,MAAO,CAACqG,OADOmqB,EAAWppB,MAAM2rB,EAAYtE,EAAa5iB,EAAE7L,OAC3CgG,MAAOyoB,EAAazuB,MAAO6L,EAAE7L,kBAKnCgzB,EAAuB3I,GACrC,MAAO,CAAC4I,EAAkBC,EAAkB1jB,EACpC+a,EAAmBvqB,KACzB,MAAM0a,EAAWvU,eAAamkB,2BAA2B2I,EAAQC,GAE3DC,EAAazY,EAAS9R,OACtBwqB,EAAgBtzB,OAAKkwB,eAAetV,GACpC2Y,EAAavzB,OAAK+I,cAAc6R,GAEhCzS,EACFnI,OAAK4vB,uBAAuB1vB,EAA0BqzB,GAEpDC,EAAQL,EAAOrqB,OACf2qB,EAAQL,EAAOtqB,OAEf4qB,EAAW1zB,OAAKkwB,eAAeiD,GAC/BQ,EAAW3zB,OAAKkwB,eAAekD,GAE/B1I,EAAiBrkB,eAAaskB,iBAAiBwI,EAAQvY,GACvDgQ,EAAiBvkB,eAAaskB,iBAAiByI,EAAQxY,GAE7D,GAAI8P,EAAe5hB,OAAS8hB,EAAe9hB,SAAW,EACpD,IAAK,IAAIM,EAAI,EAAGA,EAAIjB,EAAOW,SAAUM,EACnCjB,EAAOiB,GAAKmhB,EAAG7a,EAAMtG,EAAIsG,EAAM5G,QAAS2hB,EAAMrhB,EAAIqhB,EAAM3hB,cAG1D,IAAK,IAAIM,EAAI,EAAGA,EAAIjB,EAAOW,SAAUM,EAAG,CACtC,MAAMU,EAAM9J,OAAKsJ,WAAWF,EAAGiqB,EAAYC,GAErCvI,EAAOjhB,EAAIO,OAAOmpB,GACxB9I,EAAe5qB,QAAQsC,GAAK2oB,EAAK3oB,GAAK,GACtC,MAAM4oB,EAAShrB,OAAKgb,WAAW+P,EAAMyI,EAAOE,GAEtCzI,EAAOnhB,EAAIO,OAAOopB,GACxB7I,EAAe9qB,QAAQsC,GAAK6oB,EAAK7oB,GAAK,GACtC,MAAM8oB,EAASlrB,OAAKgb,WAAWiQ,EAAMwI,EAAOE,GAE5CxrB,EAAOiB,GAAKmhB,EAAG7a,EAAMsb,GAASP,EAAMS,IAIxC,MAAO,CAAC/iB,EAAQyS,ICzEb,MAAMgZ,EAAUV,EAAuB,CAACnnB,EAAW/J,IAAc+J,EAAI/J,GCE/D6xB,EAAYd,EAAyBe,MAAKF,GCC1CG,EAAoC,CAC/C1D,WAAY2D,gBACZzD,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQK,MAAAA,EAAO9rB,QAAAA,MAC3B,MAAMivB,MAACA,GAASxD,EACVC,EAAa1rB,EAEbxD,EAASxB,OAAK4vB,uBAChBqE,EAAM/zB,MAA0BF,OAAK+I,cAAckrB,EAAM/tB,SACtDwW,EAAOwP,EAAaC,EAAY/M,GAAe6U,EAAM/tB,MAEtDumB,EAAYiE,EAAW3qB,KAAKxB,IAAI0vB,EAAM1tB,QAAQ3E,OAEpD,IAAK,IAAIsyB,EAAW,EAAGA,EAAWxX,EAAOwX,IAAY,CACnD,MAAMtR,EAAcsR,EAAW/H,EAAaD,EAAc9M,EAE1D,IAAK,IAAI3T,EAAM,EAAGA,EAAMygB,EAAazgB,IAAO,CAC1C,MAAMoX,EAAYpX,GAAO0gB,EAAa/M,GAEtC,IAAK,IAAIzT,EAAM,EAAGA,EAAMwgB,EAAYxgB,IAAO,CACzC,MAAML,EAAYK,EAAMyT,EAExB,IAAK,IAAIzC,EAAU,EAAGA,EAAUyC,EAAazC,IAAW,CACtD,MAEM1X,EAFS,CAACyX,EAAOjR,EAAKE,EAAKgR,GAEhB,GAEXwX,EAASzxB,KAAKogB,MAAMqJ,EAAalnB,GACjCmvB,EAASxR,EAAcC,EAAYvX,EAAYqR,EAErD,IAAI0X,EAAc5H,EAAU2H,GAE5B,GAAID,GAAU,GAAKA,EAAShI,EAAY,CAKtCkI,EAAc5H,EADV7J,EAAcC,EAFOsR,EAAS/U,EAEezC,GAGnDnb,EAAO4yB,GAAUC,KAOzB,MAAO,CAAC9tB,OADOmqB,EAAWppB,MAAM9F,EAAQyyB,EAAM/tB,MAAO+tB,EAAM/zB,OAC3CgG,MAAO+tB,EAAM/tB,MAAOhG,MAAO+zB,EAAM/zB,SCrC9C,MAAMo0B,EAA+B,CAC1CjE,WAAYkE,WACZhE,YAAa,MACbC,oBAZEgE,GACF,MAAM/D,OAACA,EAAMzrB,QAAEA,GAAWwvB,GACpBvvB,EAACA,GAAKwrB,EAIZ,OAFAzrB,EAAQyvB,OAAOxvB,EAAEsB,QAEV,CAACA,OAAQtB,EAAEsB,OAAQL,MAAOjB,EAAEiB,MAAOhG,MAAO+E,EAAE/E,SCDxCw0B,EAA0B,CACrCrE,WAAYsE,MACZpE,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQK,MAAAA,EAAO9rB,QAAAA,MAC3B,MAAMC,EAACA,GAAKwrB,GACNmE,iBAACA,EAAgBC,SAAEA,GAAY/D,EAC/BJ,EAAa1rB,EACnB,IAAI3E,EAAS4E,EAAEiB,MACf,MAAM6pB,EAAQ1vB,EAAOyI,OAEfgsB,EAAW90B,OAAK+M,eAAe6nB,EAAkBv0B,GACvD,IAAIyM,EAAOgoB,EACX,MAAMC,EAAe1uB,eAAa2uB,mBAAmBloB,EAAMijB,GAC3D,IAAI/lB,EAAQ0mB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OAC1C,GAAoB,MAAhBmzB,EAAsB,CACxB,MAAMna,EAAqB,IAAIhb,MAAMmwB,GACrC,IAAK,IAAI3mB,EAAI,EAAGA,EAAIwR,EAAS9R,OAAQM,IACnCwR,EAASxR,GAAK/I,EAAO00B,EAAa3rB,IAGpCY,EAAQ6lB,EAAc7lB,EAAO3J,EAAQ4E,EAAE/E,MAAO60B,EAAcna,GAC5D9N,EAAOzG,eAAa4uB,iBAAiBnoB,EAAKhE,OAAQinB,GAElD1vB,EAASua,EAGXnb,EAAiBwF,EAAG,OACpBoB,eAAa+I,2BAA2B,MAAOtC,EAAMijB,GACrD,MAAOmF,EAAa7lB,GAChBhJ,eAAaiJ,0BAA0BjP,EAAQyM,GAI7C3E,EAASwnB,EAAQ3lB,EAFJhK,OAAK+I,cAAcsG,GAEI6lB,EAAajwB,EAAE/E,OACnDqG,EAASmqB,EAAWppB,MAAMa,EAAQ+sB,EAAajwB,EAAE/E,OAEvD,IAAIwB,EAAWwzB,EACf,GAAIL,EAAU,CAGZnzB,EADiB2E,eAAa6G,qBAAqBgoB,EAAaJ,GAIlE,MAAO,CAACvuB,OAAAA,EAAQL,MAAOxE,EAAUxB,MAAO+E,EAAE/E,SC9CvC,MAAMi1B,EAAwC,CACnD9E,WAAY+E,oBACZ7E,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQK,MAAAA,EAAO9rB,QAAAA,MAC3B,MAAMC,EAACA,GAAKwrB,GACN4E,WAACA,EAAU/0B,QAAEA,EAAOywB,IAAEA,EAAG/sB,oBAAEA,GAC7B8sB,EACEJ,EAAa1rB,EACnBvF,EAAiBwF,EAAG,qBAEpB,MAAMrD,EAAS8uB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OACvCrB,EAAW8F,eAAaivB,kBAC1BrwB,EAAEiB,MAA2CmvB,EAAY/0B,EACzD,CAAC,EAAG,GAAIywB,IACLwE,EAAQC,YClBfp1B,EAAqBC,EAAkBH,EACvC8D,EAA8BzD,GAChC,MACMk1B,EAAWt1B,EAAKC,EAASC,EAAQH,EADvBF,OAAKkwB,eAAe7vB,GACmBE,EAAU,OAC3D0D,EAAeH,EACjB1D,EAASC,EAAQH,EAAOK,GAAU,EAAMyD,GAE5C,MAAO,CAACyxB,EAAS7zB,OAAQqC,EAAarC,QDWV8zB,CACtB9zB,EAAQqD,EAAEiB,MAAOjB,EAAE/E,MAAO8D,EAAqBzD,GAE7Co1B,EACFjF,EAAWppB,MAAMiuB,EAAwBh1B,EAASmB,SAAUuD,EAAE/E,OAC5D01B,EACFlF,EAAWppB,MAAMkuB,EAAuBj1B,EAASmB,SAAUuD,EAAE/E,OACjE,MAAO,CACL,CAACqG,OAAQovB,EAAczvB,MAAO3F,EAASmB,SAAUxB,MAAO+E,EAAE/E,OAC1D,CAACqG,OAAQqvB,EAAe1vB,MAAO3F,EAASmB,SAAUxB,MAAO,YE3BzD21B,EAA0BnxB,eAAamxB,wBAIhCC,EAA0C,CACrDzF,WAAY0F,sBACZxF,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,EAAS8rB,MAAAA,MAC7B,MAAM7J,MAACA,EAAKC,OAAEA,GAAUuJ,GAClBtJ,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAc2O,mBAAEA,GAChDlF,EAEEJ,EAAa1rB,EAEnBvF,EAAiBwnB,EAAO,2BAExB,MAAMK,EAAYoJ,EAAW3qB,KAAKxB,IAAI0iB,EAAM1gB,QAAQ3E,OAC9C2lB,EAAamJ,EAAW3qB,KAAKxB,IAAI2iB,EAAO3gB,QAAQ3E,QAEhDq0B,gBAACA,EAAeC,aAAEA,GAAgBL,EACpCvO,EAAWC,EAAYJ,EAAeC,EAAcC,EACpD2O,GAEJ,MAAO,CAACC,EAAiBC,KCvBvBC,EAA0BzxB,eAAayxB,wBAIhCC,EAA0C,CACrD/F,WAAYgG,sBACZ9F,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,EAAS8rB,MAAAA,MAC7B,MAAM7J,MAACA,EAAKC,OAAEA,GAAUuJ,GAClBtJ,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAciP,aAAEA,GAChDxF,EAEEJ,EAAa1rB,EAEnBvF,EAAiBwnB,EAAO,8BAExB,MAAMK,EAAYoJ,EAAW3qB,KAAKxB,IAAI0iB,EAAM1gB,QAAQ3E,OAC9C2lB,EAAamJ,EAAW3qB,KAAKxB,IAAI2iB,EAAO3gB,QAAQ3E,OAEhD20B,EAAmBpP,EACnBqP,EAAkBpP,EAClBqP,EAAoBpP,EACpBqP,EAAkBJ,GAElBL,gBAACA,EAAeU,eAAEA,GAAkBR,EACtC7O,EAAWC,EAAYgP,EAAkBC,EACzCC,EAAmBC,GAEvB,MAAO,CAACT,EAAiBU,KCgBtB,MAAMC,EAA4B,CACvCvG,WAAYwG,QACZtG,YAAa,MACbC,oBA5CEgE,GAEF,MAAM/D,OAACA,EAAMzrB,QAAEA,EAAO8rB,MAAEA,GAAS0D,GAC3BvvB,EAACA,GAAKwrB,GACNqG,SAACA,EAAQC,cAAEA,GAAiBjG,EAElCrxB,EAAiBwF,EAAG,OAEpB,MAAMvD,EAAWo1B,EAAS3vB,IACtB,CAAC8M,EAAG7K,IAAM6K,EAAE,GAAqBhP,EAAEiB,MAAMkD,GAAK6K,EAAE,IAE9CnM,EAAQgvB,EAAS3vB,IAAI8M,GAAKA,EAAE,IAE5BjK,EAAQhF,EAAQe,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OACnCouB,EAAQhwB,OAAK+I,cAAc9D,EAAEiB,OAC7B6pB,EAAQ9qB,EAAEiB,MAAM4C,OAChBmnB,EAAWjwB,OAAKkwB,eAAejrB,EAAEiB,OAEjCqtB,EAAavzB,OAAK+I,cAAcrH,GAChC2xB,EAAa3xB,EAASoH,OACtBwqB,EAAgBtzB,OAAKkwB,eAAexuB,GACpC6M,EACFvO,OAAK4vB,uBAAuB3qB,EAAE/E,MAA0BqzB,GAEtC,IAAlBwD,GACFxoB,EAAQnE,KAAK2sB,GAGf,IAAK,IAAI3tB,EAAI,EAAGA,EAAI4mB,EAAO5mB,IAAK,CAC9B,MACM4tB,EADSh3B,OAAKsJ,WAAWF,EAAG2mB,EAAOE,GAChB9oB,IAAI,CAAC8Y,EAAG7W,IAAM6W,EAAInY,EAAMsB,IAGjDmF,EAFiBvO,OAAKgb,WAAWgc,EAAW3D,EAAYC,IAEpCtpB,EAAMZ,GAK5B,MAAO,CAAC7C,OAFMvB,EAAQsC,MAAMiH,EAAS7M,EAAUuD,EAAE/E,OAE1BgG,MAAOxE,EAAUxB,MAAO+E,EAAE/E,kBCxCnCqK,EACZiqB,GAGF,MAAM/D,OAACA,EAAMzrB,QAAEA,EAAO8rB,MAAEA,GAAS0D,GAC3BvvB,EAACA,GAAKwrB,GACNvqB,MAACA,GAAS4qB,EAIhB,OAFA9rB,EAAQyvB,OAAOxvB,EAAEsB,QAEV,CAACA,OAAQtB,EAAEsB,OAAQL,MAAAA,EAAOhG,MAAO+E,EAAE/E,OAGrC,MAAM+2B,EAA8B,CACzC5G,WAAY6G,UACZ3G,YAAa,MACbC,WAAYjmB,GCfD4sB,EAAuC,CAClD9G,WAAY+G,mBACZ7G,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQK,MAAAA,EAAO9rB,QAAAA,MAC3B,MAAMivB,MAACA,GAASxD,GACV4G,QAACA,EAAOC,UAAEA,EAASC,OAAEA,GAAUzG,EAC/BJ,EAAa1rB,EAEbxD,EAASxB,OAAK4vB,uBAChBqE,EAAM/zB,MAA0BF,OAAK+I,cAAckrB,EAAM/tB,SACtDwW,EAAOwP,EAAaC,EAAY/M,GAAe6U,EAAM/tB,OAErDsxB,EAASC,GACZpxB,eAAaqxB,eAAeH,EAAQrL,EAAaC,GAG/CwL,EAAYj1B,KAAK2Q,IAAIgkB,GACrBO,EAAYl1B,KAAKiuB,IAAI0G,GACrB5K,EAAYiE,EAAW3qB,KAAKxB,IAAI0vB,EAAM1tB,QAAQ3E,OAEpD,IAAK,IAAIsyB,EAAW,EAAGA,EAAWxX,EAAOwX,IAAY,CACnD,MAAMtR,EAAcsR,EAAW/H,EAAaD,EAAc9M,EAE1D,IAAK,IAAI3T,EAAM,EAAGA,EAAMygB,EAAazgB,IAAO,CAC1C,MAAMoX,EAAYpX,GAAO0gB,EAAa/M,GAEtC,IAAK,IAAIzT,EAAM,EAAGA,EAAMwgB,EAAYxgB,IAAO,CACzC,MAAML,EAAYK,EAAMyT,EAExB,IAAK,IAAIzC,EAAU,EAAGA,EAAUyC,EAAazC,IAAW,CACtD,MAAMkb,EAAS,CAACnb,EAAOjR,EAAKE,EAAKgR,GAE3B1X,EAAI4yB,EAAO,GACXplB,EAAIolB,EAAO,GAGjB,IAAI1D,GAAUlvB,EAAIuyB,GAAWI,GAAanlB,EAAIglB,GAAWE,EACrDG,GAAU7yB,EAAIuyB,GAAWG,GAAallB,EAAIglB,GAAWG,EACzDzD,EAASzxB,KAAKogB,MAAMqR,EAASqD,GAC7BM,EAASp1B,KAAKogB,MAAMgV,EAASL,GAE7B,IAAIpD,EAAciD,EAUlB,GATyB,iBAAdA,IAEPjD,EADc,IAAZ1X,EA7BW,IAgCC2a,EAAU3a,IAKxBwX,GAAU,GAAKA,EAAShI,GAAc2L,GAAU,GAChDA,EAAS5L,EAAa,CAMxBmI,EAAc5H,EADV7J,EAHqBkV,GAAU3L,EAAa/M,GACvB+U,EAAS/U,EAEsBzC,GAK1Dnb,EADeohB,EAAcC,EAAYvX,EAAYqR,GACpC0X,KAOzB,MAAO,CAAC9tB,OADOmqB,EAAWppB,MAAM9F,EAAQyyB,EAAM/tB,MAAO+tB,EAAM/zB,OAC3CgG,MAAO+tB,EAAM/tB,MAAOhG,MAAO+zB,EAAM/zB,kBCnErC63B,EAAUvD,GAKxB,MAAM/D,OAACA,EAAMK,MAAEA,EAAK9rB,QAAEA,GAAWwvB,GAC3BvvB,EAACA,GAAKwrB,GACNX,KAACA,GAAQgB,EAEfrxB,EAAiBwF,EAAG,aAEpB,MAAM8qB,EAAQ9qB,EAAEiB,MAAM4C,OAEhB8R,EAAqB,IAAIhb,MAAMmwB,GACrC,IAAK,IAAI3mB,EAAI,EAAGA,EAAIwR,EAAS9R,OAAQM,IACnCwR,EAASxR,GAAKnE,EAAEiB,MAAM4pB,EAAK1mB,IAG7B,MACMjB,EAAS0nB,EADA7qB,EAAQe,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OACLqD,EAAEiB,MAAOjB,EAAE/E,MAAO4vB,EAAMlV,GAG7D,MAAO,CAACrU,OADOvB,EAAQsC,MAAMa,EAAQyS,EAAU3V,EAAE/E,OACjCgG,MAAO0U,EAAU1a,MAAO+E,EAAE/E,OAGrC,MAAM83B,EAAgC,CAC3C3H,WAAY4H,YACZ1H,YAAa,MACbC,WAAYuH,GCgCP,MAAMG,EAAqC,CAChD7H,WAAY8H,iBACZ5H,YAAa,MACbC,oBA7D6BgE,GAK7B,MAAM/D,OAACA,EAAMzrB,QAAEA,EAAO8rB,MAAEA,GAAS0D,GAC3BvvB,EAACA,GAAKwrB,GACNxV,WAACA,EAAU6b,SAAEA,GAAYhG,EAE/BrxB,EAAiB,CAACwF,GAAI,kBAEtB,MAAM0K,EAAO3P,OAAK+I,cAAckS,GAE1Bmd,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBhoB,QAAS0mB,GAE1B,IAAK,IAAI1tB,EAAI,EAAI6R,EAAWnS,OAAQM,EAAInE,EAAEiB,MAAM4C,SAAUM,EACxDgvB,EAAiBhoB,KAAK,CAAC,EAAG,IAG5B,MAAMioB,EAAUzB,EAAYpG,WAAW,CACrCC,OAAQ,CAACxrB,EAAAA,GACTD,QAAAA,EACA8rB,MAAO,CAACgG,SAAUsB,EAAkBrB,cAAe,KAG/CuB,EACFjyB,eAAagV,YAAYgd,EAAQnyB,MAAO+U,EAAYtL,GAAM,GAExD4oB,EAAoClyB,eAAakV,YACnD+c,EAAoBxvB,OAAQmS,EAAWnS,QAAQ,GAE7C2mB,EACFppB,eAAaoV,oBAAoB4c,EAAQnyB,MAAO+U,EAAYtL,GAAM,GAIhE6oB,EACFjuB,EAAQ,CAACkmB,OAHwB,CAACxrB,EAAGozB,GAGLrzB,QAAAA,EAAS8rB,MAFV,CAAC5qB,MAAOoyB,KAOrCG,EACFV,EAAU,CAACtH,OAJ0B,CAACxrB,EAAGuzB,GAILxzB,QAAAA,EAAS8rB,MAF5B,CAAChB,KAAMyI,KAMtBpwB,EAASoC,EACX,CAACkmB,OAHsC,CAACxrB,EAAGwzB,GAGbzzB,QAAAA,EAAS8rB,MAFF,CAAC5qB,MAAOupB,KAQjD,OAJAzqB,EAAQ0zB,8BAA8BL,GACtCrzB,EAAQ0zB,8BAA8BF,GACtCxzB,EAAQ0zB,8BAA8BD,GAE/BtwB,IC3DIwwB,EAA6B,CACxCtI,WAAYuI,SACZrI,YAAa,MACbC,WAAY,EAAEC,OAAAA,EAAQzrB,QAAAA,MACpB,MAAMC,EAACA,GAAKwrB,EACNC,EAAa1rB,EACnBvF,EAAiBwF,EAAG,UAEpB,MAAMrD,EAAS8uB,EAAW3qB,KAAKxB,IAAIU,EAAEsB,QAAQ3E,OACvCoP,EAAY,IAAIU,aAAa9P,EAAOkH,QAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAIxH,EAAOkH,SAAUM,EAAG,CACtC,MAAMmH,EAAQ3O,EAAOwH,GACrB4H,EAAU5H,GAAKmH,EAAQA,EAGzB,MAAO,CAAChK,OADOmqB,EAAWppB,MAAM0J,EAAW/L,EAAEiB,MAAOjB,EAAE/E,OACtCgG,MAAOjB,EAAEiB,MAAOhG,MAAO+E,EAAE/E,SChBvC24B,EAAwB3F,EAAuB,CAACpiB,EAAMC,KAC1D,MAAMU,EAAOX,EAAOC,EACpB,OAAOU,EAAOA,IAGHqnB,EACT/F,EAAyBgG,oBAAmBF,GCc1CG,EAAgC,CACpC5I,EAAWQ,EAAkB+B,EAC7BV,EAAgC4B,EAAWE,EAC3CO,EAAgBa,EAAyBT,EAAWoB,EACpDM,EAA2BQ,EAAaK,EAAeE,EACvDe,EAAsBS,EAAcG,EAAyBd,GAG/D,IAAK,MAAMiB,KAAgBD,EACzBE,iBAAeD,+CC/CD"}